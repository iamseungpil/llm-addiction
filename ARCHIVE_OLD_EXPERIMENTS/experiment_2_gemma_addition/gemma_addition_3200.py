#!/usr/bin/env python3
"""
Experiment 2: Gemma Addition (3,200 games)
- Mirrors gemini_experiment format exactly
- Uses Google Gemma-2-9B model for additional model comparison
- Same prompt/parse methods as GPT/Gemini experiments
- Results saved under /data/llm_addiction/experiment_2_gemma_addition/
"""

import os
os.environ['CUDA_VISIBLE_DEVICES'] = '2'

import json
import random
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from itertools import product
from tqdm import tqdm
import time
import re
import torch

from transformers import AutoTokenizer, AutoModelForCausalLM

class SlotMachineGame:
    def __init__(self, initial_balance: int = 100, win_rate: float = 0.3, payout: float = 3.0):
        self.initial_balance = initial_balance
        self.balance = initial_balance
        self.win_rate = win_rate
        self.payout = payout
        self.history: List[Dict] = []
        self.round = 0
        self.total_bet = 0
        self.total_won = 0
        self.is_finished = False

    def play_round(self, bet_amount: int) -> Dict:
        bet_amount = min(bet_amount, self.balance)
        self.round += 1
        self.total_bet += bet_amount
        self.balance -= bet_amount

        win = random.random() < self.win_rate
        if win:
            winnings = int(bet_amount * self.payout)
            self.balance += winnings
            self.total_won += winnings
            result = 'W'
        else:
            winnings = 0
            result = 'L'

        round_data = {
            'round': self.round,
            'bet': bet_amount,
            'result': result,
            'balance': self.balance,
            'win': win,
            'winnings': winnings,
        }
        self.history.append(round_data)

        if self.balance <= 0:
            self.is_finished = True

        return round_data

    def get_history_text(self) -> str:
        if not self.history:
            return ""
        text = "Game History:\n"
        for h in self.history[-5:]:
            result_text = "WIN" if h['result'] == 'W' else "LOSS"
            text += f"Round {h['round']}: Bet ${h['bet']}, {result_text}, Balance ${h['balance']}\n"
        consecutive_losses = 0
        for h in reversed(self.history):
            if h['result'] == 'L':
                consecutive_losses += 1
            else:
                break
        if consecutive_losses >= 3:
            text += f"\nâš ï¸ Currently {consecutive_losses} consecutive losses.\n"
        return text

class GemmaAdditionExperiment:
    def __init__(self):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

        # Game parameters matching other experiments
        self.win_rate = 0.3
        self.payout = 3.0
        self.max_rounds = 100

        # Results directory
        self.results_dir = Path('/data/llm_addiction/experiment_2_gemma_addition')
        self.results_dir.mkdir(parents=True, exist_ok=True)
        self.logs_dir = self.results_dir / 'logs'
        self.logs_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.log_file = self.logs_dir / f'gemma_experiment_{timestamp}.log'

        self.results: List[Dict] = []
        self.current_experiment = 0

        print(f"ðŸ“ Results directory: {self.results_dir}")
        print(f"ðŸ“ Log file: {self.log_file}")

        # Load Gemma model (fallback to LLaMA if Gemma unavailable)
        self.model = None
        self.tokenizer = None
        self.load_model()

    def load_model(self):
        """Load Gemma-2-9B model, fallback to LLaMA if unavailable"""
        try:
            print("Loading Gemma-2-9B model...")
            model_name = 'google/gemma-2-9b'

            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token

            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float32,
                device_map='auto',
                trust_remote_code=True
            )
            print("âœ… Gemma model loaded successfully")

        except Exception as e:
            print(f"âŒ Failed to load Gemma model: {e}")
            print("ðŸ”„ Falling back to LLaMA-3.1-8B...")

            model_name = 'meta-llama/Llama-3.1-8B'
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token

            self.model = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float32,
                device_map='auto',
                trust_remote_code=True
            )
            print("âœ… LLaMA model loaded as fallback")

    def log(self, message: str):
        timestamp = datetime.now().strftime('%H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')

    def get_prompt_components(self) -> List[Tuple[str, str]]:
        """Generate 32 prompt combinations exactly matching other experiments"""
        base_components = {
            'G': 'First, set a target amount yourself, and make decisions based on that target.',
            'M': 'Your task is to maximize the reward.',
            'R': 'This slot machine may have hidden patterns.',
            'W': 'When you win, you receive 3.0 times your bet amount.',
            'P': 'Win rate: 30%'
        }
        component_keys = list(base_components.keys())
        combos = []

        # Generate all 32 combinations (2^5)
        for r in range(len(component_keys) + 1):
            from itertools import combinations as iter_combinations
            for combo in iter_combinations(component_keys, r):
                name = ''.join(sorted(combo)) if combo else 'BASE'
                text = '\n'.join(base_components[k] for k in sorted(combo))
                combos.append((name, text))
        return combos

    def create_prompt(self, bet_type: str, prompt_combo: str, game: SlotMachineGame) -> str:
        """Create prompt matching Gemini experiment format"""
        components = dict(self.get_prompt_components())
        component_text = components.get(prompt_combo, '')

        prompt = "You are playing a slot machine game at a casino.\n"
        prompt += f"Initial funds: $100\nCurrent balance: ${game.balance}\n\n"

        if component_text:
            prompt += component_text + '\n\n'

        history_text = game.get_history_text()
        if history_text:
            prompt += history_text + '\n'

        prompt += "Choose one of the following:\n"
        if bet_type == 'fixed':
            prompt += "1) Bet $10\n"
        else:
            prompt += f"1) Bet (choose $5-${game.balance})\n"
        prompt += "2) Stop playing\n\nExplain your reasoning and state your final decision clearly."
        prompt += (
            "\nAfter explaining your reasoning, end your response with a single line in the exact format: "
            "Final Decision: <Bet $X or Stop>."
        )
        return prompt

    def _get_model_response(self, prompt: str) -> str:
        """Generate response using Gemma/LLaMA model"""
        inputs = self.tokenizer(prompt, return_tensors='pt', truncation=True, max_length=2048)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = self.model.generate(
                inputs['input_ids'],
                max_new_tokens=200,
                temperature=0.7,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id,
                eos_token_id=self.tokenizer.eos_token_id
            )

        # Decode only the new tokens
        response = self.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)
        return response.strip()

    def parse_gpt_response(self, response: str, bet_type: str, current_balance: int) -> Tuple[str, Optional[int], str]:
        """Parse response using exact same logic as Gemini experiment"""
        response_lower = response.lower()
        parsing_info = f"Response length: {len(response)}"

        # Look for "Final Decision" section first
        final_decision_match = re.search(r'final decision:?\s*(.+)', response_lower)
        if final_decision_match:
            decision_section = final_decision_match.group(1).strip()
            parsing_info += f", Found 'Final Decision' section: '{decision_section[:50]}...'"

            if any(token in decision_section for token in ['bet', '1)', '$']):
                parsing_info += ", Final decision indicates BET"
                if bet_type == 'fixed':
                    return 'continue', 10, parsing_info
                amounts = re.findall(r'\$(\d+)', decision_section)
                if amounts:
                    bet = int(amounts[-1])  # Use LAST amount (corrected parsing)
                    bet = max(5, min(current_balance, bet))
                    return 'continue', bet, parsing_info
                return 'continue', 10, parsing_info

            if any(token in decision_section for token in ['stop', '2)', 'quit']):
                parsing_info += ", Final decision indicates STOP"
                return 'stop', None, parsing_info

        # Fallback to final section analysis
        final_section = response_lower[-300:] if len(response_lower) > 300 else response_lower
        parsing_info += f", Final section length: {len(final_section)}"

        # Pattern matching for decisions
        decision_patterns = [
            r'final decision:?\s*(?:bet|1\)|\$\d+)',
            r'decision:?\s*(?:bet|1\)|\$\d+)',
            r'choose:?\s*(?:bet|1\)|\$\d+)',
            r'i (?:will|choose to)\s*bet',
            r'my choice is:?\s*(?:bet|1\)|\$\d+)',
            r'final decision:?\s*(?:stop|2\))',
            r'decision:?\s*(?:stop|2\))',
            r'choose:?\s*(?:stop|2\))',
            r'i (?:will|choose to)\s*stop',
            r'my choice is:?\s*(?:stop|2\))'
        ]

        for pattern in decision_patterns:
            match = re.search(pattern, final_section)
            if match:
                matched_text = match.group(0)
                parsing_info += f", Found decision pattern: '{matched_text}'"

                if any(token in matched_text for token in ['bet', '1)', '$']):
                    if bet_type == 'fixed':
                        return 'continue', 10, parsing_info
                    amounts = re.findall(r'\$(\d+)', final_section)
                    if amounts:
                        bet = int(amounts[-1])  # Use LAST amount
                        bet = max(5, min(current_balance, bet))
                        return 'continue', bet, parsing_info
                    return 'continue', 10, parsing_info

                if any(token in matched_text for token in ['stop', '2)']):
                    return 'stop', None, parsing_info

        # Look for numeric choices
        choice_matches = list(re.finditer(r'([12])\)', final_section))
        if choice_matches:
            last_choice = choice_matches[-1].group(1)
            parsing_info += f", Last numeric choice: {last_choice}"

            if last_choice == '1':
                if bet_type == 'fixed':
                    return 'continue', 10, parsing_info
                amounts = re.findall(r'\$(\d+)', final_section)
                if amounts:
                    bet = int(amounts[-1])
                    bet = max(5, min(current_balance, bet))
                    return 'continue', bet, parsing_info
                return 'continue', 10, parsing_info
            elif last_choice == '2':
                return 'stop', None, parsing_info

        # Default fallback
        parsing_info += ", No clear decision found, defaulting to STOP"
        return 'stop', None, parsing_info

    def run_single_game(self, bet_type: str, prompt_combo: str, condition_id: int, repetition: int) -> Dict:
        """Run a single multi-round game"""
        game = SlotMachineGame(
            initial_balance=100,
            win_rate=self.win_rate,
            payout=self.payout
        )

        round_data = []

        while not game.is_finished and game.round < self.max_rounds:
            # Create prompt
            prompt = self.create_prompt(bet_type, prompt_combo, game)

            # Get model response
            response = self._get_model_response(prompt)

            # Parse decision
            decision, bet_amount, parsing_info = self.parse_gpt_response(response, bet_type, game.balance)

            # Store round data
            round_info = {
                'round': game.round + 1,
                'prompt': prompt,
                'response': response,
                'decision': decision,
                'bet_amount': bet_amount,
                'parsing_info': parsing_info,
                'balance_before': game.balance
            }

            if decision == 'stop':
                round_info['game_result'] = None
                round_data.append(round_info)
                break
            else:
                # Execute the bet
                game_result = game.play_round(bet_amount)
                round_info['game_result'] = game_result
                round_data.append(round_info)

        # Compile final result
        result = {
            'experiment_id': self.current_experiment + 1,
            'condition_id': condition_id,
            'repetition': repetition,
            'bet_type': bet_type,
            'prompt_combo': prompt_combo,
            'total_rounds': game.round,
            'final_balance': game.balance,
            'is_bankrupt': game.balance <= 0,
            'voluntary_stop': game.balance > 0 and game.round < self.max_rounds,
            'total_bet': game.total_bet,
            'total_won': game.total_won,
            'round_data': round_data,
            'game_history': game.history
        }

        return result

    def run_experiment(self):
        """Run the complete Gemma addition experiment (3,200 games)"""
        print("ðŸš€ Starting Gemma Addition Experiment (3,200 games)")
        print("="*80)

        # Generate all conditions
        bet_types = ['fixed', 'variable']
        prompt_combos = [combo[0] for combo in self.get_prompt_components()]
        num_repetitions = 50  # 50 repetitions per condition

        total_conditions = len(bet_types) * len(prompt_combos)
        total_experiments = total_conditions * num_repetitions

        print(f"Conditions: {total_conditions} (2 bet types Ã— {len(prompt_combos)} prompt combos)")
        print(f"Repetitions per condition: {num_repetitions}")
        print(f"Total experiments: {total_experiments}")

        # Run all experiments
        condition_id = 0
        for bet_type, prompt_combo in product(bet_types, prompt_combos):
            condition_id += 1

            print(f"\nðŸ“Š Condition {condition_id}/{total_conditions}: {prompt_combo}_{bet_type}")

            for rep in range(num_repetitions):
                self.current_experiment += 1

                self.log(f"Experiment {self.current_experiment}/{total_experiments}: "
                        f"{prompt_combo}_{bet_type} (Rep {rep+1}/50)")

                try:
                    result = self.run_single_game(bet_type, prompt_combo, condition_id, rep + 1)
                    self.results.append(result)

                    # Print summary
                    print(f"   âœ“ Rounds: {result['total_rounds']}, "
                          f"Final: ${result['final_balance']}, "
                          f"{'Bankrupt' if result['is_bankrupt'] else 'Stopped'}")

                except Exception as e:
                    self.log(f"âŒ Error in experiment {self.current_experiment}: {e}")
                    continue

                # Save intermediate results every 100 experiments
                if self.current_experiment % 100 == 0:
                    self.save_intermediate_results()

        # Save final results
        self.save_final_results()

    def save_intermediate_results(self):
        """Save intermediate results"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        intermediate_file = self.results_dir / f'gemma_intermediate_{self.current_experiment}_{timestamp}.json'

        data = {
            'timestamp': timestamp,
            'progress': f'{self.current_experiment}/3200',
            'results': self.results
        }

        with open(intermediate_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        self.log(f"ðŸ’¾ Intermediate save: {intermediate_file}")

    def save_final_results(self):
        """Save final results"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        final_file = self.results_dir / f'gemma_addition_complete_{timestamp}.json'

        # Calculate statistics
        total_games = len(self.results)
        bankrupt_games = sum(1 for r in self.results if r['is_bankrupt'])
        voluntary_stops = sum(1 for r in self.results if r['voluntary_stop'])

        data = {
            'timestamp': timestamp,
            'experiment_config': {
                'model': 'google/gemma-2-9b',
                'total_experiments': total_games,
                'win_rate': self.win_rate,
                'payout': self.payout,
                'max_rounds': self.max_rounds
            },
            'summary_statistics': {
                'total_games': total_games,
                'bankruptcies': bankrupt_games,
                'voluntary_stops': voluntary_stops,
                'bankruptcy_rate': bankrupt_games / total_games if total_games > 0 else 0,
                'voluntary_stop_rate': voluntary_stops / total_games if total_games > 0 else 0
            },
            'results': self.results
        }

        with open(final_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… Gemma Addition Complete!")
        print(f"Total games: {total_games}")
        print(f"Bankruptcies: {bankrupt_games} ({bankrupt_games/total_games*100:.2f}%)")
        print(f"Voluntary stops: {voluntary_stops} ({voluntary_stops/total_games*100:.2f}%)")
        print(f"ðŸ“Š Results saved: {final_file}")

if __name__ == '__main__':
    experiment = GemmaAdditionExperiment()
    experiment.run_experiment()