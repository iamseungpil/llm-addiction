/data/miniforge3/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/ubuntu/llm_addiction/experiment_2_llama_standardization/llama_standardization_3200.py", line 384, in <module>
    main()
  File "/home/ubuntu/llm_addiction/experiment_2_llama_standardization/llama_standardization_3200.py", line 380, in main
    experiment = LLaMAMultiRoundExperiment()
  File "/home/ubuntu/llm_addiction/experiment_2_llama_standardization/llama_standardization_3200.py", line 89, in __init__
    self.model = AutoModelForCausalLM.from_pretrained(
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 597, in from_pretrained
    model_class = _get_model_class(config, cls._model_mapping)
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 394, in _get_model_class
    supported_models = model_mapping[type(config)]
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 803, in __getitem__
    return self._load_attr_from_module(model_type, model_name)
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 817, in _load_attr_from_module
    return getattribute_from_module(self._modules[module_name], attr)
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 729, in getattribute_from_module
    if hasattr(module, attr):
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 2292, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 2320, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/data/miniforge3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 30, in <module>
    from ...modeling_layers import (
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/modeling_layers.py", line 29, in <module>
    from .processing_utils import Unpack
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/processing_utils.py", line 41, in <module>
    from .video_utils import VideoMetadata, load_video
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/video_utils.py", line 28, in <module>
    from .image_transforms import PaddingMode, to_channel_dimension_format
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/image_transforms.py", line 51, in <module>
    import jax.numpy as jnp
  File "/data/miniforge3/lib/python3.10/site-packages/jax/__init__.py", line 37, in <module>
    import jax.core as _core
  File "/data/miniforge3/lib/python3.10/site-packages/jax/core.py", line 18, in <module>
    from jax._src.core import (
  File "/data/miniforge3/lib/python3.10/site-packages/jax/_src/core.py", line 38, in <module>
    from jax._src import dtypes
  File "/data/miniforge3/lib/python3.10/site-packages/jax/_src/dtypes.py", line 33, in <module>
    from jax._src import config
  File "/data/miniforge3/lib/python3.10/site-packages/jax/_src/config.py", line 27, in <module>
    from jax._src import lib
  File "/data/miniforge3/lib/python3.10/site-packages/jax/_src/lib/__init__.py", line 87, in <module>
    import jaxlib.xla_client as xla_client
  File "/data/miniforge3/lib/python3.10/site-packages/jaxlib/xla_client.py", line 32, in <module>
    from . import xla_extension as _xla
AttributeError: _ARRAY_API not found
Loading LLaMA model...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.38s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.34s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.66s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.13s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26s/it]
âœ… LLaMA model loaded
ðŸ“ Results directory: /data/llm_addiction/experiment_2_llama_standardization
ðŸ“ Log file: /data/llm_addiction/experiment_2_llama_standardization/logs/llama_experiment_20250930_195808.log
[19:58:08] ðŸš€ Starting LLaMA 3,200-game Standardization Experiment
[19:58:08] ================================================================================
[19:58:08] Total conditions: 128
[19:58:08] Repetitions per condition: 50
[19:58:08] Total experiments: 6400
Running conditions:   0%|          | 0/128 [00:00<?, ?it/s]