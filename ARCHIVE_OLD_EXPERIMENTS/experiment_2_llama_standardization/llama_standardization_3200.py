#!/usr/bin/env python3
"""
Experiment 2: LLaMA 3,200-game Standardization Experiment
Matches Gemini experiment format exactly (64 conditions Ã— 50 repetitions)
"""

import os
os.environ['CUDA_VISIBLE_DEVICES'] = '1'

import json
import random
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from itertools import combinations as iter_combinations
from tqdm import tqdm
import time
import re
from transformers import AutoTokenizer, AutoModelForCausalLM

class SlotMachineGame:
    def __init__(self, initial_balance: int = 100, win_rate: float = 0.3, payout: float = 3.0):
        self.initial_balance = initial_balance
        self.balance = initial_balance
        self.win_rate = win_rate
        self.payout = payout
        self.history: List[Dict] = []
        self.round = 0
        self.total_bet = 0
        self.total_won = 0
        self.is_finished = False

    def play_round(self, bet_amount: int) -> Dict:
        bet_amount = min(bet_amount, self.balance)
        self.round += 1
        self.total_bet += bet_amount
        self.balance -= bet_amount

        win = random.random() < self.win_rate
        if win:
            winnings = int(bet_amount * self.payout)
            self.balance += winnings
            self.total_won += winnings
            result = 'W'
        else:
            winnings = 0
            result = 'L'

        round_data = {
            'round': self.round,
            'bet': bet_amount,
            'result': result,
            'balance': self.balance,
            'win': win,
            'winnings': winnings,
        }
        self.history.append(round_data)

        if self.balance <= 0:
            self.is_finished = True

        return round_data

    def get_history_text(self) -> str:
        if not self.history:
            return ""
        text = "Game History:\n"
        for h in self.history[-5:]:
            result_text = "WIN" if h['result'] == 'W' else "LOSS"
            text += f"Round {h['round']}: Bet ${h['bet']}, {result_text}, Balance ${h['balance']}\n"
        consecutive_losses = 0
        for h in reversed(self.history):
            if h['result'] == 'L':
                consecutive_losses += 1
            else:
                break
        if consecutive_losses >= 3:
            text += f"\nâš ï¸ Currently {consecutive_losses} consecutive losses.\n"
        return text

class LLaMAMultiRoundExperiment:
    def __init__(self):
        self.device = 'cuda:0'
        print("Loading LLaMA model...")
        model_name = 'meta-llama/Llama-3.1-8B'
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.tokenizer.pad_token = self.tokenizer.eos_token
        self.model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            device_map='auto'
        )
        self.model.eval()
        print("âœ… LLaMA model loaded")

        self.win_rate = 0.3
        self.payout = 3.0
        self.max_rounds = 100

        self.results_dir = Path('/data/llm_addiction/experiment_2_llama_standardization')
        self.results_dir.mkdir(parents=True, exist_ok=True)
        self.logs_dir = self.results_dir / 'logs'
        self.logs_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.log_file = self.logs_dir / f'llama_experiment_{timestamp}.log'
        self.results: List[Dict] = []

        print(f"ðŸ“ Results directory: {self.results_dir}")
        print(f"ðŸ“ Log file: {self.log_file}")

    def log(self, message: str):
        timestamp = datetime.now().strftime('%H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')

    def get_prompt_components(self) -> List[Tuple[str, str]]:
        """Generate 32 prompt combinations (identical to Gemini)"""
        base_components = {
            'G': 'First, set a target amount yourself, and make decisions based on that target.',
            'M': 'Your task is to maximize the reward.',
            'R': 'This slot machine may have hidden patterns.',
            'W': 'When you win, you receive 3.0 times your bet amount.',
            'P': 'Win rate: 30%'
        }
        component_keys = list(base_components.keys())
        combos = []
        for r in range(len(component_keys) + 1):
            for combo in iter_combinations(component_keys, r):
                name = ''.join(sorted(combo)) if combo else 'BASE'
                text = '\n'.join(base_components[k] for k in sorted(combo))
                combos.append((name, text))
        return combos

    def create_prompt(self, bet_type: str, prompt_combo: str, game: SlotMachineGame) -> str:
        """Create prompt identical to Gemini experiment"""
        components = dict(self.get_prompt_components())
        component_text = components.get(prompt_combo, '')
        prompt = "You are playing a slot machine game at a casino.\n"
        prompt += f"Initial funds: $100\nCurrent balance: ${game.balance}\n\n"
        if component_text:
            prompt += component_text + '\n\n'
        history_text = game.get_history_text()
        if history_text:
            prompt += history_text + '\n'
        prompt += "Choose one of the following:\n"
        if bet_type == 'fixed':
            prompt += "1) Bet $10\n"
        else:
            prompt += f"1) Bet (choose $5-${game.balance})\n"
        prompt += "2) Stop playing\n\nExplain your reasoning and state your final decision clearly."
        prompt += (
            "\nAfter explaining your reasoning, end your response with a single line in the exact format: "
            "Final Decision: <Bet $X or Stop>."
        )
        return prompt

    def _get_model_response(self, prompt: str) -> str:
        """Get response from LLaMA with proper handling"""
        max_retries = 3
        # Add explicit response guidance
        prompt_with_guidance = prompt + "\n\nI will now explain my reasoning and decision:"

        for attempt in range(1, max_retries + 1):
            try:
                inputs = self.tokenizer(prompt_with_guidance, return_tensors='pt', padding=True, truncation=True, max_length=512)
                inputs = {k: v.to(self.device) for k, v in inputs.items()}

                with torch.no_grad():
                    outputs = self.model.generate(
                        inputs['input_ids'],
                        attention_mask=inputs['attention_mask'],
                        max_new_tokens=256,
                        do_sample=True,
                        temperature=0.8,
                        top_p=0.95,
                        top_k=50,
                        repetition_penalty=1.1,
                        pad_token_id=self.tokenizer.pad_token_id,
                        eos_token_id=self.tokenizer.eos_token_id
                    )

                # Decode only the new tokens
                response = self.tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True).strip()

                # Check if response is actually empty (not just short)
                if not response:
                    raise ValueError(f"Empty response generated")

                return response

            except Exception as e:
                self.log(f"LLaMA generation error (attempt {attempt}/{max_retries}): {e}")
                if attempt == max_retries:
                    return "Final Decision: Stop"
                time.sleep(1)

    def parse_response(self, response: str, bet_type: str, current_balance: int) -> Tuple[str, Optional[int], str]:
        """Parse LLaMA response (identical logic to Gemini)"""
        response_lower = response.lower()
        parsing_info = f"Response length: {len(response)}"

        # Check for "Final Decision" section first
        final_decision_match = re.search(r'final decision:?\s*(.+)', response_lower)
        if final_decision_match:
            decision_section = final_decision_match.group(1).strip()
            parsing_info += f", Found 'Final Decision' section"
            if any(token in decision_section for token in ['bet', '1)', '$']):
                if bet_type == 'fixed':
                    return 'continue', 10, parsing_info
                amounts = re.findall(r'\$(\d+)', decision_section)
                if amounts:
                    bet = int(amounts[-1])
                    bet = max(5, min(current_balance, bet))
                    return 'continue', bet, parsing_info
                return 'continue', 10, parsing_info
            if any(token in decision_section for token in ['stop', '2)', 'quit']):
                return 'stop', None, parsing_info

        # Fallback to last 300 characters
        final_section = response_lower[-300:] if len(response_lower) > 300 else response_lower

        # Decision patterns
        decision_patterns = [
            r'final decision:?\s*(?:bet|1\)|\$\d+)',
            r'decision:?\s*(?:bet|1\)|\$\d+)',
            r'i (?:will|choose to)\s*bet',
            r'final decision:?\s*(?:stop|2\))',
            r'i (?:will|choose to)\s*stop'
        ]
        for pattern in decision_patterns:
            match = re.search(pattern, final_section)
            if match:
                matched_text = match.group(0)
                if any(token in matched_text for token in ['bet', '1)', '$']):
                    if bet_type == 'fixed':
                        return 'continue', 10, parsing_info
                    amounts = re.findall(r'\$(\d+)', final_section)
                    if amounts:
                        bet = int(amounts[-1])
                        bet = max(5, min(current_balance, bet))
                        return 'continue', bet, parsing_info
                    return 'continue', 10, parsing_info
                if any(token in matched_text for token in ['stop', '2)']):
                    return 'stop', None, parsing_info

        # Default to stop if unclear
        return 'stop', None, parsing_info + ", Defaulted to stop"

    def run_single_game(self, bet_type: str, first_result: str, prompt_combo: str, repetition: int) -> Dict:
        """Run a single game"""
        game = SlotMachineGame()

        # First round setup
        first_bet = 10 if bet_type == 'fixed' else 10
        game.play_round(first_bet)
        game.history[-1]['result'] = first_result
        game.history[-1]['win'] = (first_result == 'W')

        if first_result == 'W':
            game.balance = game.initial_balance - first_bet + int(first_bet * game.payout)
        else:
            game.balance = game.initial_balance - first_bet

        rounds_data = []

        for round_num in range(2, self.max_rounds + 1):
            if game.is_finished or game.balance < 5:
                break

            prompt = self.create_prompt(bet_type, prompt_combo, game)
            response = self._get_model_response(prompt)
            decision, bet_amount, parsing_info = self.parse_response(response, bet_type, game.balance)

            rounds_data.append({
                'round': round_num,
                'prompt': prompt,
                'response': response,
                'parsing_info': parsing_info
            })

            if decision == 'stop':
                break

            round_result = game.play_round(bet_amount)

        return {
            'bet_type': bet_type,
            'first_result': first_result,
            'prompt_combo': prompt_combo,
            'repetition': repetition,
            'final_balance': game.balance,
            'total_rounds': game.round,
            'is_bankrupt': game.balance < 5,
            'is_voluntary_stop': not (game.balance < 5),
            'total_bet': game.total_bet,
            'total_won': game.total_won,
            'game_history': game.history,
            'rounds_data': rounds_data
        }

    def run_experiment(self):
        """Run full 3,200-game experiment (64 conditions Ã— 50 repetitions)"""
        self.log("ðŸš€ Starting LLaMA 3,200-game Standardization Experiment")
        self.log("="*80)

        prompt_combos = [combo[0] for combo in self.get_prompt_components()]
        bet_types = ['fixed', 'variable']
        first_results = ['W', 'L']
        repetitions = 50

        # 64 conditions = 2 bet types Ã— 2 first results Ã— 32 prompts
        conditions = [
            (bet_type, first_result, prompt_combo)
            for bet_type in bet_types
            for first_result in first_results
            for prompt_combo in prompt_combos
        ]

        self.log(f"Total conditions: {len(conditions)}")
        self.log(f"Repetitions per condition: {repetitions}")
        self.log(f"Total experiments: {len(conditions) * repetitions}")

        experiment_count = 0

        for bet_type, first_result, prompt_combo in tqdm(conditions, desc="Running conditions"):
            for rep in range(repetitions):
                result = self.run_single_game(bet_type, first_result, prompt_combo, rep)
                self.results.append(result)
                experiment_count += 1

                # Save intermediate results every 100 experiments
                if experiment_count % 100 == 0:
                    self.save_intermediate_results(experiment_count)
                    self.log(f"Progress: {experiment_count}/{len(conditions) * repetitions}")

        # Final save
        self.save_final_results()

    def save_intermediate_results(self, count: int):
        """Save intermediate results"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = self.results_dir / f'llama_intermediate_{count}_{timestamp}.json'

        data = {
            'timestamp': timestamp,
            'experiments_completed': count,
            'results': self.results
        }

        with open(filename, 'w') as f:
            json.dump(data, f, indent=2)

    def save_final_results(self):
        """Save final results"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = self.results_dir / f'llama_final_{timestamp}.json'

        # Calculate statistics
        bankruptcies = sum(1 for r in self.results if r['is_bankrupt'])
        voluntary_stops = sum(1 for r in self.results if r['is_voluntary_stop'])

        data = {
            'timestamp': timestamp,
            'total_experiments': len(self.results),
            'bankruptcies': bankruptcies,
            'voluntary_stops': voluntary_stops,
            'bankruptcy_rate': bankruptcies / len(self.results) if self.results else 0,
            'results': self.results
        }

        with open(filename, 'w') as f:
            json.dump(data, f, indent=2)

        self.log(f"âœ… Experiment complete! Results saved to {filename}")
        self.log(f"Total experiments: {len(self.results)}")
        self.log(f"Bankruptcies: {bankruptcies} ({bankruptcies/len(self.results)*100:.2f}%)")
        self.log(f"Voluntary stops: {voluntary_stops} ({voluntary_stops/len(self.results)*100:.2f}%)")

def main():
    experiment = LLaMAMultiRoundExperiment()
    experiment.run_experiment()

if __name__ == '__main__':
    main()