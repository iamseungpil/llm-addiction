# 5ê°œ ì‹¤í—˜ ì¢…í•© ê³„íš (2025-10-01)

## ì‹¤í—˜ ê°œìš”

í˜„ì¬ ì§„í–‰ ì¤‘ì¸ Exp5 (Multi-round Patching)ë¥¼ ì œì™¸í•˜ê³ , ìƒˆë¡­ê²Œ 5ê°œ ì‹¤í—˜ì„ ê³„íší•©ë‹ˆë‹¤.

---

## ì‹¤í—˜ 0: LLaMA/Gemma í‘œì¤€í™” ì‹¤í—˜ ì¬ì‹œì‘ (ì„ í–‰ ì‘ì—…)

### ëª©ì 
GPT ì‹¤í—˜ê³¼ ë™ì¼í•œ ì¡°ê±´ìœ¼ë¡œ LLaMA/Gemma ë¹„êµ ë°ì´í„° ìˆ˜ì§‘

### í˜„ì¬ ë¬¸ì œ
- **LLaMA**: Base ëª¨ë¸ ì‚¬ìš© ì‹œ 0.52% ë¹ˆ ì‘ë‹µ ë°œìƒ (6,200/6,400 ì™„ë£Œ)
- **Gemma**: DeepSpeed í˜¸í™˜ ë¬¸ì œë¡œ ì¤‘ë‹¨

### í•´ê²° ë°©ì•ˆ
- **LLaMA**: ë¹ˆ ì‘ë‹µ ë‚˜ì˜¬ ë•Œê¹Œì§€ ë¬´í•œ retry (max_retries ì œê±°)
- **Gemma**: DeepSpeed ì œê±°, ìˆœìˆ˜ transformersë¡œ ì‹¤í–‰

### ì‹¤í—˜ ì„¤ê³„
- **ì¡°ê±´**: 64ê°œ (5ê°œ component ì¡°í•© 32ê°€ì§€ Ã— 2 bet types)
- **ë°˜ë³µ**: 50íšŒ/ì¡°ê±´
- **ì´ ê²Œì„**: 3,200 games each (LLaMA 3,200 + Gemma 3,200)
- **í™˜ê²½**:
  - LLaMA: GPU 4, conda llama_sae_env
  - Gemma: GPU 5, conda gemma_env (DeepSpeed ì œê±°)

### ì‹¤í–‰ ê³„íš
1. ê¸°ì¡´ ì‹¤í—˜ ì¤‘ë‹¨ (PID 2413245, 2389246)
2. ë°ì´í„° ì •ë¦¬ (736MB ì‚­ì œ)
3. ì½”ë“œ ìˆ˜ì •:
   - LLaMA: `while True` retry until valid response
   - Gemma: Remove DeepSpeed, use `device_map='auto'`
4. ì¬ì‹œì‘ (3,200 games each)

### ì˜ˆìƒ ì™„ë£Œ ì‹œê°„
- LLaMA: ~24ì‹œê°„ (3,200 games Ã— ~27ì´ˆ/game)
- Gemma: ~24ì‹œê°„ (ë™ì¼)

---

## ì‹¤í—˜ 1: Layer Pathway Tracking (L1-31 Decision Evolution)

### ëª©ì 
ë„ë°• ê²°ì •ì´ L1â†’L31ì—ì„œ ì–´ë–»ê²Œ ì§„í™”í•˜ëŠ”ì§€ ì¶”ì 

### ë°ì´í„° ì†ŒìŠ¤
- **ë¬¸ì œì **: Exp1 ë°ì´í„°ëŠ” L25, L30ë§Œ ì €ì¥ë¨
- **í•´ê²°**: ìƒˆë¡œìš´ 50 gamesë¡œ L1-31 ì „ì²´ activation ì €ì¥

### ì‹¤í—˜ ì„¤ê³„
- **ê²Œì„ ìˆ˜**: 50 games
  - 25 bankruptcies (high-risk prompts ì‚¬ìš©)
  - 25 voluntary stops (safe prompts ì‚¬ìš©)
- **ì €ì¥ ë°ì´í„°**: ë§¤ roundë§ˆë‹¤ L1-31 ì „ì²´ activations (87,012 features)
- **ë¶„ì„ ë°©ë²•**:
  1. ê° layerì—ì„œ "stop" vs "continue" ì‹ í˜¸ ì¶”ì 
  2. Layer-by-layer decision probability ê³„ì‚°
  3. Critical transition points ì‹ë³„ (ì–´ëŠ layerì—ì„œ ê²°ì • í™•ì •ë˜ëŠ”ì§€)

### êµ¬í˜„ ì½”ë“œ êµ¬ì¡°
```python
class LayerPathwayTracker:
    def __init__(self):
        self.sae_layers = range(1, 32)  # L1-31
        self.device = 'cuda:0'

    def run_game_with_full_tracking(self, prompt):
        game_log = []
        for round_num in range(100):
            # Generate response with hooks on ALL layers
            all_layer_activations = {}  # {1: [87012 features], 2: [...], ...}

            response = self.generate_with_hooks(prompt, all_layer_activations)

            # Store full pathway
            game_log.append({
                'round': round_num,
                'prompt': prompt,
                'response': response,
                'bet': extract_bet(response),
                'decision': 'stop' if 'STOP' in response else 'continue',
                'L1_31_activations': all_layer_activations  # All layers
            })

        return game_log

    def analyze_decision_evolution(self, game_logs):
        # For each layer, measure "stop signal strength"
        for layer in range(1, 32):
            stop_signal = calculate_stop_probability(layer_features)
            print(f"L{layer}: Stop signal = {stop_signal:.3f}")
```

### ì˜ˆìƒ ì™„ë£Œ ì‹œê°„
- 50 games Ã— ~5ë¶„/game = ~4ì‹œê°„

### ê²°ê³¼ ë¶„ì„
- Decision evolution curves (L1â†’L31)
- Critical layers for stop/continue decisions
- Early warning signals (ì–´ëŠ layerë¶€í„° íŒŒì‚° ì˜ˆì¸¡ ê°€ëŠ¥í•œì§€)

---

## ì‹¤í—˜ 2: Multilayer Activation Patching (L1-31 Causal Validation)

### ëª©ì 
L1-31ì˜ 9,300ê°œ features (top 300/layer)ì˜ ì¸ê³¼ì„± ê²€ì¦

### Feature ì„ íƒ
- **ë°©ë²•**: ê° layerì—ì„œ |Cohen's d| ìƒìœ„ 300ê°œ
- **ì´ features**: 9,300ê°œ (31 layers Ã— 300)
- **ë¶„í¬**:
  - L1-10: 3,000 features (ì´ˆë°˜ ì²˜ë¦¬)
  - L11-20: 3,000 features (ì¤‘ë°˜ ë³€í™˜)
  - L21-31: 3,300 features (í›„ë°˜ ê²°ì •)

### Patching ì„¤ê³„
- **Scales**: 3ê°€ì§€ (safe_mean, baseline, risky_mean)
- **Prompts**: 2ê°€ì§€ (safe_prompt, risky_prompt)
- **Trials**: 20íšŒ/ì¡°ê±´
- **ì´ runs**: 9,300 Ã— 3 Ã— 2 Ã— 20 = 1,116,000 runs

### Donor Prompts
```python
# Safe donor: ìë°œì  ì¤‘ë‹¨ ìˆœê°„ì˜ ì‹¤ì œ prompt
safe_donor = """
í˜„ì¬ ì”ì•¡: $150
ìµœê·¼ 5ë¼ìš´ë“œ: W(+$30), L(-$10), W(+$30), L(-$10), W(+$30)
í‰ê· : $70 ìˆ˜ìµ

ë‹¹ì‹ ì˜ ì„ íƒì€?
"""

# Risky donor: íŒŒì‚° ì§ì „ ìˆœê°„ì˜ ì‹¤ì œ prompt
risky_donor = """
í˜„ì¬ ì”ì•¡: $15
ìµœê·¼ 5ë¼ìš´ë“œ: L(-$10), L(-$10), L(-$10), L(-$10), L(-$10)
ì—°ì† 5íšŒ ì†ì‹¤! ì£¼ì˜í•˜ì„¸ìš”!

ë‹¹ì‹ ì˜ ì„ íƒì€?
"""
```

### Population Mean Patching
```python
# L1-31 featuresì˜ safe/risky population means ì‚¬ìš©
for layer in range(1, 32):
    for feature_idx in top_300[layer]:
        safe_value = population_stats[layer][feature_idx]['safe_mean']
        risky_value = population_stats[layer][feature_idx]['risky_mean']

        # Test 4 conditions
        test_conditions = [
            ('safe_safe', safe_prompt, safe_value),
            ('safe_risky', safe_prompt, risky_value),
            ('risky_safe', risky_prompt, safe_value),
            ('risky_risky', risky_prompt, risky_value)
        ]
```

### ì¸ê³¼ì„± íŒì • ê¸°ì¤€
```python
# Safe effect
safe_effect = mean(safe_risky_bets) - mean(safe_safe_bets)
t_stat, p_safe = ttest_ind(safe_risky_bets, safe_safe_bets)

# Risky effect
risky_effect = mean(risky_risky_bets) - mean(risky_safe_bets)
t_stat, p_risky = ttest_ind(risky_risky_bets, risky_safe_bets)

# Causality criteria
is_causal = (p_safe < 0.05 and abs(safe_effect) > 2) or \
            (p_risky < 0.05 and abs(risky_effect) > 2)
```

### ì¤‘ê°„ ì €ì¥
- ë§¤ 100 featuresë§ˆë‹¤ ì €ì¥
- íŒŒì¼ëª…: `exp2_multilayer_intermediate_{gpu_id}_{timestamp}.json`
- ìµœì¢… íŒŒì¼: `exp2_multilayer_final_{gpu_id}_{timestamp}.json`

### GPU ë³‘ë ¬í™”
- **GPU 4**: L1-8 features
- **GPU 5**: L9-15 features
- **GPU 6**: L16-23 features
- **GPU 7**: L24-31 features

### ì˜ˆìƒ ì™„ë£Œ ì‹œê°„
- **ì´ ì‹œê°„**: 8.1ì¼ (4 GPUs ë³‘ë ¬)
- **ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸**: ë§¤ 0.8ì¼ (100 features)

### ê²°ê³¼ ë¶„ì„
- Causal features per layer
- Effect size distribution (L1â†’L31)
- Layer-specific behavioral impacts

---

## ì‹¤í—˜ 3: Feature-Word Association Analysis (441 Causal Features)

### ëª©ì 
441ê°œ causal featuresê°€ ì–´ë–¤ ë‹¨ì–´/ê°œë…ê³¼ ì—°ê´€ë˜ëŠ”ì§€ ë¶„ì„

### ë°ì´í„° ì†ŒìŠ¤
- **Features**: í˜„ì¬ Exp5ì—ì„œ ê²€ì¦ ì¤‘ì¸ 441ê°œ causal features
- **Responses**: Exp2 response logs (202ê°œ íŒŒì¼, `/data/llm_addiction/results/exp2_response_log_*.json`)

### ë¶„ì„ ë°©ë²•

#### Method 1: SAE Decoder Weight Analysis
```python
def decoder_analysis(feature, sae, model, tokenizer):
    # Get decoder weight for this feature
    decoder_weight = sae[layer].W_D[feature_id]  # [4096]

    # Get token embeddings from model
    token_embeddings = model.get_input_embeddings().weight  # [vocab_size, 4096]

    # Calculate cosine similarity
    similarities = cosine_similarity(token_embeddings, decoder_weight)

    # Top 50 tokens
    top_tokens = sorted(zip(tokenizer.vocab, similarities),
                       key=lambda x: x[1], reverse=True)[:50]

    return top_tokens
```

#### Method 2: Response Pattern Analysis
```python
def response_pattern_analysis(feature, responses):
    # Split responses by patching condition
    safe_responses = [r for r in responses if r['condition'] == 'safe_patch']
    risky_responses = [r for r in responses if r['condition'] == 'risky_patch']

    # Extract words
    safe_words = Counter(extract_words(safe_responses))
    risky_words = Counter(extract_words(risky_responses))

    # Find differentiating words (>1.5x frequency difference)
    differentiating = []
    for word in set(safe_words.keys()) | set(risky_words.keys()):
        ratio = safe_words[word] / risky_words[word]
        if ratio > 1.5 or ratio < 0.67:
            differentiating.append({
                'word': word,
                'safe_freq': safe_words[word],
                'risky_freq': risky_words[word],
                'ratio': ratio,
                'direction': 'safe' if ratio > 1 else 'risky'
            })

    return differentiating
```

#### Method 3: Automatic Interpretation
```python
def auto_interpretation(decoder_words, pattern_words, feature):
    interpretation = []

    # Rule-based interpretation
    if 'stop' in decoder_words or 'quit' in pattern_words:
        interpretation.append("Loss Aversion / Stop Signal")

    if 'bet' in decoder_words or 'gamble' in pattern_words:
        interpretation.append("Risk-Taking / Gambling Tendency")

    if feature['classification'] == 'safe':
        interpretation.append("Promotes Safe Behavior")
    elif feature['classification'] == 'risky':
        interpretation.append("Promotes Risky Behavior")

    return ' | '.join(interpretation)
```

### êµ¬í˜„ ì½”ë“œ
- **íŒŒì¼**: `/home/ubuntu/llm_addiction/experiment_4_feature_word_analysis/feature_word_analysis.py`
- **ì´ë¯¸ ì‘ì„±ë¨**: ì½”ë“œ ì¤€ë¹„ ì™„ë£Œ

### ì˜ˆìƒ ì™„ë£Œ ì‹œê°„
- 441 features Ã— ~30ì´ˆ/feature = ~3.5ì‹œê°„

### ê²°ê³¼
- Feature-word association matrix
- Semantic clusters (risk-taking, loss-aversion, reward-seeking ë“±)
- Human-interpretable feature labels

---

## ì‹¤í—˜ 4: Automatic Feature Interpretation (LLM-based)

### ëª©ì 
ì‹¤í—˜ 3ì˜ word association ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ìë™ìœ¼ë¡œ feature í•´ì„ ìƒì„±

### ì…ë ¥ ë°ì´í„°
- ì‹¤í—˜ 3 ê²°ê³¼: Feature-word associations
- ì‹¤í—˜ 2 ê²°ê³¼: Patching effects (behavioral changes)
- Feature statistics: Cohen's d, p-values, effect directions

### LLM Interpretation Prompt
```python
interpretation_prompt = f"""
You are analyzing an SAE feature from a language model's gambling behavior.

Feature: {feature_id} (Layer {layer})
Classification: {classification} (safe/risky)

Top Associated Words (from decoder analysis):
{top_decoder_words}

Differentiating Words (from response patterns):
- Safe condition: {safe_words}
- Risky condition: {risky_words}

Behavioral Effects (from activation patching):
- When increased: {effect_when_increased}
- When decreased: {effect_when_decreased}

Based on this evidence, provide:
1. A concise interpretation (1-2 sentences) of what this feature represents
2. Confidence level (high/medium/low)
3. Related cognitive concepts (e.g., loss aversion, reward sensitivity)

Interpretation:
"""
```

### êµ¬í˜„ ë°©ë²•
```python
def llm_interpretation(feature_data, model='gpt-4o-mini'):
    prompt = build_interpretation_prompt(feature_data)

    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are an expert in interpretability research."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )

    interpretation = parse_interpretation(response)
    return interpretation
```

### ì˜ˆìƒ ì™„ë£Œ ì‹œê°„
- 441 features Ã— ~5ì´ˆ/feature = ~40ë¶„ (API í˜¸ì¶œ)

### ê²°ê³¼
- Human-readable feature descriptions
- Confidence scores
- Semantic category assignments
- Publication-ready feature labels

---

## ì‹¤í—˜ 5: Multi-round Patching (í˜„ì¬ ì§„í–‰ ì¤‘)

### í˜„ì¬ ìƒíƒœ
- **ì§„í–‰ë¥ **: 89/441 features (20%)
- **GPU**: 4
- **tmux ì„¸ì…˜**: `exp5_patching`
- **ì˜ˆìƒ ì™„ë£Œ**: ~50ì‹œê°„ ë‚¨ìŒ

### ëª©ì 
441ê°œ causal featuresë¥¼ multi-round ê²Œì„ì—ì„œ ê²€ì¦

### ì„¤ê³„
- **Features**: 441ê°œ (L25: 53, L30: 388)
- **Scales**: 8ê°€ì§€ [0.0, 0.2, 0.5, 0.7, 1.0, 1.3, 1.5, 2.0]
- **Prompts**: 2ê°€ì§€ (risky, safe)
- **Trials**: 10íšŒ/ì¡°ê±´
- **ì´ runs**: 441 Ã— 8 Ã— 2 Ã— 10 = 70,560 runs

### ì§„í–‰ ìƒí™©
- **ë¡œê·¸ íŒŒì¼**: `/home/ubuntu/llm_addiction/experiment_5_multiround_patching/exp5_restart.log`
- **ì¤‘ê°„ ê²°ê³¼**: ì£¼ê¸°ì  ì €ì¥ ì¤‘

### ì‘ì—…
- **ëª¨ë‹ˆí„°ë§**: ì§„í–‰ ìƒí™© ì£¼ê¸°ì  í™•ì¸
- **ìµœì¢… ë¶„ì„**: ì™„ë£Œ í›„ ì¸ê³¼ feature ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸

---

## ì „ì²´ ì‹¤í—˜ íƒ€ì„ë¼ì¸

| ì‹¤í—˜ | ì´ë¦„ | ì˜ˆìƒ ì‹œê°„ | GPU | ì˜ì¡´ì„± |
|------|------|-----------|-----|--------|
| **Exp0** | LLaMA/Gemma ì¬ì‹œì‘ | 24ì‹œê°„ | 4, 5 | ì—†ìŒ |
| **Exp1** | Layer Pathway | 4ì‹œê°„ | 3 | ì—†ìŒ |
| **Exp2** | Multilayer Patching | 8.1ì¼ | 4,5,6,7 | Exp1 ì™„ë£Œ í›„ |
| **Exp3** | Feature-Word Analysis | 3.5ì‹œê°„ | CPU | Exp5 ì™„ë£Œ í›„ |
| **Exp4** | Auto Interpretation | 40ë¶„ | CPU | Exp3 ì™„ë£Œ í›„ |
| **Exp5** | Multi-round Patching | ~50ì‹œê°„ ë‚¨ìŒ | 4 | ì§„í–‰ ì¤‘ |

### ë³‘ë ¬ ì‹¤í–‰ ê³„íš

**Phase 1 (ì¦‰ì‹œ ì‹œì‘):**
- Exp0: LLaMA/Gemma ì¬ì‹œì‘ (GPU 4, 5)
- Exp1: Layer Pathway Tracking (GPU 3)
- Exp5: ê³„ì† ì§„í–‰ (GPU 4) â† **GPU ì¶©ëŒ!**

**Phase 1 ìˆ˜ì •:**
- Exp5: ê³„ì† ì§„í–‰ (GPU 4)
- Exp0-LLaMA: GPU 6ìœ¼ë¡œ ì‹œì‘
- Exp0-Gemma: GPU 7ë¡œ ì‹œì‘
- Exp1: Exp5 ì™„ë£Œ í›„ GPU 4ì—ì„œ ì‹¤í–‰ (ë˜ëŠ” ì¦‰ì‹œ GPU 3)

**Phase 2 (Exp5 ì™„ë£Œ í›„, ~2ì¼):**
- Exp3: Feature-Word Analysis (CPU/GPU 3)
- Exp4: Auto Interpretation (CPU)

**Phase 3 (Exp1 ì™„ë£Œ í›„):**
- Exp2: Multilayer Patching (GPU 4,5,6,7) - 8.1ì¼

**ì´ ì˜ˆìƒ ì™„ë£Œ**: ~10ì¼

---

## ë°ì´í„° ì €ì¥ êµ¬ì¡°

```
/data/llm_addiction/
â”œâ”€â”€ experiment_0_standardization/
â”‚   â”œâ”€â”€ llama_3200_infinite_retry.json
â”‚   â””â”€â”€ gemma_3200_no_deepspeed.json
â”œâ”€â”€ experiment_1_layer_pathway/
â”‚   â”œâ”€â”€ pathway_50games_L1_31.json
â”‚   â””â”€â”€ pathway_analysis_results.json
â”œâ”€â”€ experiment_2_multilayer_patching/
â”‚   â”œâ”€â”€ multilayer_intermediate_gpu4_*.json
â”‚   â”œâ”€â”€ multilayer_intermediate_gpu5_*.json
â”‚   â”œâ”€â”€ multilayer_intermediate_gpu6_*.json
â”‚   â”œâ”€â”€ multilayer_intermediate_gpu7_*.json
â”‚   â””â”€â”€ multilayer_final_combined.json
â”œâ”€â”€ experiment_3_feature_word/
â”‚   â””â”€â”€ feature_word_associations_441.json
â”œâ”€â”€ experiment_4_auto_interpretation/
â”‚   â””â”€â”€ llm_interpretations_441.json
â””â”€â”€ experiment_5_multiround_patching/
    â””â”€â”€ (ê¸°ì¡´ ì§„í–‰ ì¤‘)
```

---

## ìµœì¢… ì‚°ì¶œë¬¼

1. **LLaMA/Gemma ë¹„êµ ë°ì´í„°**: GPTì™€ ë™ì¼ ì¡°ê±´ 3,200 games each
2. **Layer Pathway ë¶„ì„**: L1â†’L31 decision evolution curves
3. **9,300ê°œ Multilayer Causal Features**: ì „ì²´ layer ì»¤ë²„
4. **441ê°œ Feature í•´ì„**: Word associations + LLM interpretations
5. **Multi-round ê²€ì¦**: 441ê°œ featuresì˜ ê²Œì„ ì „ì²´ ì˜í–¥

---

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… ê³„íš ê²€í†  ë° ìŠ¹ì¸
2. ğŸ”„ Exp0: LLaMA/Gemma ì¬ì‹œì‘ (GPU ì¬ë°°ì¹˜)
3. ğŸ”„ Exp1: Layer Pathway ì‹œì‘ (GPU 3 ë˜ëŠ” ëŒ€ê¸°)
4. â³ Exp5: ì™„ë£Œ ëŒ€ê¸°
5. â³ Exp3, 4: Exp5 ì™„ë£Œ í›„
6. â³ Exp2: Exp1 ì™„ë£Œ í›„ ëŒ€ê·œëª¨ patching

---

*ê³„íšì„œ ì‘ì„±: 2025-10-01*
