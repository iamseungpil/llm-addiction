/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading 441 causal features...
âœ… Loaded 441 causal features

Loading LLaMA model...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.43s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.44s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.46s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.02s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.17s/it]
âœ… LLaMA model loaded

================================================================================
ðŸ”¬ Feature-Word Association Analysis
================================================================================

Loading experiment indices from /data/llm_addiction/results/exp1_multiround_intermediate_20250819_140040.json...
Total experiments: 5780
Sampled 320 experiments

ðŸ“Š Processing 320 experiments...
Experiments:   0%|          | 0/320 [00:00<?, ?it/s]Experiments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 320/320 [00:00<00:00, 604040.18it/s]

ðŸ“Š Analyzing token-feature associations...
Processing features:   0%|          | 0/441 [00:00<?, ?it/s]Processing features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 441/441 [00:00<00:00, 114079.69it/s]

âœ… Results saved: /data/llm_addiction/analysis/feature_word_associations.json
   Total features analyzed: 441
   Total unique tokens tracked: 0

ðŸ“‹ Sample results (first 3 features):

  L25-1026 (safe):

  L25-10427 (safe):

  L25-1130 (safe):

ðŸŽ‰ Feature-word association analysis complete!
