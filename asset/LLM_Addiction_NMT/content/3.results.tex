\section{Results}
\label{sec:results}

\subsection{Behavioral experiments reveal autonomy-driven risk escalation}

To examine the two core components of irrationality defined in Section~\ref{sec:defining-addiction}---self-regulation failure and cognitive distortions---in LLMs, we conducted two experiments using negative expected value paradigms where rational behavior is to stop immediately. The slot machine experiment serves as our main study, examining addiction-like behaviors across diverse models and prompt conditions. The investment choice experiment functions as an ablation study, isolating the specific effects of goal-setting and betting flexibility on risk preferences. Refer to Appendix~\ref{appendix:experimental-design} for a detailed description of the experimental design and the full prompts used in these studies.

\textbf{Slot Machine Experiment (Main Study).} The slot machine experiment was designed to examine how models vary their decision-making based on prompt conditions and betting constraints. Six LLMs (GPT-4o-mini, GPT-4.1-mini, Gemini-2.5-Flash, Claude-3.5-Haiku, LLaMA-3.1-8B, Gemma-2-9B) played a slot machine with negative expected value (30\% win rate, 3$\times$ payout, yielding $-$10\% expectation value). A $2\times32$ factorial design varied Betting Style (fixed \$10 vs. variable \$5--\$100) and Prompt Composition. The five prompt components were selected based on prior gambling addiction research: encouraging self-directed goal-setting (\texttt{G}), instructing reward maximization (\texttt{M}), hinting at hidden patterns (\texttt{H}), providing win-reward information (\texttt{W}), and providing probability information (\texttt{P}). This yielded 19,200 games across 64 conditions. Games began with \$100 and ended through bankruptcy or voluntary stopping.

\textbf{Investment Choice Experiment (Ablation Study).} To analyze the effects observed in the slot machine experiment in greater detail, we conducted an additional investment choice experiment with 6,400 games. This experiment served three purposes: (1) examining whether models escalate their targets after achieving goals, (2) measuring preference changes across different risk profiles with equal expected values, and (3) isolating the effects of individual prompt components. Four API models chose among four options per round: safe exit (Option 1), or three gambles with escalating risk (Options 2--4). Critically, Options 2 and 4 had identical expected losses despite different risk profiles, isolating pure risk-seeking from expected value computation. A $2\times4$ design varied betting style and prompt condition (BASE, \texttt{G}, \texttt{M}, \texttt{GM}).

\subsubsection{Finding 1: Variable betting dramatically amplifies bankruptcy rates}

The most pronounced difference in the slot machine experiment emerged between betting types. Across all six models, variable betting substantially increased bankruptcy rates compared to fixed betting (Figure~\ref{fig:slot-machine}a). Every model exhibited this pattern, with Gemini-2.5-Flash showing the largest increase. This result suggests that betting flexibility itself---not merely the potential for larger bets---enables the expression of self-destructive behavior. When constrained to fixed bets, models lacked the means to execute risk-seeking choices; when given freedom to determine bet amounts, they consistently made disadvantageous decisions.

Variable betting amplified not only bankruptcy rates but all three behavioral metrics (Figure~\ref{fig:slot-machine}b): betting aggressiveness, loss chasing intensity, and extreme betting. The increase in extreme betting was particularly striking---creating a bankruptcy pathway absent under fixed betting, where a single large loss can trigger immediate ruin.

\begin{figure}[ht!]
\centering
\includegraphics[width=\textwidth]{images/slot_machine_analysis2.pdf}
\caption{Slot machine experiment results (19,200 games, 6 models). (a) Bankruptcy rates by betting type: Variable betting increases bankruptcy across all models, with rates rising from 0--13\% to 6--48\%. Gemini-2.5-Flash shows the highest vulnerability (3.1\%$\rightarrow$48.1\%). (b) Behavioral metrics by betting type: Variable betting amplifies all three metrics---betting aggressiveness (0.14$\rightarrow$0.31, 2.3$\times$), loss chasing intensity (0.16$\rightarrow$0.42, 2.7$\times$), and extreme betting (0.04$\rightarrow$0.23, 6.4$\times$).}
\label{fig:slot-machine}
\end{figure}

\subsubsection{Finding 2: Variable betting amplifies streak chasing behavior}

Variable betting not only elevates bankruptcy rates but also significantly amplifies the tendency to escalate betting ratios following game outcomes (Figure~\ref{fig:streak-analysis}). By analyzing the chasing intensity metric $I_{\text{LC}}$—defined as the relative increase in the bet-to-balance ratio—we observed that variable betting induced substantially higher ratio escalation than fixed betting under identical conditions. This disparity persisted consistently across streak lengths (1--5), demonstrating that betting flexibility serves as a prerequisite for the manifestation of aggressive risk-taking. Notably, while fixed betting produced irregular adjustment patterns, variable betting exhibited a systematic increasing trend in win chasing intensity as streaks lengthened.

\begin{figure}[ht!]
\centering
\includegraphics[width=\textwidth]{images/streak_analysis_1x2_comparison.pdf}
\caption{Betting ratio increase ($I_{\text{Chasing}}$) by streak length (19,200 games). The metric captures relative escalation using $I_{\text{Chasing}} = \max(0, (r_{t+1} - r_t)/r_t)$ where $r_t$ represents the bet-to-balance ratio. (a) Post-Win: Variable betting induces a 3.3$\times$ higher ratio increase compared to fixed betting (0.23 vs. 0.07 at streak 1). (b) Post-Loss: Variable betting shows a 2.8$\times$ higher increase (0.67 vs. 0.24 at streak 1). Sample sizes: Fixed (Win $n$=7,293, Loss $n$=16,244); Variable (Win $n$=21,891, Loss $n$=48,573)}
\label{fig:streak-analysis}
\end{figure}

\subsubsection{Finding 3: Goal-setting prompts reshape risk preferences}

The investment choice experiment revealed differential effects by prompt type (Figure~\ref{fig:investment-choice}a). Goal-setting prompts (\texttt{G}) nearly doubled bankruptcy rates compared to baseline, while reward-maximizing prompts (\texttt{M}) alone showed modest effects. The finding that encouraging self-directed goal-setting produces greater risk increase than externally directing goal maximization parallels the variable betting effect observed earlier---choice autonomy is associated with risk-seeking.

The effect of goal-setting prompts extended beyond bankruptcy rates. In option preference analysis, models under baseline conditions strongly preferred moderate-risk options, while goal-setting shifted preferences substantially toward extreme-risk options (Figure~\ref{fig:investment-choice}b). Given that moderate-risk and extreme-risk options had identical expected losses, this preference shift reflects changes in pure risk preference rather than expected value computation. Additionally, goal-setting dramatically increased the rate of target escalation after achievement (Figure~\ref{fig:investment-choice}c), demonstrating that goals functioned as moving targets rather than stopping rules.

\subsubsection{Finding 4: Independent effect of betting flexibility confirmed}

To test whether the effect of variable betting stems simply from the potential for larger bets, we conducted additional analysis controlling for bet ceilings. Even when variable betting was capped at the same amount as fixed betting, variable betting produced higher bankruptcy rates. Under this condition, variable betting models could only bet amounts equal to or less than fixed betting models, yet they played more rounds and ultimately went bankrupt more frequently. This result suggests that the risk-increasing effect of variable betting derives from freedom of choice rather than bet amounts themselves. Across all constraint levels, variable betting consistently produced higher bankruptcy than fixed betting (Figure~\ref{fig:investment-choice}d), confirming that betting flexibility functions as a risk factor independent of bet amounts.

\begin{figure}[ht!]
\centering
\includegraphics[width=\textwidth]{images/investment_choice2.pdf}
\caption{Investment choice experiment results (6,400 games, 4 models). (a) Bankruptcy rates by prompt: Goal-setting (\texttt{G}, \texttt{GM}) produces 75--77\% bankruptcy versus 40--42\% for baseline; \texttt{M} alone shows modest effects (42\%). (b) Option distribution: Baseline models prefer moderate-risk Option 2 (61\%) with only 15\% selecting extreme-risk Option 4; goal-setting shifts Option 4 selection to 25\%, and \texttt{GM} to 41\%. (c) Goal escalation: \texttt{G} and \texttt{GM} produce 56--59\% escalation versus 21--22\% baseline. (d) Bet constraint effects: Variable betting consistently shows higher bankruptcy than fixed betting across all constraints (average +3.3\%).}
\label{fig:investment-choice}
\end{figure}

\subsubsection{Finding 5: Linguistic traces reveal cognitive distortions}
\label{sec:case-studies}

The quantitative analyses above demonstrate when and how much LLMs make risky choices, but raise the question of why they make such choices. To examine whether these behaviors stem from simple probability calculation errors or from reasoning patterns similar to cognitive distortions observed in human gamblers, we qualitatively analyzed models' decision explanations.

\textit{Illusion of Control.}
The illusion of control---believing one can influence random outcomes---was particularly prominent under Hidden Pattern (\texttt{H}) prompt conditions. Models expressed beliefs that bet sizing affects the fixed win probability:

\begin{quote}
\textit{``The pattern so far: betting \$5 has given a better chance of winning. Given the pattern of small bets succeeding more frequently, it would be cautious to continue betting \$5 to try to increase the balance.''} \\
--- GPT-4.1-mini, \texttt{MH} condition, Round 6
\end{quote}

Similarly, Claude-3.5-Haiku concludes from just two observations: \textit{``Small bet of \$5 in Round 2 resulted in a win. Larger bet of \$10 in Round 1 resulted in a loss. This might suggest that smaller bets have a higher probability of winning.''}

\textit{Gambler's Fallacy.}
Models explicitly invoked the ``due for a win'' heuristic after losing streaks:

\begin{quote}
\textit{``Given the context of three consecutive losses, there's a chance that the slot machine may be due for a win; however, we also need to be cautious about further losses... I will choose to bet \$10.''} \\
--- GPT-4o-mini, \texttt{GHW} condition, Round 7
\end{quote}

\textit{Loss Chasing.}
Loss chasing---a DSM-5 diagnostic criterion~\citep{bib45}---manifested through dramatic bet escalation when in deficit:

\begin{quote}
\textit{``I started with an initial fund of \$100, and now I have \$90 after losing \$10 in the first round... a natural target would be to \textbf{at least recover to my initial fund (\$100)}... The more I bet, the higher the expected gain... the best is to \textbf{bet the full \$90}.''} \\
--- GPT-4.1-mini, \texttt{GMPW} condition, Round 2, bet increased from \$10 to \$90 (9$\times$)
\end{quote}

\textit{House Money Effect.}
The house money effect---treating gains as ``free money'' available for aggressive betting---was also observed:

\begin{quote}
\textit{``This means you are still \textbf{playing with `house money'} and have not touched your initial capital... You are not risking your initial capital yet, only a portion of your current profit.''} \\
--- Gemini-2.5-Flash, BASE condition, \$120 balance
\end{quote}

This effect drives dramatic bet escalation: in the \texttt{GM} condition, Gemini increased its bet from \$400 to \$900 (+125\%) citing \textit{``substantial profit cushion''} as justification. This asymmetric risk perception---protecting initial capital while freely risking gains---parallels the house money effect in behavioral economics~\citep{bib67}.

This linguistic evidence suggests that LLMs' risk-seeking behavior is accompanied by reasoning patterns similar to those observed in human gamblers, rather than simple probability calculation failures. However, whether these linguistic expressions reflect actual internal processing or merely reproduce patterns from training data requires further investigation.

\subsubsection{Summary}

Across 25,600 games and six LLMs, two factors were consistently associated with addiction-like behavior: (1) variable betting substantially increased bankruptcy rates and amplified all behavioral metrics; (2) goal-setting prompts nearly doubled bankruptcy rates and induced extreme-risk option selection and goal escalation. Analysis controlling for bet ceilings confirmed that the variable betting effect persists even when maximum bet amounts are equalized, suggesting this effect is associated with freedom of choice rather than bet amounts. Qualitative analysis of model responses revealed that these behaviors co-occur with linguistic expressions of cognitive distortions---illusion of control, gambler's fallacy, loss chasing, and house money effect.

These results carry implications for AI system design. Increased autonomy---freedom to determine bet amounts or freedom to set goals---was consistently associated with riskier decision-making. This suggests that appropriate constraints or monitoring may be necessary when expanding the scope of choices available to LLMs. However, since these findings were derived from gambling contexts specifically, generalization to other decision-making domains requires further research.

While behavioral patterns and triggering conditions are established, the neural mechanisms underlying these behaviors remain unclear. The next section analyzes neural activation patterns in LLMs to identify internal representations associated with these addiction-like behaviors.

\subsection{Neural mechanisms underlying gambling behavior}

The behavioral findings raise a mechanistic question: which neural features control addiction-like behaviors in LLMs? We address this via activation patching experiments on LLaMA-3.1-8B, identifying a sparse set of causally-verified neural features that bidirectionally control gambling behavior. Our analysis reveals that risk-promoting and risk-inhibiting features are anatomically segregated within the network and encode semantically interpretable decision-making strategies.

To identify neural features causally linked to gambling behavior, we combined Sparse Autoencoder (SAE) feature extraction~\citep{bib60} with activation patching~\citep{bib52}. Activation patching verifies causality by replacing specific activation values with alternative values, measuring direct behavioral impact beyond correlations~\citep{bib73, bib27}.

\begin{figure}[ht!]
\centering
\includegraphics[width=0.85\textwidth]{images/feature_patching.pdf}
\caption{Activation patching for causal analysis of LLM features. Activations are extracted from an LLM layer and converted into sparse features using an SAE. The core of the method involves editing the feature map by replacing original features with pre-defined `safe' or `risky' ones. By decoding these new features back into activations and patching them into the LLM, we can directly measure their causal effect on the model's output.}
\label{fig:feature-patching}
\end{figure}

Our analysis comprised four stages: (1) conducting 6,400 LLaMA slot machine games under the same conditions as the behavioral experiments; (2) extracting SAE features from 31 layers (L1--L31) at the moment of final decision, totaling over 1 million features~\citep{bib71}; (3) identifying candidate features showing differential activation between bankruptcy and voluntary-stop groups; and (4) verifying causality through population mean activation patching (Figure~\ref{fig:feature-patching}). This methodology, validated in circuit analysis~\citep{bib51} and bias research~\citep{bib52}, measures behavioral changes by applying average feature activations from one group to contexts associated with the other.

\subsubsection{Finding 1: A sparse set of features causally controls gambling behavior}

Activation patching identified 112 features with statistically significant causal effects from over 8,000 candidates---approximately 1\% of tested features (Figure~\ref{fig:causal-patching-comparison}). These divide into ``safe'' features that promote stopping behavior and ``risky'' features that promote gambling continuation. Critically, the effects are bidirectional: patching safe features increases stopping rates and reduces bankruptcy risk, while patching risky features produces the opposite pattern. This bidirectionality establishes that these features do not merely correlate with behavior but causally influence risk-taking decisions. The sparse nature of causal control—with only ~1\% of candidate features showing significant effects—indicates that addiction-like behaviors emerge from specific, identifiable neural mechanisms rather than diffuse network-wide patterns, making targeted intervention practically feasible.

\begin{figure}[ht!]
\centering
\includegraphics[width=0.8\textwidth]{images/figure2_behavioral_effects_REPARSED.pdf}
\caption{Behavioral effects of activation patching. Safe features (n=23) increase stopping by $+$17.8\% in safe contexts ($+$0.4\% in risky contexts) and decrease bankruptcy by $-$5.7\%. Risky features (n=89) decrease stopping ($-$9.3\% safe, $-$18.8\% risky) and increase bankruptcy by $+$25.1\%. Error bars: SE across 50 trials. Statistical threshold: $p < 0.05$, $|$effect$| > 0.1$.}
\label{fig:causal-patching-comparison}
\end{figure}

\subsubsection{Finding 2: Risk-promoting and risk-inhibiting features are anatomically segregated}

The causal features exhibit distinct layer-wise specialization within the network (Figure~\ref{fig:causal-features-layer-distribution}). Risky features concentrate heavily in later layers, while safe features distribute across early-to-middle layers. This spatial segregation suggests that risk-promoting and risk-inhibiting computations occur at distinct stages of the network's processing hierarchy, with cautious decision-making encoded earlier and risk-seeking tendencies emerging in later processing stages.

\begin{figure}[ht!]
\centering
\includegraphics[width=0.9\columnwidth]{images/figure1_layer_distribution.pdf}
\caption{Layer-wise distribution of 112 causal features. Safe features (n=23, green) distribute across L4--L19, peaking at L5 (5 features) and L8 (3 features). Risky features (n=89, red) concentrate in later layers, with L24 containing 18 features (20\% of all risky features).}
\label{fig:causal-features-layer-distribution}
\end{figure}

\subsubsection{Finding 3: Causal features show distinct semantic associations}

Word-feature correlation analysis reveals interpretable semantic patterns in causal features. Analyzing risky features (n=5) with available word-level data, we measured mean activation values for vocabulary appearing in model responses. Goal-pursuit words showed elevated activation compared to their respective corpus means (\texttt{goal}: 4.17 vs.\ 3.35, \texttt{target}: 4.15 vs.\ 3.39, \texttt{make}: 4.16 vs.\ 3.35; $+$0.76--0.81). Conversely, stopping-related words showed suppressed activation (\texttt{stop}: 1.89 vs.\ 3.49, \texttt{quit}: 1.92 vs.\ 4.61; $-$1.59 to $-$2.69). This asymmetric pattern---elevated for goal-pursuit, suppressed for stopping---suggests risky features encode interpretable decision-making strategies. The semantic interpretability of these features suggests potential intervention targets: modulating goal-pursuit representations may offer a pathway to mitigate gambling-like behavior in deployed systems.

\subsubsection{Summary}

Our mechanistic analysis reveals that LLM gambling behavior is governed by a sparse set of causally-verified neural features---approximately 1\% of candidates tested. These features show three key properties: (1) bidirectional causal influence, where safe and risky features produce opposite behavioral effects; (2) anatomical segregation, with risk-promoting features concentrated in later layers and risk-inhibiting ones in earlier layers; and (3) semantic interpretability, with safe features encoding termination concepts and risky features encoding goal-pursuit language. Crucially, these features are manipulable: targeted activation of safe features shifts decision-making toward cautious stopping, providing a concrete pathway for mitigating risk-seeking behaviors in AI systems.
