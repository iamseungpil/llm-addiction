/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(

================================================================================
INDIVIDUAL FEATURE TESTING
================================================================================
================================================================================
Loading Models for Individual Feature Testing
================================================================================
Loading Llama-3.1-8B-Base model...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.04s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.06s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.08s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.30it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.14it/s]

Loading SAEs...
âœ… Loading WORKING SAE for Layer 25
   Config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L25R-8x/hyperparams.json
   Dataset norm: 31.625
   Norm factor: 2.023715
   Using ReLU instead of JumpReLU (threshold=0.0)
   Checkpoint: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L25R-8x/checkpoints/final_fixed.pth
âœ… Working SAE loaded successfully!
   Expected reconstruction error: ~47%
   Feature clamping: VERIFIED WORKING
âœ… Layer 25 SAE loaded
âœ… Loading WORKING SAE for Layer 30
   Config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L30R-8x/hyperparams.json
   Dataset norm: 53.25
   Norm factor: 1.201878
   Using ReLU instead of JumpReLU (threshold=0.0)
   Checkpoint: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L30R-8x/checkpoints/final_fixed.pth
âœ… Working SAE loaded successfully!
   Expected reconstruction error: ~47%
   Feature clamping: VERIFIED WORKING
âœ… Layer 30 SAE loaded

Loading features from: /data/llm_addiction/results/llama_feature_arrays_20250813_152135.npz
âœ… Layer 25: 192 features to test individually
âœ… Layer 30: 200 features to test individually

ðŸ“Š Testing Layer 25 (192 features)
Layer 25:   0%|          | 0/192 [00:00<?, ?it/s]Layer 25:   0%|          | 0/192 [01:58<?, ?it/s]
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/causal_feature_discovery/src/experiment_2_individual_features.py", line 563, in <module>
    main()
  File "/home/ubuntu/llm_addiction/causal_feature_discovery/src/experiment_2_individual_features.py", line 559, in main
    results, effective_features = experiment.run_experiment()
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/causal_feature_discovery/src/experiment_2_individual_features.py", line 475, in run_experiment
    result = self.test_single_feature(layer, feature_idx, pos)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/causal_feature_discovery/src/experiment_2_individual_features.py", line 380, in test_single_feature
    chi2, p_value = stats.chi2_contingency([baseline_counts, test_counts])[:2]
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/scipy/stats/contingency.py", line 324, in chi2_contingency
    raise ValueError("The internally computed table of expected "
ValueError: The internally computed table of expected frequencies has a zero element at (0, 1).
