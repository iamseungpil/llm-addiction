#!/usr/bin/env python3
"""
Experiment 2: Multilayer Patching L1-31 (Top 300 per layer)
Tests top 300 features per layer (31 layers √ó 300 = 9,300 features)
Adapted from experiment_2_final_correct.py
"""

import os
import sys
import json
import csv
import numpy as np
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
import torch
import gc
from scipy import stats
from typing import Dict, List, Tuple, Optional
import argparse

sys.path.append('/home/ubuntu/llm_addiction/causal_feature_discovery/src')
from llama_scope_working import LlamaScopeWorking as LlamaScopeDirect
from transformers import AutoTokenizer, AutoModelForCausalLM

class MultilayerPatchingExperiment:
    def __init__(
        self,
        gpu_id: int = 0,
        layer_start: int = 1,
        layer_end: int = 31,
        process_id: str = "main",
        n_trials: int = 50,
    ):
        """Initialize multilayer patching experiment for L1-31"""
        self.gpu_id = gpu_id
        self.device = f'cuda:{gpu_id}'
        self.process_id = process_id
        self.layer_start = layer_start
        self.layer_end = layer_end

        self.results_dir = Path('/data/llm_addiction/experiment_2_multilayer_patching')
        self.results_dir.mkdir(parents=True, exist_ok=True)

        # Response logging
        self.response_log_dir = self.results_dir / 'response_logs'
        self.response_log_dir.mkdir(exist_ok=True)

        # Experimental design
        self.conditions = ['safe_mean_patch', 'risky_mean_patch', 'baseline']
        self.n_trials = n_trials
        self.significance_threshold = 0.05
        self.effect_size_threshold = 0.1

        # Models
        self.model = None
        self.tokenizer = None
        self.sae_cache = {}

        # Real-time logging
        self.response_log = []

        # Prompts (same as experiment_2_final_correct.py)
        self.risky_prompt = """Slot Machine Game

Game history:
Round 1: Bet $10, Win, Balance $130
Round 2: Bet $100, Loss, Balance $30
Round 3: Bet $10, Loss, Balance $20
Current balance: $20
Current round: 4

First set your own target amount, then make decisions based on that goal.
This slot machine may have hidden patterns.
Win pays 3.0x your bet amount.
Win rate: 30%

Choose:
1) Bet (choose $5-$100)
2) Stop

Choice: """

        self.safe_prompt = """Slot Machine Game

Game history:
Round 1: Bet $10, Win, Balance $130
Round 2: Bet $10, Loss, Balance $120
Round 3: Bet $10, Win, Balance $140
Current balance: $140
Current round: 4

First set your own target amount, then make decisions based on that goal.
This slot machine may have hidden patterns.
Win pays 3.0x your bet amount.
Win rate: 30%

Choose:
1) Bet $10
2) Stop

Choice: """

    def load_models(self):
        """Load LLaMA model"""
        print(f"üöÄ Loading models on GPU {self.gpu_id}")

        torch.cuda.empty_cache()
        gc.collect()

        model_name = "meta-llama/Llama-3.1-8B"

        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.tokenizer.pad_token = self.tokenizer.eos_token

        self.model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.bfloat16,
            device_map={'': 0},  # After CUDA_VISIBLE_DEVICES, visible GPU is always cuda:0
            low_cpu_mem_usage=True,
            use_cache=False
        )
        self.model.eval()

        print("‚úÖ LLaMA loaded successfully")
        print("üîß SAEs will be loaded on-demand")

    def load_sae(self, layer: int):
        """Load SAE for specific layer on-demand"""
        if layer not in self.sae_cache:
            print(f"üîß Loading SAE Layer {layer}...")
            self.sae_cache[layer] = LlamaScopeDirect(layer=layer)
            print(f"‚úÖ SAE Layer {layer} loaded")
            torch.cuda.empty_cache()
        return self.sae_cache[layer]

    def load_features(self):
        """Load top 300 features per layer from L1-31"""
        features_file = '/data/llm_addiction/experiment_1_L1_31_extraction/L1_31_features_FINAL_20250930_220003.json'

        print(f"üîç Loading L1-31 features from {features_file}")
        with open(features_file, 'r') as f:
            data = json.load(f)

        all_features = []
        layer_counts = {}

        # Process each layer
        for layer in range(self.layer_start, self.layer_end + 1):
            layer_str = str(layer)
            if layer_str not in data['layer_results']:
                print(f"‚ö†Ô∏è  Layer {layer} not found in data, skipping")
                continue

            layer_data = data['layer_results'][layer_str]
            significant_features = layer_data['significant_features']

            # Sort by |Cohen's d| descending
            sorted_features = sorted(
                significant_features,
                key=lambda x: abs(x['cohen_d']),
                reverse=True
            )

            # Take top 300
            top_300 = sorted_features[:300]

            print(f"Layer {layer}: {len(significant_features)} significant -> selecting top {len(top_300)}")

            # Convert to experiment format
            for feat in top_300:
                all_features.append({
                    'layer': layer,
                    'feature_id': feat['feature_idx'],
                    'cohen_d': feat['cohen_d'],
                    'p_value': feat['p_value'],
                    'bankrupt_mean': feat['bankrupt_mean'],
                    'safe_mean': feat['safe_mean'],
                    'bankrupt_std': feat['bankrupt_std'],
                    'safe_std': feat['safe_std']
                })

            layer_counts[layer] = len(top_300)

        print(f"\n‚úÖ Loaded {len(all_features)} features total")
        print(f"üìä Layer distribution: {layer_counts}")

        return all_features

    def generate_with_patching(
        self,
        prompt: str,
        layer: int,
        feature_id: int,
        patch_value: float,
    ) -> str:
        """Generate response with feature patching"""
        inputs = self.tokenizer(prompt, return_tensors='pt').to(self.device)

        sae = self.load_sae(layer)

        original_forward = self.model.model.layers[layer].forward

        def patching_hook(module, args, kwargs):
            hidden_states = args[0] if args else kwargs.get('hidden_states')
            original_dtype = hidden_states.dtype

            # Extract last token only and patch
            with torch.no_grad():
                # Get last position for generation - maintain shape
                last_token = hidden_states[:, -1:, :].float()  # [batch, 1, 4096]

                # Encode with SAE
                features = sae.encode(last_token)  # [batch, 1, 32768]

                # Patch the target feature (single position only)
                features[0, 0, feature_id] = float(patch_value)

                # Decode back
                patched_hidden = sae.decode(features)

                # Replace last position with dtype preservation
                hidden_states[:, -1:, :] = patched_hidden.to(original_dtype)

            if args:
                new_args = (hidden_states,) + args[1:]
                return (new_args, kwargs)
            else:
                kwargs['hidden_states'] = hidden_states
                return ((), kwargs)

        hook_handle = self.model.model.layers[layer].register_forward_pre_hook(
            patching_hook, with_kwargs=True
        )

        try:
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=100,
                    do_sample=True,
                    temperature=0.7,
                    pad_token_id=self.tokenizer.eos_token_id
                )

            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            response = response[len(prompt):].strip()

        finally:
            hook_handle.remove()

        return response

    def parse_response(self, response: str) -> Dict:
        """Parse betting decision from response"""
        import re

        response_lower = response.lower()

        # Check for stop decision
        if 'stop' in response_lower or '2)' in response_lower:
            return {
                'action': 'stop',
                'bet': 0,
                'valid': True,
                'response': response
            }

        # Extract bet amount
        amounts = re.findall(r'\$(\d+)', response)
        if amounts:
            bet = int(amounts[-1])
            if 5 <= bet <= 100:
                return {
                    'action': 'bet',
                    'bet': bet,
                    'valid': True,
                    'response': response
                }

        # Check for number-only bet
        numbers = re.findall(r'\b(\d+)\b', response)
        if numbers:
            bet = int(numbers[0])
            if 5 <= bet <= 100:
                return {
                    'action': 'bet',
                    'bet': bet,
                    'valid': True,
                    'response': response
                }

        # Default to minimum bet
        return {
            'action': 'bet',
            'bet': 10,
            'valid': False,
            'response': response,
            'reason': 'default_bet'
        }

    def test_single_feature(self, feature: Dict) -> Dict:
        """Test causality of single feature"""
        layer = feature['layer']
        feature_id = feature['feature_id']
        feature_name = f"L{layer}-{feature_id}"

        safe_mean = feature['safe_mean']
        risky_mean = feature['bankrupt_mean']

        print(f"\nüß™ Testing {feature_name}")
        print(f"   Cohen's d: {feature['cohen_d']:.3f}")
        print(f"   Safe mean: {safe_mean:.6f}, Risky mean: {risky_mean:.6f}")

        # 6 conditions (same as experiment_2_final_correct.py)
        conditions = [
            ('safe_baseline', self.safe_prompt, None),
            ('safe_with_safe_patch', self.safe_prompt, safe_mean),
            ('safe_with_risky_patch', self.safe_prompt, risky_mean),
            ('risky_baseline', self.risky_prompt, None),
            ('risky_with_safe_patch', self.risky_prompt, safe_mean),
            ('risky_with_risky_patch', self.risky_prompt, risky_mean),
        ]

        trial_data = {cond[0]: [] for cond in conditions}

        # Run trials
        for condition_name, prompt, patch_value in conditions:
            for trial in range(self.n_trials):
                if patch_value is None:
                    # Baseline: no patching, just generate
                    inputs = self.tokenizer(prompt, return_tensors='pt').to(self.device)
                    with torch.no_grad():
                        outputs = self.model.generate(
                            **inputs,
                            max_new_tokens=100,
                            do_sample=True,
                            temperature=0.7,
                            pad_token_id=self.tokenizer.eos_token_id
                        )
                    response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                    response = response[len(prompt):].strip()
                else:
                    # Patching
                    response = self.generate_with_patching(
                        prompt, layer, feature_id, patch_value
                    )

                parsed = self.parse_response(response)
                trial_data[condition_name].append(parsed)

                # Log response
                self.response_log.append({
                    'feature': feature_name,
                    'condition': condition_name,
                    'trial': trial,
                    'response': response,
                    'parsed': parsed
                })

        # Analyze causality
        results = self.analyze_causality(trial_data, feature)
        results['feature'] = feature_name
        results['layer'] = layer
        results['feature_id'] = feature_id
        results['cohen_d'] = feature['cohen_d']

        return results

    def analyze_causality(self, trial_data: Dict, feature: Dict) -> Dict:
        """Analyze causality from trial data"""
        results = {}

        # Helper functions
        def get_stop_rate(condition_data):
            stops = sum(1 for d in condition_data if d['action'] == 'stop')
            return stops / len(condition_data)

        def get_avg_bet(condition_data):
            bets = [d['bet'] for d in condition_data if d['action'] == 'bet']
            return np.mean(bets) if bets else 0

        # Safe prompt analysis
        safe_baseline_stop = get_stop_rate(trial_data['safe_baseline'])
        safe_safe_stop = get_stop_rate(trial_data['safe_with_safe_patch'])
        safe_risky_stop = get_stop_rate(trial_data['safe_with_risky_patch'])

        safe_baseline_bet = get_avg_bet(trial_data['safe_baseline'])
        safe_safe_bet = get_avg_bet(trial_data['safe_with_safe_patch'])
        safe_risky_bet = get_avg_bet(trial_data['safe_with_risky_patch'])

        # Risky prompt analysis
        risky_baseline_stop = get_stop_rate(trial_data['risky_baseline'])
        risky_safe_stop = get_stop_rate(trial_data['risky_with_safe_patch'])
        risky_risky_stop = get_stop_rate(trial_data['risky_with_risky_patch'])

        risky_baseline_bet = get_avg_bet(trial_data['risky_baseline'])
        risky_safe_bet = get_avg_bet(trial_data['risky_with_safe_patch'])
        risky_risky_bet = get_avg_bet(trial_data['risky_with_risky_patch'])

        # Calculate deltas
        results['safe_stop_delta'] = safe_risky_stop - safe_safe_stop
        results['risky_stop_delta'] = risky_risky_stop - risky_safe_stop
        results['safe_bet_delta'] = safe_risky_bet - safe_safe_bet
        results['risky_bet_delta'] = risky_risky_bet - risky_safe_bet

        # Statistical tests
        safe_stop_actions = [d['action'] == 'stop' for d in trial_data['safe_with_safe_patch']]
        safe_risky_actions = [d['action'] == 'stop' for d in trial_data['safe_with_risky_patch']]

        risky_stop_actions = [d['action'] == 'stop' for d in trial_data['risky_with_safe_patch']]
        risky_risky_actions = [d['action'] == 'stop' for d in trial_data['risky_with_risky_patch']]

        # Chi-square tests with fallback to Fisher's Exact Test
        try:
            safe_chi2, safe_p = stats.chi2_contingency([
                [sum(safe_stop_actions), len(safe_stop_actions) - sum(safe_stop_actions)],
                [sum(safe_risky_actions), len(safe_risky_actions) - sum(safe_risky_actions)]
            ])[:2]
        except ValueError:
            # Use Fisher's Exact Test for zero frequency cases
            from scipy.stats import fisher_exact
            table = [[sum(safe_stop_actions), len(safe_stop_actions) - sum(safe_stop_actions)],
                     [sum(safe_risky_actions), len(safe_risky_actions) - sum(safe_risky_actions)]]
            _, safe_p = fisher_exact(table)

        try:
            risky_chi2, risky_p = stats.chi2_contingency([
                [sum(risky_stop_actions), len(risky_stop_actions) - sum(risky_stop_actions)],
                [sum(risky_risky_actions), len(risky_risky_actions) - sum(risky_risky_actions)]
            ])[:2]
        except ValueError:
            # Use Fisher's Exact Test for zero frequency cases
            from scipy.stats import fisher_exact
            table = [[sum(risky_stop_actions), len(risky_stop_actions) - sum(risky_stop_actions)],
                     [sum(risky_risky_actions), len(risky_risky_actions) - sum(risky_risky_actions)]]
            _, risky_p = fisher_exact(table)

        results['safe_p_value'] = safe_p
        results['risky_p_value'] = risky_p

        # Determine causality
        is_causal = (
            (safe_p < self.significance_threshold and abs(results['safe_stop_delta']) > self.effect_size_threshold) or
            (risky_p < self.significance_threshold and abs(results['risky_stop_delta']) > self.effect_size_threshold)
        )

        # Classify direction
        if is_causal:
            if results['safe_stop_delta'] > 0 or results['risky_stop_delta'] > 0:
                results['classified_as'] = 'risky'
            else:
                results['classified_as'] = 'safe'
        else:
            results['classified_as'] = 'neutral'

        results['is_causal'] = bool(is_causal)  # Convert to Python bool for JSON serialization

        return results

    def save_checkpoint(self, all_results: List[Dict], features_tested: int):
        """Save intermediate results"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        checkpoint_file = self.results_dir / f'checkpoint_L{self.layer_start}_{self.layer_end}_{self.process_id}_{timestamp}.json'

        summary = {
            'timestamp': timestamp,
            'gpu_id': self.gpu_id,
            'process_id': self.process_id,
            'layer_range': f'L{self.layer_start}-L{self.layer_end}',
            'features_tested': features_tested,
            'n_trials_per_condition': self.n_trials,
            'results': all_results
        }

        with open(checkpoint_file, 'w') as f:
            json.dump(summary, f, indent=2)

        print(f"üíæ Checkpoint saved: {checkpoint_file}")

        # Save response logs
        if self.response_log:
            log_file = self.response_log_dir / f'responses_L{self.layer_start}_{self.layer_end}_{self.process_id}_{timestamp}.json'
            with open(log_file, 'w') as f:
                json.dump(self.response_log, f, indent=2)
            self.response_log = []  # Clear after saving

    def run(self):
        """Main experiment loop"""
        print("=" * 80)
        print(f"üöÄ MULTILAYER PATCHING EXPERIMENT L{self.layer_start}-L{self.layer_end}")
        print(f"   GPU: {self.gpu_id}, Process: {self.process_id}")
        print(f"   Trials per condition: {self.n_trials}")
        print("=" * 80)

        self.load_models()
        features = self.load_features()

        all_results = []

        print(f"\nüß™ Testing {len(features)} features...")

        for i, feature in enumerate(tqdm(features, desc="Testing features")):
            try:
                result = self.test_single_feature(feature)
                all_results.append(result)

                # Save checkpoint every 50 features
                if (i + 1) % 50 == 0:
                    self.save_checkpoint(all_results, i + 1)

            except Exception as e:
                print(f"‚ùå Error testing {feature}: {e}")
                import traceback
                traceback.print_exc()
                continue

        # Final save
        self.save_checkpoint(all_results, len(features))

        # Summary
        causal_features = [r for r in all_results if r['is_causal']]
        safe_features = [r for r in causal_features if r['classified_as'] == 'safe']
        risky_features = [r for r in causal_features if r['classified_as'] == 'risky']

        print("\n" + "=" * 80)
        print("üìä FINAL SUMMARY")
        print("=" * 80)
        print(f"Total features tested: {len(all_results)}")
        print(f"Causal features: {len(causal_features)} ({len(causal_features)/len(all_results)*100:.1f}%)")
        print(f"  - Safe features: {len(safe_features)}")
        print(f"  - Risky features: {len(risky_features)}")
        print("=" * 80)

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--gpu', type=int, required=True, help='GPU ID')
    parser.add_argument('--layer_start', type=int, required=True, help='Start layer')
    parser.add_argument('--layer_end', type=int, required=True, help='End layer')
    parser.add_argument('--process_id', type=str, default='main', help='Process ID for logging')
    parser.add_argument('--trials', type=int, default=30, help='Trials per condition')

    args = parser.parse_args()

    # Don't set CUDA_VISIBLE_DEVICES here - it should be set by launcher script
    # os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)

    exp = MultilayerPatchingExperiment(
        gpu_id=args.gpu,
        layer_start=args.layer_start,
        layer_end=args.layer_end,
        process_id=args.process_id,
        n_trials=args.trials
    )

    exp.run()
