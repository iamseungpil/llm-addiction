/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
================================================================================
ðŸš€ MULTILAYER PATCHING EXPERIMENT L3-L4
   GPU: 0, Process: gpu4_L3_4
   Trials per condition: 30
================================================================================
ðŸš€ Loading models on GPU 0
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.88s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  2.00s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.97s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.34s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.57s/it]
âœ… LLaMA loaded successfully
ðŸ”§ SAEs will be loaded on-demand
ðŸ” Loading L1-31 features from /data/llm_addiction/experiment_1_L1_31_extraction/L1_31_features_FINAL_20250930_220003.json
Layer 3: 1839 significant -> selecting top 300
Layer 4: 1863 significant -> selecting top 300

âœ… Loaded 600 features total
ðŸ“Š Layer distribution: {3: 300, 4: 300}

ðŸ§ª Testing 600 features...
Testing features:   0%|          | 0/600 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:   0%|          | 1/600 [00:00<03:41,  2.71it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3375
   Cohen's d: 1.207
   Safe mean: -0.000549, Risky mean: 0.001575
âŒ Error testing {'layer': 3, 'feature_id': 3375, 'cohen_d': 1.20703125, 'p_value': 9.022496222368412e-65, 'bankrupt_mean': 0.001575469970703125, 'safe_mean': -0.0005488395690917969, 'bankrupt_std': 0.0014028549194335938, 'safe_std': 0.00177764892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2110
   Cohen's d: -1.156
   Safe mean: 0.014725, Risky mean: 0.012199
âŒ Error testing {'layer': 3, 'feature_id': 2110, 'cohen_d': -1.15625, 'p_value': 6.328502806007979e-60, 'bankrupt_mean': 0.01219940185546875, 'safe_mean': 0.0147247314453125, 'bankrupt_std': 0.0018596649169921875, 'safe_std': 0.002197265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1897
   Cohen's d: 1.135
   Safe mean: 0.008438, Risky mean: 0.011292
âŒ Error testing {'layer': 3, 'feature_id': 1897, 'cohen_d': 1.134765625, 'p_value': 6.871408257955054e-58, 'bankrupt_mean': 0.01129150390625, 'safe_mean': 0.0084381103515625, 'bankrupt_std': 0.0022373199462890625, 'safe_std': 0.00252532958984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1149
   Cohen's d: 1.068
   Safe mean: -0.005898, Risky mean: -0.002054
âŒ Error testing {'layer': 3, 'feature_id': 1149, 'cohen_d': 1.068359375, 'p_value': 8.525533775496883e-52, 'bankrupt_mean': -0.0020542144775390625, 'safe_mean': -0.00589752197265625, 'bankrupt_std': 0.0032672882080078125, 'safe_std': 0.003604888916015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-987
   Cohen's d: 1.064
   Safe mean: -0.013931, Risky mean: -0.011108
âŒ Error testing {'layer': 3, 'feature_id': 987, 'cohen_d': 1.064453125, 'p_value': 2.201280620047946e-51, 'bankrupt_mean': -0.0111083984375, 'safe_mean': -0.0139312744140625, 'bankrupt_std': 0.0026187896728515625, 'safe_std': 0.002651214599609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-461
   Cohen's d: 1.061
   Safe mean: -0.023941, Risky mean: -0.021713
âŒ Error testing {'layer': 3, 'feature_id': 461, 'cohen_d': 1.060546875, 'p_value': 5.3021400368055975e-51, 'bankrupt_mean': -0.0217132568359375, 'safe_mean': -0.0239410400390625, 'bankrupt_std': 0.0016374588012695312, 'safe_std': 0.0021152496337890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3949
   Cohen's d: -1.054
   Safe mean: -0.021042, Risky mean: -0.023895
âŒ Error testing {'layer': 3, 'feature_id': 3949, 'cohen_d': -1.0537109375, 'p_value': 3.1986714486224805e-50, 'bankrupt_mean': -0.023895263671875, 'safe_mean': -0.0210418701171875, 'bankrupt_std': 0.002513885498046875, 'safe_std': 0.0027179718017578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3116
   Cohen's d: -1.052
   Safe mean: 0.012047, Risky mean: 0.009155
âŒ Error testing {'layer': 3, 'feature_id': 3116, 'cohen_d': -1.0517578125, 'p_value': 2.8189894293493454e-50, 'bankrupt_mean': 0.0091552734375, 'safe_mean': 0.01204681396484375, 'bankrupt_std': 0.00225067138671875, 'safe_std': 0.0027618408203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-281
   Cohen's d: -1.042
   Safe mean: 0.035645, Risky mean: 0.031982
âŒ Error testing {'layer': 3, 'feature_id': 281, 'cohen_d': -1.0419921875, 'p_value': 1.864593546862652e-49, 'bankrupt_mean': 0.031982421875, 'safe_mean': 0.03564453125, 'bankrupt_std': 0.00365447998046875, 'safe_std': 0.0034961700439453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1748
   Cohen's d: 1.033
   Safe mean: -0.018585, Risky mean: -0.015915
âŒ Error testing {'layer': 3, 'feature_id': 1748, 'cohen_d': 1.033203125, 'p_value': 2.1664435426194558e-48, 'bankrupt_mean': -0.0159149169921875, 'safe_mean': -0.018585205078125, 'bankrupt_std': 0.0027179718017578125, 'safe_std': 0.0025844573974609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2692
   Cohen's d: 1.030
   Safe mean: -0.133789, Risky mean: -0.126831
âŒ Error testing {'layer': 3, 'feature_id': 2692, 'cohen_d': 1.0302734375, 'p_value': 3.429180006796162e-48, 'bankrupt_mean': -0.1268310546875, 'safe_mean': -0.1337890625, 'bankrupt_std': 0.0053863525390625, 'safe_std': 0.006801605224609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1434
   Cohen's d: 1.029
   Safe mean: 0.008125, Risky mean: 0.009972
âŒ Error testing {'layer': 3, 'feature_id': 1434, 'cohen_d': 1.029296875, 'p_value': 1.913763728131295e-48, 'bankrupt_mean': 0.00997161865234375, 'safe_mean': 0.00812530517578125, 'bankrupt_std': 0.0016193389892578125, 'safe_std': 0.0017938613891601562}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1487
   Cohen's d: -1.028
   Safe mean: -0.018097, Risky mean: -0.020370
âŒ Error testing {'layer': 3, 'feature_id': 1487, 'cohen_d': -1.0283203125, 'p_value': 3.4783253791170454e-48, 'bankrupt_mean': -0.0203704833984375, 'safe_mean': -0.018096923828125, 'bankrupt_std': 0.0016918182373046875, 'safe_std': 0.002223968505859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3473
   Cohen's d: -1.028
   Safe mean: 0.018204, Risky mean: 0.016342
âŒ Error testing {'layer': 3, 'feature_id': 3473, 'cohen_d': -1.0283203125, 'p_value': 6.085672331715721e-48, 'bankrupt_mean': 0.0163421630859375, 'safe_mean': 0.0182037353515625, 'bankrupt_std': 0.0018911361694335938, 'safe_std': 0.0018110275268554688}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-389
   Cohen's d: 1.013
   Safe mean: -0.018234, Risky mean: -0.015823
âŒ Error testing {'layer': 3, 'feature_id': 389, 'cohen_d': 1.0126953125, 'p_value': 7.877589333766039e-47, 'bankrupt_mean': -0.0158233642578125, 'safe_mean': -0.0182342529296875, 'bankrupt_std': 0.0019063949584960938, 'safe_std': 0.002391815185546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1052
   Cohen's d: 1.010
   Safe mean: 0.050354, Risky mean: 0.051971
âŒ Error testing {'layer': 3, 'feature_id': 1052, 'cohen_d': 1.009765625, 'p_value': 7.531289887678464e-47, 'bankrupt_mean': 0.051971435546875, 'safe_mean': 0.05035400390625, 'bankrupt_std': 0.0014028549194335938, 'safe_std': 0.0016012191772460938}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-104
   Cohen's d: -1.000
   Safe mean: 0.038055, Risky mean: 0.035095
âŒ Error testing {'layer': 3, 'feature_id': 104, 'cohen_d': -1.0, 'p_value': 1.4383133270071384e-45, 'bankrupt_mean': 0.03509521484375, 'safe_mean': 0.038055419921875, 'bankrupt_std': 0.00270843505859375, 'safe_std': 0.0029697418212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3045
   Cohen's d: -0.987
   Safe mean: 0.002497, Risky mean: 0.000041
âŒ Error testing {'layer': 3, 'feature_id': 3045, 'cohen_d': -0.98681640625, 'p_value': 2.1439015697162318e-44, 'bankrupt_mean': 4.07099723815918e-05, 'safe_mean': 0.0024967193603515625, 'bankrupt_std': 0.002559661865234375, 'safe_std': 0.0024890899658203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2473
   Cohen's d: -0.985
   Safe mean: 0.001209, Risky mean: -0.001326
âŒ Error testing {'layer': 3, 'feature_id': 2473, 'cohen_d': -0.9853515625, 'p_value': 1.9240719716827876e-44, 'bankrupt_mean': -0.0013256072998046875, 'safe_mean': 0.001209259033203125, 'bankrupt_std': 0.00212860107421875, 'safe_std': 0.0025844573974609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3698
   Cohen's d: -0.983
   Safe mean: 0.003744, Risky mean: 0.001518
âŒ Error testing {'layer': 3, 'feature_id': 3698, 'cohen_d': -0.98291015625, 'p_value': 2.3059425483808575e-44, 'bankrupt_mean': 0.00151824951171875, 'safe_mean': 0.0037441253662109375, 'bankrupt_std': 0.0020999908447265625, 'safe_std': 0.0022640228271484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1610
   Cohen's d: -0.980
   Safe mean: -0.022186, Risky mean: -0.025406
âŒ Error testing {'layer': 3, 'feature_id': 1610, 'cohen_d': -0.98046875, 'p_value': 5.462631841502084e-44, 'bankrupt_mean': -0.0254058837890625, 'safe_mean': -0.022186279296875, 'bankrupt_std': 0.0029201507568359375, 'safe_std': 0.0032939910888671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2001
   Cohen's d: 0.979
   Safe mean: -0.004032, Risky mean: -0.001318
âŒ Error testing {'layer': 3, 'feature_id': 2001, 'cohen_d': 0.978515625, 'p_value': 8.426193454618717e-44, 'bankrupt_mean': -0.0013179779052734375, 'safe_mean': -0.004032135009765625, 'bankrupt_std': 0.00244140625, 'safe_std': 0.0027828216552734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3908
   Cohen's d: -0.979
   Safe mean: -0.006760, Risky mean: -0.009354
âŒ Error testing {'layer': 3, 'feature_id': 3908, 'cohen_d': -0.978515625, 'p_value': 9.251782921664769e-44, 'bankrupt_mean': -0.0093536376953125, 'safe_mean': -0.0067596435546875, 'bankrupt_std': 0.0029506683349609375, 'safe_std': 0.0026416778564453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1336
   Cohen's d: 0.968
   Safe mean: 0.009621, Risky mean: 0.012253
âŒ Error testing {'layer': 3, 'feature_id': 1336, 'cohen_d': 0.96826171875, 'p_value': 4.3685214575467235e-43, 'bankrupt_mean': 0.0122528076171875, 'safe_mean': 0.00962066650390625, 'bankrupt_std': 0.002857208251953125, 'safe_std': 0.00270843505859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1379
   Cohen's d: 0.965
   Safe mean: 0.008392, Risky mean: 0.011429
âŒ Error testing {'layer': 3, 'feature_id': 1379, 'cohen_d': 0.96533203125, 'p_value': 1.2845985942465187e-42, 'bankrupt_mean': 0.0114288330078125, 'safe_mean': 0.008392333984375, 'bankrupt_std': 0.0026073455810546875, 'safe_std': 0.0031642913818359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3510
   Cohen's d: -0.961
   Safe mean: -0.004627, Risky mean: -0.007973
âŒ Error testing {'layer': 3, 'feature_id': 3510, 'cohen_d': -0.96142578125, 'p_value': 2.0496991731554213e-42, 'bankrupt_mean': -0.00797271728515625, 'safe_mean': -0.004627227783203125, 'bankrupt_std': 0.00286865234375, 'safe_std': 0.0034961700439453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1628
   Cohen's d: -0.954
   Safe mean: -0.034576, Risky mean: -0.037933
âŒ Error testing {'layer': 3, 'feature_id': 1628, 'cohen_d': -0.95361328125, 'p_value': 1.0541163889495949e-41, 'bankrupt_mean': -0.037933349609375, 'safe_mean': -0.034576416015625, 'bankrupt_std': 0.00348663330078125, 'safe_std': 0.003520965576171875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1749
   Cohen's d: -0.947
   Safe mean: -0.007637, Risky mean: -0.008904
âŒ Error testing {'layer': 3, 'feature_id': 1749, 'cohen_d': -0.947265625, 'p_value': 3.019405406304966e-41, 'bankrupt_mean': -0.00890350341796875, 'safe_mean': -0.00763702392578125, 'bankrupt_std': 0.0012922286987304688, 'safe_std': 0.0013370513916015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-258
   Cohen's d: 0.945
   Safe mean: -0.013496, Risky mean: -0.011513
âŒ Error testing {'layer': 3, 'feature_id': 258, 'cohen_d': 0.94482421875, 'p_value': 7.119652805392934e-41, 'bankrupt_mean': -0.01151275634765625, 'safe_mean': -0.01349639892578125, 'bankrupt_std': 0.001708984375, 'safe_std': 0.0021152496337890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-681
   Cohen's d: -0.942
   Safe mean: -0.032715, Risky mean: -0.034241
âŒ Error testing {'layer': 3, 'feature_id': 681, 'cohen_d': -0.9423828125, 'p_value': 1.3722445741507182e-40, 'bankrupt_mean': -0.03424072265625, 'safe_mean': -0.03271484375, 'bankrupt_std': 0.0017261505126953125, 'safe_std': 0.0016193389892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2307
   Cohen's d: -0.941
   Safe mean: 0.002840, Risky mean: -0.002060
âŒ Error testing {'layer': 3, 'feature_id': 2307, 'cohen_d': -0.94140625, 'p_value': 1.0173034918930342e-40, 'bankrupt_mean': -0.0020599365234375, 'safe_mean': 0.0028400421142578125, 'bankrupt_std': 0.00445556640625, 'safe_std': 0.00522613525390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1348
   Cohen's d: 0.941
   Safe mean: 0.010117, Risky mean: 0.012367
âŒ Error testing {'layer': 3, 'feature_id': 1348, 'cohen_d': 0.94091796875, 'p_value': 1.1630936279261055e-40, 'bankrupt_mean': 0.01236724853515625, 'safe_mean': 0.0101165771484375, 'bankrupt_std': 0.001983642578125, 'safe_std': 0.0024051666259765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1148
   Cohen's d: -0.939
   Safe mean: -0.019241, Risky mean: -0.022385
âŒ Error testing {'layer': 3, 'feature_id': 1148, 'cohen_d': -0.93896484375, 'p_value': 2.0842010062386604e-40, 'bankrupt_mean': -0.0223846435546875, 'safe_mean': -0.0192413330078125, 'bankrupt_std': 0.0029201507568359375, 'safe_std': 0.00336456298828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-531
   Cohen's d: 0.935
   Safe mean: 0.011215, Risky mean: 0.014191
âŒ Error testing {'layer': 3, 'feature_id': 531, 'cohen_d': 0.9345703125, 'p_value': 3.859249418003777e-40, 'bankrupt_mean': 0.014190673828125, 'safe_mean': 0.0112152099609375, 'bankrupt_std': 0.0025959014892578125, 'safe_std': 0.0032024383544921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-459
   Cohen's d: -0.930
   Safe mean: 0.007698, Risky mean: 0.005867
âŒ Error testing {'layer': 3, 'feature_id': 459, 'cohen_d': -0.93017578125, 'p_value': 6.443826679663931e-40, 'bankrupt_mean': 0.00586700439453125, 'safe_mean': 0.00769805908203125, 'bankrupt_std': 0.0013151168823242188, 'safe_std': 0.001983642578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-955
   Cohen's d: 0.928
   Safe mean: 0.037140, Risky mean: 0.039062
âŒ Error testing {'layer': 3, 'feature_id': 955, 'cohen_d': 0.92822265625, 'p_value': 2.0206173034676114e-39, 'bankrupt_mean': 0.0390625, 'safe_mean': 0.037139892578125, 'bankrupt_std': 0.0017938613891601562, 'safe_std': 0.002086639404296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-556
   Cohen's d: 0.923
   Safe mean: 0.001730, Risky mean: 0.004471
âŒ Error testing {'layer': 3, 'feature_id': 556, 'cohen_d': 0.9228515625, 'p_value': 4.5227894074122356e-39, 'bankrupt_mean': 0.0044708251953125, 'safe_mean': 0.0017299652099609375, 'bankrupt_std': 0.0024890899658203125, 'safe_std': 0.00299072265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2935
   Cohen's d: 0.919
   Safe mean: 0.023514, Risky mean: 0.026093
âŒ Error testing {'layer': 3, 'feature_id': 2935, 'cohen_d': 0.9189453125, 'p_value': 6.359051211540685e-39, 'bankrupt_mean': 0.026092529296875, 'safe_mean': 0.0235137939453125, 'bankrupt_std': 0.0027942657470703125, 'safe_std': 0.0028057098388671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1829
   Cohen's d: 0.917
   Safe mean: 0.030624, Risky mean: 0.032471
âŒ Error testing {'layer': 3, 'feature_id': 1829, 'cohen_d': 0.91650390625, 'p_value': 1.2215722703354322e-38, 'bankrupt_mean': 0.032470703125, 'safe_mean': 0.0306243896484375, 'bankrupt_std': 0.0016193389892578125, 'safe_std': 0.0020275115966796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1681
   Cohen's d: 0.915
   Safe mean: 0.001978, Risky mean: 0.003572
âŒ Error testing {'layer': 3, 'feature_id': 1681, 'cohen_d': 0.91455078125, 'p_value': 1.4807753928956796e-38, 'bankrupt_mean': 0.0035724639892578125, 'safe_mean': 0.0019779205322265625, 'bankrupt_std': 0.0017261505126953125, 'safe_std': 0.001743316650390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-748
   Cohen's d: 0.912
   Safe mean: -0.006580, Risky mean: -0.004288
âŒ Error testing {'layer': 3, 'feature_id': 748, 'cohen_d': 0.912109375, 'p_value': 3.011936733625828e-38, 'bankrupt_mean': -0.0042877197265625, 'safe_mean': -0.006580352783203125, 'bankrupt_std': 0.0026187896728515625, 'safe_std': 0.002513885498046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2713
   Cohen's d: 0.912
   Safe mean: -0.002623, Risky mean: -0.000842
âŒ Error testing {'layer': 3, 'feature_id': 2713, 'cohen_d': 0.91162109375, 'p_value': 3.812693277525866e-38, 'bankrupt_mean': -0.0008420944213867188, 'safe_mean': -0.0026226043701171875, 'bankrupt_std': 0.0016012191772460938, 'safe_std': 0.0019683837890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:   8%|â–Š         | 48/600 [00:00<00:04, 132.39it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-2112
   Cohen's d: 0.907
   Safe mean: 0.018600, Risky mean: 0.021301
âŒ Error testing {'layer': 3, 'feature_id': 2112, 'cohen_d': 0.90673828125, 'p_value': 8.574084985507875e-38, 'bankrupt_mean': 0.02130126953125, 'safe_mean': 0.0186004638671875, 'bankrupt_std': 0.002452850341796875, 'safe_std': 0.0030002593994140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1335
   Cohen's d: 0.905
   Safe mean: 0.000871, Risky mean: 0.002611
âŒ Error testing {'layer': 3, 'feature_id': 1335, 'cohen_d': 0.90478515625, 'p_value': 1.0525679203540435e-37, 'bankrupt_mean': 0.0026111602783203125, 'safe_mean': 0.0008711814880371094, 'bankrupt_std': 0.00146484375, 'safe_std': 0.0019378662109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-118
   Cohen's d: -0.903
   Safe mean: 0.008720, Risky mean: 0.006748
âŒ Error testing {'layer': 3, 'feature_id': 118, 'cohen_d': -0.90283203125, 'p_value': 1.2841490287460339e-37, 'bankrupt_mean': 0.006748199462890625, 'safe_mean': 0.00872039794921875, 'bankrupt_std': 0.002197265625, 'safe_std': 0.0021839141845703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1103
   Cohen's d: 0.898
   Safe mean: 0.022568, Risky mean: 0.024612
âŒ Error testing {'layer': 3, 'feature_id': 1103, 'cohen_d': 0.89794921875, 'p_value': 3.0498179965816906e-37, 'bankrupt_mean': 0.0246124267578125, 'safe_mean': 0.0225677490234375, 'bankrupt_std': 0.001827239990234375, 'safe_std': 0.0022907257080078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2303
   Cohen's d: -0.898
   Safe mean: -0.125977, Risky mean: -0.132935
âŒ Error testing {'layer': 3, 'feature_id': 2303, 'cohen_d': -0.89794921875, 'p_value': 3.208534134163131e-37, 'bankrupt_mean': -0.1329345703125, 'safe_mean': -0.1259765625, 'bankrupt_std': 0.005584716796875, 'safe_std': 0.0078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1627
   Cohen's d: -0.896
   Safe mean: -0.015129, Risky mean: -0.016327
âŒ Error testing {'layer': 3, 'feature_id': 1627, 'cohen_d': -0.89599609375, 'p_value': 2.5284785918079888e-37, 'bankrupt_mean': -0.016326904296875, 'safe_mean': -0.01512908935546875, 'bankrupt_std': 0.001171112060546875, 'safe_std': 0.0013370513916015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-511
   Cohen's d: -0.893
   Safe mean: 0.008621, Risky mean: 0.006386
âŒ Error testing {'layer': 3, 'feature_id': 511, 'cohen_d': -0.89306640625, 'p_value': 5.4306252434883846e-37, 'bankrupt_mean': 0.00638580322265625, 'safe_mean': 0.0086212158203125, 'bankrupt_std': 0.00238037109375, 'safe_std': 0.00250244140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2489
   Cohen's d: -0.892
   Safe mean: 0.008995, Risky mean: 0.007133
âŒ Error testing {'layer': 3, 'feature_id': 2489, 'cohen_d': -0.89208984375, 'p_value': 1.3758548363177884e-36, 'bankrupt_mean': 0.00713348388671875, 'safe_mean': 0.00899505615234375, 'bankrupt_std': 0.0018434524536132812, 'safe_std': 0.0020999908447265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3120
   Cohen's d: -0.889
   Safe mean: -0.009048, Risky mean: -0.010941
âŒ Error testing {'layer': 3, 'feature_id': 3120, 'cohen_d': -0.888671875, 'p_value': 1.8335191748958618e-36, 'bankrupt_mean': -0.0109405517578125, 'safe_mean': -0.0090484619140625, 'bankrupt_std': 0.001743316650390625, 'safe_std': 0.0021419525146484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-891
   Cohen's d: -0.884
   Safe mean: 0.100891, Risky mean: 0.096924
âŒ Error testing {'layer': 3, 'feature_id': 891, 'cohen_d': -0.8837890625, 'p_value': 2.9538706375907863e-36, 'bankrupt_mean': 0.096923828125, 'safe_mean': 0.10089111328125, 'bankrupt_std': 0.0040283203125, 'safe_std': 0.0045013427734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-819
   Cohen's d: -0.883
   Safe mean: -0.007153, Risky mean: -0.009888
âŒ Error testing {'layer': 3, 'feature_id': 819, 'cohen_d': -0.8828125, 'p_value': 3.8210333120770485e-36, 'bankrupt_mean': -0.0098876953125, 'safe_mean': -0.007152557373046875, 'bankrupt_std': 0.002979278564453125, 'safe_std': 0.0030975341796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2084
   Cohen's d: 0.882
   Safe mean: -0.012383, Risky mean: -0.009575
âŒ Error testing {'layer': 3, 'feature_id': 2084, 'cohen_d': 0.8818359375, 'p_value': 5.67503762408418e-36, 'bankrupt_mean': -0.00957489013671875, 'safe_mean': -0.01238250732421875, 'bankrupt_std': 0.0034694671630859375, 'safe_std': 0.003173828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1068
   Cohen's d: -0.875
   Safe mean: 0.009529, Risky mean: 0.007351
âŒ Error testing {'layer': 3, 'feature_id': 1068, 'cohen_d': -0.875, 'p_value': 2.588363996888443e-35, 'bankrupt_mean': 0.007350921630859375, 'safe_mean': 0.00952911376953125, 'bankrupt_std': 0.002277374267578125, 'safe_std': 0.00250244140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3855
   Cohen's d: 0.875
   Safe mean: -0.023331, Risky mean: -0.020630
âŒ Error testing {'layer': 3, 'feature_id': 3855, 'cohen_d': 0.87451171875, 'p_value': 1.6803675827304404e-35, 'bankrupt_mean': -0.0206298828125, 'safe_mean': -0.0233306884765625, 'bankrupt_std': 0.003513336181640625, 'safe_std': 0.0030689239501953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-2534
   Cohen's d: 0.874
   Safe mean: -0.047699, Risky mean: -0.045258
âŒ Error testing {'layer': 3, 'feature_id': 2534, 'cohen_d': 0.87353515625, 'p_value': 3.116279039998044e-35, 'bankrupt_mean': -0.045257568359375, 'safe_mean': -0.047698974609375, 'bankrupt_std': 0.002277374267578125, 'safe_std': 0.00281524658203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2210
   Cohen's d: -0.873
   Safe mean: 0.005600, Risky mean: 0.003511
âŒ Error testing {'layer': 3, 'feature_id': 2210, 'cohen_d': -0.873046875, 'p_value': 2.2884402170390052e-35, 'bankrupt_mean': 0.0035114288330078125, 'safe_mean': 0.0055999755859375, 'bankrupt_std': 0.0023288726806640625, 'safe_std': 0.002391815185546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-960
   Cohen's d: -0.871
   Safe mean: 0.028839, Risky mean: 0.025986
âŒ Error testing {'layer': 3, 'feature_id': 960, 'cohen_d': -0.87109375, 'p_value': 4.2373077550524795e-35, 'bankrupt_mean': 0.0259857177734375, 'safe_mean': 0.028839111328125, 'bankrupt_std': 0.00336456298828125, 'safe_std': 0.0032749176025390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3912
   Cohen's d: -0.870
   Safe mean: 0.006882, Risky mean: 0.003639
âŒ Error testing {'layer': 3, 'feature_id': 3912, 'cohen_d': -0.8701171875, 'p_value': 4.079096738707597e-35, 'bankrupt_mean': 0.00363922119140625, 'safe_mean': 0.0068817138671875, 'bankrupt_std': 0.0034084320068359375, 'safe_std': 0.003734588623046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1635
   Cohen's d: 0.869
   Safe mean: 0.012016, Risky mean: 0.015717
âŒ Error testing {'layer': 3, 'feature_id': 1635, 'cohen_d': 0.869140625, 'p_value': 5.189425812626698e-35, 'bankrupt_mean': 0.015716552734375, 'safe_mean': 0.01201629638671875, 'bankrupt_std': 0.003604888916015625, 'safe_std': 0.004276275634765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2054
   Cohen's d: -0.867
   Safe mean: 0.003691, Risky mean: 0.002369
âŒ Error testing {'layer': 3, 'feature_id': 2054, 'cohen_d': -0.86669921875, 'p_value': 7.656094465609443e-35, 'bankrupt_mean': 0.002368927001953125, 'safe_mean': 0.0036907196044921875, 'bankrupt_std': 0.0015249252319335938, 'safe_std': 0.0015249252319335938}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-98
   Cohen's d: 0.863
   Safe mean: -0.030380, Risky mean: -0.027740
âŒ Error testing {'layer': 3, 'feature_id': 98, 'cohen_d': 0.86279296875, 'p_value': 9.516091300268994e-35, 'bankrupt_mean': -0.027740478515625, 'safe_mean': -0.0303802490234375, 'bankrupt_std': 0.0030498504638671875, 'safe_std': 0.00305938720703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-572
   Cohen's d: 0.861
   Safe mean: -0.007137, Risky mean: -0.002665
âŒ Error testing {'layer': 3, 'feature_id': 572, 'cohen_d': 0.861328125, 'p_value': 1.7605879781726653e-34, 'bankrupt_mean': -0.0026645660400390625, 'safe_mean': -0.007137298583984375, 'bankrupt_std': 0.0046844482421875, 'safe_std': 0.005207061767578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2872
   Cohen's d: -0.860
   Safe mean: -0.016129, Risky mean: -0.017960
âŒ Error testing {'layer': 3, 'feature_id': 2872, 'cohen_d': -0.8603515625, 'p_value': 2.444100482502579e-34, 'bankrupt_mean': -0.0179595947265625, 'safe_mean': -0.0161285400390625, 'bankrupt_std': 0.0016736984252929688, 'safe_std': 0.0021419525146484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1145
   Cohen's d: -0.859
   Safe mean: -0.002438, Risky mean: -0.004242
âŒ Error testing {'layer': 3, 'feature_id': 1145, 'cohen_d': -0.859375, 'p_value': 3.4110512007259742e-34, 'bankrupt_mean': -0.004241943359375, 'safe_mean': -0.002437591552734375, 'bankrupt_std': 0.001708984375, 'safe_std': 0.0021152496337890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3648
   Cohen's d: -0.857
   Safe mean: 0.020325, Risky mean: 0.018860
âŒ Error testing {'layer': 3, 'feature_id': 3648, 'cohen_d': -0.85693359375, 'p_value': 7.659390022953621e-34, 'bankrupt_mean': 0.01885986328125, 'safe_mean': 0.02032470703125, 'bankrupt_std': 0.00138092041015625, 'safe_std': 0.0017261505126953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-875
   Cohen's d: -0.855
   Safe mean: -0.019638, Risky mean: -0.020874
âŒ Error testing {'layer': 3, 'feature_id': 875, 'cohen_d': -0.85546875, 'p_value': 6.123032435856597e-34, 'bankrupt_mean': -0.0208740234375, 'safe_mean': -0.0196380615234375, 'bankrupt_std': 0.0014848709106445312, 'safe_std': 0.0014448165893554688}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3553
   Cohen's d: 0.855
   Safe mean: -0.018204, Risky mean: -0.015823
âŒ Error testing {'layer': 3, 'feature_id': 3553, 'cohen_d': 0.85546875, 'p_value': 5.2738483937577455e-34, 'bankrupt_mean': -0.0158233642578125, 'safe_mean': -0.0182037353515625, 'bankrupt_std': 0.0027179718017578125, 'safe_std': 0.0027828216552734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3168
   Cohen's d: 0.854
   Safe mean: 0.005493, Risky mean: 0.006996
âŒ Error testing {'layer': 3, 'feature_id': 3168, 'cohen_d': 0.853515625, 'p_value': 7.873909176200266e-34, 'bankrupt_mean': 0.00699615478515625, 'safe_mean': 0.0054931640625, 'bankrupt_std': 0.0017604827880859375, 'safe_std': 0.0017604827880859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-107
   Cohen's d: 0.853
   Safe mean: 0.011208, Risky mean: 0.012833
âŒ Error testing {'layer': 3, 'feature_id': 107, 'cohen_d': 0.8525390625, 'p_value': 9.674630205874076e-34, 'bankrupt_mean': 0.0128326416015625, 'safe_mean': 0.01120758056640625, 'bankrupt_std': 0.0019063949584960938, 'safe_std': 0.0019063949584960938}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1685
   Cohen's d: -0.850
   Safe mean: -0.015465, Risky mean: -0.018356
âŒ Error testing {'layer': 3, 'feature_id': 1685, 'cohen_d': -0.85009765625, 'p_value': 1.1859658669724832e-33, 'bankrupt_mean': -0.0183563232421875, 'safe_mean': -0.01546478271484375, 'bankrupt_std': 0.0033111572265625, 'safe_std': 0.0034008026123046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3226
   Cohen's d: 0.850
   Safe mean: -0.028580, Risky mean: -0.026474
âŒ Error testing {'layer': 3, 'feature_id': 3226, 'cohen_d': 0.85009765625, 'p_value': 1.662520338811024e-33, 'bankrupt_mean': -0.0264739990234375, 'safe_mean': -0.0285797119140625, 'bankrupt_std': 0.0017261505126953125, 'safe_std': 0.00250244140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1795
   Cohen's d: 0.848
   Safe mean: -0.008141, Risky mean: -0.006325
âŒ Error testing {'layer': 3, 'feature_id': 1795, 'cohen_d': 0.84765625, 'p_value': 1.8374748164519334e-33, 'bankrupt_mean': -0.00632476806640625, 'safe_mean': -0.00814056396484375, 'bankrupt_std': 0.002071380615234375, 'safe_std': 0.0021419525146484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2388
   Cohen's d: 0.846
   Safe mean: -0.013199, Risky mean: -0.010391
âŒ Error testing {'layer': 3, 'feature_id': 2388, 'cohen_d': 0.845703125, 'p_value': 3.0714402360561896e-33, 'bankrupt_mean': -0.0103912353515625, 'safe_mean': -0.0131988525390625, 'bankrupt_std': 0.0030498504638671875, 'safe_std': 0.003330230712890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-187
   Cohen's d: -0.844
   Safe mean: 0.007351, Risky mean: 0.005417
âŒ Error testing {'layer': 3, 'feature_id': 187, 'cohen_d': -0.84423828125, 'p_value': 3.737079896419494e-33, 'bankrupt_mean': 0.0054168701171875, 'safe_mean': 0.007350921630859375, 'bankrupt_std': 0.0023040771484375, 'safe_std': 0.0022907257080078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2027
   Cohen's d: -0.844
   Safe mean: 0.008553, Risky mean: 0.006996
âŒ Error testing {'layer': 3, 'feature_id': 2027, 'cohen_d': -0.84423828125, 'p_value': 2.433107869601254e-33, 'bankrupt_mean': 0.00699615478515625, 'safe_mean': 0.00855255126953125, 'bankrupt_std': 0.0016736984252929688, 'safe_std': 0.0018434524536132812}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2368
   Cohen's d: 0.844
   Safe mean: 0.008148, Risky mean: 0.011894
âŒ Error testing {'layer': 3, 'feature_id': 2368, 'cohen_d': 0.84375, 'p_value': 4.462062443111543e-33, 'bankrupt_mean': 0.01189422607421875, 'safe_mean': 0.008148193359375, 'bankrupt_std': 0.0035877227783203125, 'safe_std': 0.004467010498046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1522
   Cohen's d: -0.841
   Safe mean: 0.013199, Risky mean: 0.011124
âŒ Error testing {'layer': 3, 'feature_id': 1522, 'cohen_d': -0.84130859375, 'p_value': 3.978710777201434e-33, 'bankrupt_mean': 0.0111236572265625, 'safe_mean': 0.0131988525390625, 'bankrupt_std': 0.00225067138671875, 'safe_std': 0.0024662017822265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3445
   Cohen's d: -0.836
   Safe mean: -0.003027, Risky mean: -0.004921
âŒ Error testing {'layer': 3, 'feature_id': 3445, 'cohen_d': -0.83642578125, 'p_value': 1.2466187743132397e-32, 'bankrupt_mean': -0.00492095947265625, 'safe_mean': -0.0030269622802734375, 'bankrupt_std': 0.0022106170654296875, 'safe_std': 0.0022640228271484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1887
   Cohen's d: -0.836
   Safe mean: 0.016022, Risky mean: 0.014290
âŒ Error testing {'layer': 3, 'feature_id': 1887, 'cohen_d': -0.8359375, 'p_value': 1.903751208471027e-32, 'bankrupt_mean': 0.01428985595703125, 'safe_mean': 0.016021728515625, 'bankrupt_std': 0.002170562744140625, 'safe_std': 0.002071380615234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1273
   Cohen's d: 0.834
   Safe mean: 0.012245, Risky mean: 0.013565
âŒ Error testing {'layer': 3, 'feature_id': 1273, 'cohen_d': 0.83447265625, 'p_value': 9.288430358485658e-33, 'bankrupt_mean': 0.0135650634765625, 'safe_mean': 0.01224517822265625, 'bankrupt_std': 0.0018596649169921875, 'safe_std': 0.0015630722045898438}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1096
   Cohen's d: 0.834
   Safe mean: -0.013123, Risky mean: -0.010902
âŒ Error testing {'layer': 3, 'feature_id': 1096, 'cohen_d': 0.833984375, 'p_value': 2.0730034750801546e-32, 'bankrupt_mean': -0.01090240478515625, 'safe_mean': -0.01312255859375, 'bankrupt_std': 0.00225067138671875, 'safe_std': 0.002674102783203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3768
   Cohen's d: -0.832
   Safe mean: 0.015762, Risky mean: 0.014015
âŒ Error testing {'layer': 3, 'feature_id': 3768, 'cohen_d': -0.83203125, 'p_value': 1.99905133039127e-32, 'bankrupt_mean': 0.01401519775390625, 'safe_mean': 0.0157623291015625, 'bankrupt_std': 0.002315521240234375, 'safe_std': 0.002086639404296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  16%|â–ˆâ–Œ        | 93/600 [00:00<00:02, 221.76it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-722
   Cohen's d: 0.828
   Safe mean: 0.004814, Risky mean: 0.006229
âŒ Error testing {'layer': 3, 'feature_id': 722, 'cohen_d': 0.828125, 'p_value': 1.082928511157877e-31, 'bankrupt_mean': 0.006229400634765625, 'safe_mean': 0.00481414794921875, 'bankrupt_std': 0.0019378662109375, 'safe_std': 0.001708984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2811
   Cohen's d: 0.828
   Safe mean: 0.018005, Risky mean: 0.019745
âŒ Error testing {'layer': 3, 'feature_id': 2811, 'cohen_d': 0.828125, 'p_value': 4.0808983748468746e-32, 'bankrupt_mean': 0.019744873046875, 'safe_mean': 0.01800537109375, 'bankrupt_std': 0.001953125, 'safe_std': 0.0020999908447265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-312
   Cohen's d: 0.827
   Safe mean: -0.018127, Risky mean: -0.016190
âŒ Error testing {'layer': 3, 'feature_id': 312, 'cohen_d': 0.8271484375, 'p_value': 9.134298314580296e-32, 'bankrupt_mean': -0.0161895751953125, 'safe_mean': -0.01812744140625, 'bankrupt_std': 0.0021419525146484375, 'safe_std': 0.002353668212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3457
   Cohen's d: -0.826
   Safe mean: 0.012894, Risky mean: 0.011124
âŒ Error testing {'layer': 3, 'feature_id': 3457, 'cohen_d': -0.826171875, 'p_value': 9.598846228130659e-32, 'bankrupt_mean': 0.0111236572265625, 'safe_mean': 0.0128936767578125, 'bankrupt_std': 0.0022373199462890625, 'safe_std': 0.0021419525146484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3931
   Cohen's d: 0.821
   Safe mean: -0.000916, Risky mean: 0.001629
âŒ Error testing {'layer': 3, 'feature_id': 3931, 'cohen_d': 0.8212890625, 'p_value': 1.716378520125604e-31, 'bankrupt_mean': 0.001628875732421875, 'safe_mean': -0.0009164810180664062, 'bankrupt_std': 0.002452850341796875, 'safe_std': 0.003116607666015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2887
   Cohen's d: -0.819
   Safe mean: -0.026398, Risky mean: -0.027710
âŒ Error testing {'layer': 3, 'feature_id': 2887, 'cohen_d': -0.8193359375, 'p_value': 1.3684206608365678e-31, 'bankrupt_mean': -0.0277099609375, 'safe_mean': -0.026397705078125, 'bankrupt_std': 0.0014028549194335938, 'safe_std': 0.0016012191772460938}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2908
   Cohen's d: -0.819
   Safe mean: -0.005245, Risky mean: -0.007401
âŒ Error testing {'layer': 3, 'feature_id': 2908, 'cohen_d': -0.8193359375, 'p_value': 1.7751571622138744e-31, 'bankrupt_mean': -0.0074005126953125, 'safe_mean': -0.005245208740234375, 'bankrupt_std': 0.002086639404296875, 'safe_std': 0.0026416778564453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3523
   Cohen's d: 0.819
   Safe mean: 0.024719, Risky mean: 0.026855
âŒ Error testing {'layer': 3, 'feature_id': 3523, 'cohen_d': 0.8193359375, 'p_value': 2.0144581077195435e-31, 'bankrupt_mean': 0.02685546875, 'safe_mean': 0.02471923828125, 'bankrupt_std': 0.0016736984252929688, 'safe_std': 0.0026302337646484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-4087
   Cohen's d: 0.819
   Safe mean: -0.010452, Risky mean: -0.008675
âŒ Error testing {'layer': 3, 'feature_id': 4087, 'cohen_d': 0.81884765625, 'p_value': 2.7155374335628244e-31, 'bankrupt_mean': -0.00867462158203125, 'safe_mean': -0.0104522705078125, 'bankrupt_std': 0.0022106170654296875, 'safe_std': 0.002170562744140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2430
   Cohen's d: 0.816
   Safe mean: 0.001322, Risky mean: 0.003391
âŒ Error testing {'layer': 3, 'feature_id': 2430, 'cohen_d': 0.81591796875, 'p_value': 3.956645861937277e-31, 'bankrupt_mean': 0.003391265869140625, 'safe_mean': 0.0013217926025390625, 'bankrupt_std': 0.0024662017822265625, 'safe_std': 0.002536773681640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1137
   Cohen's d: 0.812
   Safe mean: 0.008537, Risky mean: 0.009926
âŒ Error testing {'layer': 3, 'feature_id': 1137, 'cohen_d': 0.8125, 'p_value': 5.4816914949631335e-31, 'bankrupt_mean': 0.00992584228515625, 'safe_mean': 0.00853729248046875, 'bankrupt_std': 0.0015821456909179688, 'safe_std': 0.001708984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3028
   Cohen's d: -0.812
   Safe mean: -0.006985, Risky mean: -0.008713
âŒ Error testing {'layer': 3, 'feature_id': 3028, 'cohen_d': -0.81201171875, 'p_value': 1.1108061757834108e-30, 'bankrupt_mean': -0.0087127685546875, 'safe_mean': -0.006984710693359375, 'bankrupt_std': 0.0018434524536132812, 'safe_std': 0.0021419525146484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-4028
   Cohen's d: -0.811
   Safe mean: -0.050598, Risky mean: -0.055817
âŒ Error testing {'layer': 3, 'feature_id': 4028, 'cohen_d': -0.81103515625, 'p_value': 9.309629336604061e-31, 'bankrupt_mean': -0.055816650390625, 'safe_mean': -0.05059814453125, 'bankrupt_std': 0.006343841552734375, 'safe_std': 0.006439208984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2242
   Cohen's d: -0.810
   Safe mean: -0.018539, Risky mean: -0.020920
âŒ Error testing {'layer': 3, 'feature_id': 2242, 'cohen_d': -0.81005859375, 'p_value': 1.3190176502343014e-30, 'bankrupt_mean': -0.0209197998046875, 'safe_mean': -0.0185394287109375, 'bankrupt_std': 0.003009796142578125, 'safe_std': 0.0029392242431640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-3823
   Cohen's d: 0.809
   Safe mean: -0.050537, Risky mean: -0.046783
âŒ Error testing {'layer': 3, 'feature_id': 3823, 'cohen_d': 0.80908203125, 'p_value': 1.2927547894470592e-30, 'bankrupt_mean': -0.046783447265625, 'safe_mean': -0.050537109375, 'bankrupt_std': 0.0056610107421875, 'safe_std': 0.00460052490234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-802
   Cohen's d: -0.807
   Safe mean: 0.001225, Risky mean: 0.000220
âŒ Error testing {'layer': 3, 'feature_id': 802, 'cohen_d': -0.80712890625, 'p_value': 1.1734255003344314e-30, 'bankrupt_mean': 0.00022029876708984375, 'safe_mean': 0.001224517822265625, 'bankrupt_std': 0.0010919570922851562, 'safe_std': 0.0012445449829101562}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3560
   Cohen's d: -0.806
   Safe mean: -0.002182, Risky mean: -0.004070
âŒ Error testing {'layer': 3, 'feature_id': 3560, 'cohen_d': -0.80615234375, 'p_value': 2.4056985898512287e-30, 'bankrupt_mean': -0.004070281982421875, 'safe_mean': -0.0021820068359375, 'bankrupt_std': 0.002429962158203125, 'safe_std': 0.00234222412109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-831
   Cohen's d: 0.806
   Safe mean: -0.028885, Risky mean: -0.026428
âŒ Error testing {'layer': 3, 'feature_id': 831, 'cohen_d': 0.8056640625, 'p_value': 2.8348832295126235e-30, 'bankrupt_mean': -0.02642822265625, 'safe_mean': -0.0288848876953125, 'bankrupt_std': 0.0029087066650390625, 'safe_std': 0.00305938720703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3037
   Cohen's d: 0.805
   Safe mean: -0.035156, Risky mean: -0.033142
âŒ Error testing {'layer': 3, 'feature_id': 3037, 'cohen_d': 0.8046875, 'p_value': 2.7509331119392562e-30, 'bankrupt_mean': -0.03314208984375, 'safe_mean': -0.03515625, 'bankrupt_std': 0.0028781890869140625, 'safe_std': 0.0024890899658203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1111
   Cohen's d: -0.797
   Safe mean: -0.026749, Risky mean: -0.028687
âŒ Error testing {'layer': 3, 'feature_id': 1111, 'cohen_d': -0.79736328125, 'p_value': 8.579803392962434e-30, 'bankrupt_mean': -0.0286865234375, 'safe_mean': -0.0267486572265625, 'bankrupt_std': 0.002452850341796875, 'safe_std': 0.002429962158203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1129
   Cohen's d: 0.797
   Safe mean: -0.009018, Risky mean: -0.006157
âŒ Error testing {'layer': 3, 'feature_id': 1129, 'cohen_d': 0.79736328125, 'p_value': 8.751573070114011e-30, 'bankrupt_mean': -0.00615692138671875, 'safe_mean': -0.0090179443359375, 'bankrupt_std': 0.0035877227783203125, 'safe_std': 0.0035877227783203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1873
   Cohen's d: -0.797
   Safe mean: -0.015686, Risky mean: -0.016769
âŒ Error testing {'layer': 3, 'feature_id': 1873, 'cohen_d': -0.79736328125, 'p_value': 7.556183131742645e-30, 'bankrupt_mean': -0.0167694091796875, 'safe_mean': -0.01568603515625, 'bankrupt_std': 0.0012922286987304688, 'safe_std': 0.0013589859008789062}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3011
   Cohen's d: 0.797
   Safe mean: -0.034760, Risky mean: -0.031708
âŒ Error testing {'layer': 3, 'feature_id': 3011, 'cohen_d': 0.796875, 'p_value': 8.97577445242993e-30, 'bankrupt_mean': -0.031707763671875, 'safe_mean': -0.034759521484375, 'bankrupt_std': 0.00330352783203125, 'safe_std': 0.00384521484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3902
   Cohen's d: 0.796
   Safe mean: -0.079468, Risky mean: -0.076599
âŒ Error testing {'layer': 3, 'feature_id': 3902, 'cohen_d': 0.7958984375, 'p_value': 1.1629177368238693e-29, 'bankrupt_mean': -0.07659912109375, 'safe_mean': -0.0794677734375, 'bankrupt_std': 0.00386810302734375, 'safe_std': 0.003597259521484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-841
   Cohen's d: -0.795
   Safe mean: 0.023117, Risky mean: 0.021286
âŒ Error testing {'layer': 3, 'feature_id': 841, 'cohen_d': -0.794921875, 'p_value': 9.619903480759484e-30, 'bankrupt_mean': 0.0212860107421875, 'safe_mean': 0.0231170654296875, 'bankrupt_std': 0.0021419525146484375, 'safe_std': 0.0023040771484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-871
   Cohen's d: -0.794
   Safe mean: -0.010864, Risky mean: -0.012222
âŒ Error testing {'layer': 3, 'feature_id': 871, 'cohen_d': -0.79443359375, 'p_value': 1.1900366366883888e-29, 'bankrupt_mean': -0.0122222900390625, 'safe_mean': -0.0108642578125, 'bankrupt_std': 0.00165557861328125, 'safe_std': 0.001708984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1199
   Cohen's d: -0.791
   Safe mean: 0.001574, Risky mean: -0.001278
âŒ Error testing {'layer': 3, 'feature_id': 1199, 'cohen_d': -0.791015625, 'p_value': 2.3670010988211054e-29, 'bankrupt_mean': -0.001277923583984375, 'safe_mean': 0.0015735626220703125, 'bankrupt_std': 0.003337860107421875, 'safe_std': 0.003612518310546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-4089
   Cohen's d: 0.791
   Safe mean: -0.026917, Risky mean: -0.025024
âŒ Error testing {'layer': 3, 'feature_id': 4089, 'cohen_d': 0.791015625, 'p_value': 3.195104327058913e-29, 'bankrupt_mean': -0.0250244140625, 'safe_mean': -0.02691650390625, 'bankrupt_std': 0.00286865234375, 'safe_std': 0.00238037109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-1131
   Cohen's d: 0.790
   Safe mean: -0.039703, Risky mean: -0.035278
âŒ Error testing {'layer': 3, 'feature_id': 1131, 'cohen_d': 0.78955078125, 'p_value': 3.174314192631732e-29, 'bankrupt_mean': -0.0352783203125, 'safe_mean': -0.039703369140625, 'bankrupt_std': 0.005496978759765625, 'safe_std': 0.005611419677734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1431
   Cohen's d: 0.790
   Safe mean: -0.011864, Risky mean: -0.008797
âŒ Error testing {'layer': 3, 'feature_id': 1431, 'cohen_d': 0.78955078125, 'p_value': 3.3281260793903564e-29, 'bankrupt_mean': -0.00879669189453125, 'safe_mean': -0.01186370849609375, 'bankrupt_std': 0.0037746429443359375, 'safe_std': 0.0038909912109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2205
   Cohen's d: 0.790
   Safe mean: 0.022751, Risky mean: 0.024399
âŒ Error testing {'layer': 3, 'feature_id': 2205, 'cohen_d': 0.78955078125, 'p_value': 2.126982013801749e-29, 'bankrupt_mean': 0.0243988037109375, 'safe_mean': 0.0227508544921875, 'bankrupt_std': 0.0019378662109375, 'safe_std': 0.002086639404296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-455
   Cohen's d: 0.789
   Safe mean: -0.004936, Risky mean: -0.003059
âŒ Error testing {'layer': 3, 'feature_id': 455, 'cohen_d': 0.78857421875, 'p_value': 2.8628026691207475e-29, 'bankrupt_mean': -0.00305938720703125, 'safe_mean': -0.00493621826171875, 'bankrupt_std': 0.0022640228271484375, 'safe_std': 0.00238037109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3956
   Cohen's d: -0.786
   Safe mean: 0.003376, Risky mean: 0.001222
âŒ Error testing {'layer': 3, 'feature_id': 3956, 'cohen_d': -0.7861328125, 'p_value': 5.317530056081573e-29, 'bankrupt_mean': 0.0012216567993164062, 'safe_mean': 0.003376007080078125, 'bankrupt_std': 0.0027828216552734375, 'safe_std': 0.0027408599853515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3891
   Cohen's d: 0.786
   Safe mean: 0.008926, Risky mean: 0.011360
âŒ Error testing {'layer': 3, 'feature_id': 3891, 'cohen_d': 0.78564453125, 'p_value': 5.873895926436458e-29, 'bankrupt_mean': 0.01136016845703125, 'safe_mean': 0.0089263916015625, 'bankrupt_std': 0.003391265869140625, 'safe_std': 0.0030879974365234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3703
   Cohen's d: -0.784
   Safe mean: -0.004284, Risky mean: -0.005665
âŒ Error testing {'layer': 3, 'feature_id': 3703, 'cohen_d': -0.7841796875, 'p_value': 4.142590307163161e-29, 'bankrupt_mean': -0.005664825439453125, 'safe_mean': -0.004283905029296875, 'bankrupt_std': 0.0015249252319335938, 'safe_std': 0.0017604827880859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1850
   Cohen's d: 0.784
   Safe mean: -0.013512, Risky mean: -0.011810
âŒ Error testing {'layer': 3, 'feature_id': 1850, 'cohen_d': 0.78369140625, 'p_value': 5.216851963719957e-29, 'bankrupt_mean': -0.011810302734375, 'safe_mean': -0.01351165771484375, 'bankrupt_std': 0.001983642578125, 'safe_std': 0.002170562744140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2876
   Cohen's d: 0.778
   Safe mean: 0.022079, Risky mean: 0.023987
âŒ Error testing {'layer': 3, 'feature_id': 2876, 'cohen_d': 0.77783203125, 'p_value': 1.857962144980334e-28, 'bankrupt_mean': 0.02398681640625, 'safe_mean': 0.0220794677734375, 'bankrupt_std': 0.00238037109375, 'safe_std': 0.002452850341796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3428
   Cohen's d: 0.776
   Safe mean: -0.001918, Risky mean: -0.000552
âŒ Error testing {'layer': 3, 'feature_id': 3428, 'cohen_d': 0.77587890625, 'p_value': 2.613803696370929e-28, 'bankrupt_mean': -0.0005517005920410156, 'safe_mean': -0.0019178390502929688, 'bankrupt_std': 0.001743316650390625, 'safe_std': 0.0017604827880859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1696
   Cohen's d: -0.773
   Safe mean: -0.004112, Risky mean: -0.007000
âŒ Error testing {'layer': 3, 'feature_id': 1696, 'cohen_d': -0.7734375, 'p_value': 3.961389226675196e-28, 'bankrupt_mean': -0.006999969482421875, 'safe_mean': -0.00411224365234375, 'bankrupt_std': 0.0032196044921875, 'safe_std': 0.003749847412109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1856
   Cohen's d: -0.773
   Safe mean: -0.041077, Risky mean: -0.043213
âŒ Error testing {'layer': 3, 'feature_id': 1856, 'cohen_d': -0.7734375, 'p_value': 4.046185735134758e-28, 'bankrupt_mean': -0.043212890625, 'safe_mean': -0.04107666015625, 'bankrupt_std': 0.002452850341796875, 'safe_std': 0.002773284912109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2175
   Cohen's d: 0.773
   Safe mean: 0.019089, Risky mean: 0.022461
âŒ Error testing {'layer': 3, 'feature_id': 2175, 'cohen_d': 0.7734375, 'p_value': 4.122996861593323e-28, 'bankrupt_mean': 0.0224609375, 'safe_mean': 0.0190887451171875, 'bankrupt_std': 0.003997802734375, 'safe_std': 0.004375457763671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2197
   Cohen's d: 0.773
   Safe mean: -0.001399, Risky mean: 0.000696
âŒ Error testing {'layer': 3, 'feature_id': 2197, 'cohen_d': 0.7734375, 'p_value': 3.195630481410506e-28, 'bankrupt_mean': 0.0006957054138183594, 'safe_mean': -0.0013990402221679688, 'bankrupt_std': 0.0022106170654296875, 'safe_std': 0.0027179718017578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  23%|â–ˆâ–ˆâ–Ž       | 138/600 [00:00<00:01, 286.48it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-1675
   Cohen's d: 0.772
   Safe mean: 0.019012, Risky mean: 0.021759
âŒ Error testing {'layer': 3, 'feature_id': 1675, 'cohen_d': 0.7724609375, 'p_value': 4.143360256516663e-28, 'bankrupt_mean': 0.021759033203125, 'safe_mean': 0.019012451171875, 'bankrupt_std': 0.0035037994384765625, 'safe_std': 0.0035552978515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2077
   Cohen's d: 0.772
   Safe mean: -0.012596, Risky mean: -0.010719
âŒ Error testing {'layer': 3, 'feature_id': 2077, 'cohen_d': 0.7724609375, 'p_value': 4.615034995074115e-28, 'bankrupt_mean': -0.01071929931640625, 'safe_mean': -0.01259613037109375, 'bankrupt_std': 0.002071380615234375, 'safe_std': 0.00244140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1213
   Cohen's d: -0.768
   Safe mean: 0.005241, Risky mean: 0.003222
âŒ Error testing {'layer': 3, 'feature_id': 1213, 'cohen_d': -0.76806640625, 'p_value': 6.823594128533224e-28, 'bankrupt_mean': 0.0032215118408203125, 'safe_mean': 0.00524139404296875, 'bankrupt_std': 0.002452850341796875, 'safe_std': 0.0026187896728515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1974
   Cohen's d: 0.767
   Safe mean: 0.047882, Risky mean: 0.049774
âŒ Error testing {'layer': 3, 'feature_id': 1974, 'cohen_d': 0.76708984375, 'p_value': 9.915177253955293e-28, 'bankrupt_mean': 0.049774169921875, 'safe_mean': 0.047882080078125, 'bankrupt_std': 0.0027942657470703125, 'safe_std': 0.002452850341796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2106
   Cohen's d: -0.767
   Safe mean: -0.006893, Risky mean: -0.009392
âŒ Error testing {'layer': 3, 'feature_id': 2106, 'cohen_d': -0.76708984375, 'p_value': 9.449973995540388e-28, 'bankrupt_mean': -0.00939178466796875, 'safe_mean': -0.006893157958984375, 'bankrupt_std': 0.0028896331787109375, 'safe_std': 0.0032672882080078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3854
   Cohen's d: -0.766
   Safe mean: 0.015205, Risky mean: 0.014023
âŒ Error testing {'layer': 3, 'feature_id': 3854, 'cohen_d': -0.76611328125, 'p_value': 9.377669386860675e-28, 'bankrupt_mean': 0.0140228271484375, 'safe_mean': 0.01520538330078125, 'bankrupt_std': 0.0014238357543945312, 'safe_std': 0.0015439987182617188}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1566
   Cohen's d: -0.766
   Safe mean: -0.030716, Risky mean: -0.032959
âŒ Error testing {'layer': 3, 'feature_id': 1566, 'cohen_d': -0.765625, 'p_value': 1.6215700953361645e-27, 'bankrupt_mean': -0.032958984375, 'safe_mean': -0.0307159423828125, 'bankrupt_std': 0.0030879974365234375, 'safe_std': 0.0029296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1728
   Cohen's d: -0.766
   Safe mean: 0.004269, Risky mean: 0.002438
âŒ Error testing {'layer': 3, 'feature_id': 1728, 'cohen_d': -0.765625, 'p_value': 1.0267896314280773e-27, 'bankrupt_mean': 0.002437591552734375, 'safe_mean': 0.004268646240234375, 'bankrupt_std': 0.002223968505859375, 'safe_std': 0.002391815185546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2036
   Cohen's d: 0.766
   Safe mean: -0.010239, Risky mean: -0.008675
âŒ Error testing {'layer': 3, 'feature_id': 2036, 'cohen_d': 0.765625, 'p_value': 1.6293822277488302e-27, 'bankrupt_mean': -0.00867462158203125, 'safe_mean': -0.0102386474609375, 'bankrupt_std': 0.001708984375, 'safe_std': 0.0020580291748046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-65
   Cohen's d: 0.765
   Safe mean: 0.011810, Risky mean: 0.013939
âŒ Error testing {'layer': 3, 'feature_id': 65, 'cohen_d': 0.76513671875, 'p_value': 1.2116559111152219e-27, 'bankrupt_mean': 0.01393890380859375, 'safe_mean': 0.011810302734375, 'bankrupt_std': 0.0022640228271484375, 'safe_std': 0.0027942657470703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2730
   Cohen's d: 0.764
   Safe mean: -0.006874, Risky mean: -0.005596
âŒ Error testing {'layer': 3, 'feature_id': 2730, 'cohen_d': 0.763671875, 'p_value': 2.5153664504214866e-27, 'bankrupt_mean': -0.005596160888671875, 'safe_mean': -0.00687408447265625, 'bankrupt_std': 0.0018110275268554688, 'safe_std': 0.0016736984252929688}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1667
   Cohen's d: 0.763
   Safe mean: 0.026016, Risky mean: 0.027252
âŒ Error testing {'layer': 3, 'feature_id': 1667, 'cohen_d': 0.76318359375, 'p_value': 2.6978965398606487e-27, 'bankrupt_mean': 0.027252197265625, 'safe_mean': 0.0260162353515625, 'bankrupt_std': 0.0017604827880859375, 'safe_std': 0.0016193389892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2227
   Cohen's d: -0.762
   Safe mean: 0.001543, Risky mean: -0.000659
âŒ Error testing {'layer': 3, 'feature_id': 2227, 'cohen_d': -0.76171875, 'p_value': 2.664456053293212e-27, 'bankrupt_mean': -0.0006589889526367188, 'safe_mean': 0.0015430450439453125, 'bankrupt_std': 0.00234222412109375, 'safe_std': 0.0029087066650390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2434
   Cohen's d: -0.761
   Safe mean: 0.016617, Risky mean: 0.014740
âŒ Error testing {'layer': 3, 'feature_id': 2434, 'cohen_d': -0.76123046875, 'p_value': 2.1058231171516105e-27, 'bankrupt_mean': 0.014739990234375, 'safe_mean': 0.0166168212890625, 'bankrupt_std': 0.0023288726806640625, 'safe_std': 0.0024662017822265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-2783
   Cohen's d: 0.761
   Safe mean: 0.008698, Risky mean: 0.011711
âŒ Error testing {'layer': 3, 'feature_id': 2783, 'cohen_d': 0.76123046875, 'p_value': 2.599842980751024e-27, 'bankrupt_mean': 0.01171112060546875, 'safe_mean': 0.008697509765625, 'bankrupt_std': 0.00417327880859375, 'safe_std': 0.0039520263671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2985
   Cohen's d: 0.760
   Safe mean: 0.012184, Risky mean: 0.013885
âŒ Error testing {'layer': 3, 'feature_id': 2985, 'cohen_d': 0.76025390625, 'p_value': 4.0532085886076235e-27, 'bankrupt_mean': 0.013885498046875, 'safe_mean': 0.01218414306640625, 'bankrupt_std': 0.0024166107177734375, 'safe_std': 0.0022373199462890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3877
   Cohen's d: 0.760
   Safe mean: 0.018417, Risky mean: 0.020187
âŒ Error testing {'layer': 3, 'feature_id': 3877, 'cohen_d': 0.76025390625, 'p_value': 4.199594916721871e-27, 'bankrupt_mean': 0.0201873779296875, 'safe_mean': 0.0184173583984375, 'bankrupt_std': 0.00212860107421875, 'safe_std': 0.00234222412109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3754
   Cohen's d: 0.758
   Safe mean: 0.009865, Risky mean: 0.011841
âŒ Error testing {'layer': 3, 'feature_id': 3754, 'cohen_d': 0.7578125, 'p_value': 3.426276412433185e-27, 'bankrupt_mean': 0.0118408203125, 'safe_mean': 0.00986480712890625, 'bankrupt_std': 0.0024662017822265625, 'safe_std': 0.0026073455810546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2338
   Cohen's d: -0.757
   Safe mean: 0.008286, Risky mean: 0.005608
âŒ Error testing {'layer': 3, 'feature_id': 2338, 'cohen_d': -0.7568359375, 'p_value': 4.568996934609984e-27, 'bankrupt_mean': 0.00560760498046875, 'safe_mean': 0.0082855224609375, 'bankrupt_std': 0.0031833648681640625, 'safe_std': 0.0035457611083984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3404
   Cohen's d: -0.756
   Safe mean: -0.022552, Risky mean: -0.023804
âŒ Error testing {'layer': 3, 'feature_id': 3404, 'cohen_d': -0.755859375, 'p_value': 8.089677654795722e-27, 'bankrupt_mean': -0.0238037109375, 'safe_mean': -0.022552490234375, 'bankrupt_std': 0.00177764892578125, 'safe_std': 0.00165557861328125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2640
   Cohen's d: -0.754
   Safe mean: -0.018158, Risky mean: -0.020157
âŒ Error testing {'layer': 3, 'feature_id': 2640, 'cohen_d': -0.75390625, 'p_value': 1.0059479134404636e-26, 'bankrupt_mean': -0.0201568603515625, 'safe_mean': -0.018157958984375, 'bankrupt_std': 0.0024662017822265625, 'safe_std': 0.00266265869140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3869
   Cohen's d: -0.754
   Safe mean: -0.055664, Risky mean: -0.058655
âŒ Error testing {'layer': 3, 'feature_id': 3869, 'cohen_d': -0.75390625, 'p_value': 8.017691409931557e-27, 'bankrupt_mean': -0.05865478515625, 'safe_mean': -0.0556640625, 'bankrupt_std': 0.002674102783203125, 'safe_std': 0.00400543212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2423
   Cohen's d: -0.752
   Safe mean: -0.003990, Risky mean: -0.005882
âŒ Error testing {'layer': 3, 'feature_id': 2423, 'cohen_d': -0.75244140625, 'p_value': 1.0551980453148554e-26, 'bankrupt_mean': -0.00588226318359375, 'safe_mean': -0.00399017333984375, 'bankrupt_std': 0.002223968505859375, 'safe_std': 0.00252532958984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-887
   Cohen's d: -0.751
   Safe mean: -0.039703, Risky mean: -0.042145
âŒ Error testing {'layer': 3, 'feature_id': 887, 'cohen_d': -0.75146484375, 'p_value': 1.2394987215375845e-26, 'bankrupt_mean': -0.042144775390625, 'safe_mean': -0.039703369140625, 'bankrupt_std': 0.002429962158203125, 'safe_std': 0.0032749176025390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3129
   Cohen's d: 0.751
   Safe mean: -0.022766, Risky mean: -0.021591
âŒ Error testing {'layer': 3, 'feature_id': 3129, 'cohen_d': 0.75146484375, 'p_value': 6.057232323747855e-27, 'bankrupt_mean': -0.0215911865234375, 'safe_mean': -0.02276611328125, 'bankrupt_std': 0.0018434524536132812, 'safe_std': 0.0015439987182617188}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1777
   Cohen's d: 0.750
   Safe mean: 0.006031, Risky mean: 0.007034
âŒ Error testing {'layer': 3, 'feature_id': 1777, 'cohen_d': 0.75048828125, 'p_value': 1.0036588097492401e-26, 'bankrupt_mean': 0.0070343017578125, 'safe_mean': 0.006031036376953125, 'bankrupt_std': 0.001220703125, 'safe_std': 0.0013370513916015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1504
   Cohen's d: 0.750
   Safe mean: 0.017776, Risky mean: 0.020218
âŒ Error testing {'layer': 3, 'feature_id': 1504, 'cohen_d': 0.74951171875, 'p_value': 1.7673906018228364e-26, 'bankrupt_mean': 0.0202178955078125, 'safe_mean': 0.0177764892578125, 'bankrupt_std': 0.0031070709228515625, 'safe_std': 0.0032672882080078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3456
   Cohen's d: 0.750
   Safe mean: 0.009750, Risky mean: 0.011772
âŒ Error testing {'layer': 3, 'feature_id': 3456, 'cohen_d': 0.74951171875, 'p_value': 1.1918684930408546e-26, 'bankrupt_mean': 0.01177215576171875, 'safe_mean': 0.0097503662109375, 'bankrupt_std': 0.002857208251953125, 'safe_std': 0.002685546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-541
   Cohen's d: -0.749
   Safe mean: -0.007473, Risky mean: -0.010635
âŒ Error testing {'layer': 3, 'feature_id': 541, 'cohen_d': -0.7490234375, 'p_value': 1.7612427144764855e-26, 'bankrupt_mean': -0.0106353759765625, 'safe_mean': -0.007472991943359375, 'bankrupt_std': 0.004093170166015625, 'safe_std': 0.004230499267578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1527
   Cohen's d: 0.749
   Safe mean: 0.004692, Risky mean: 0.006855
âŒ Error testing {'layer': 3, 'feature_id': 1527, 'cohen_d': 0.74853515625, 'p_value': 1.5121959577714894e-26, 'bankrupt_mean': 0.006855010986328125, 'safe_mean': 0.00469207763671875, 'bankrupt_std': 0.0027828216552734375, 'safe_std': 0.0028896331787109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3917
   Cohen's d: 0.748
   Safe mean: 0.009552, Risky mean: 0.011101
âŒ Error testing {'layer': 3, 'feature_id': 3917, 'cohen_d': 0.74755859375, 'p_value': 2.523614706896812e-26, 'bankrupt_mean': 0.01110076904296875, 'safe_mean': 0.009552001953125, 'bankrupt_std': 0.0021839141845703125, 'safe_std': 0.002071380615234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1698
   Cohen's d: -0.746
   Safe mean: 0.018082, Risky mean: 0.016403
âŒ Error testing {'layer': 3, 'feature_id': 1698, 'cohen_d': -0.74560546875, 'p_value': 3.509656152000418e-26, 'bankrupt_mean': 0.0164031982421875, 'safe_mean': 0.0180816650390625, 'bankrupt_std': 0.0019989013671875, 'safe_std': 0.0022640228271484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-63
   Cohen's d: -0.744
   Safe mean: 0.012093, Risky mean: 0.009773
âŒ Error testing {'layer': 3, 'feature_id': 63, 'cohen_d': -0.744140625, 'p_value': 4.1219097130784727e-26, 'bankrupt_mean': 0.00977325439453125, 'safe_mean': 0.01209259033203125, 'bankrupt_std': 0.00266265869140625, 'safe_std': 0.00313568115234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-723
   Cohen's d: 0.743
   Safe mean: -0.001122, Risky mean: 0.000897
âŒ Error testing {'layer': 3, 'feature_id': 723, 'cohen_d': 0.7431640625, 'p_value': 3.3056868408761837e-26, 'bankrupt_mean': 0.0008974075317382812, 'safe_mean': -0.0011224746704101562, 'bankrupt_std': 0.0025482177734375, 'safe_std': 0.0027179718017578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-105
   Cohen's d: 0.743
   Safe mean: -0.011787, Risky mean: -0.010048
âŒ Error testing {'layer': 3, 'feature_id': 105, 'cohen_d': 0.74267578125, 'p_value': 5.0888753419854835e-26, 'bankrupt_mean': -0.01004791259765625, 'safe_mean': -0.01178741455078125, 'bankrupt_std': 0.002071380615234375, 'safe_std': 0.002353668212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3518
   Cohen's d: -0.743
   Safe mean: -0.008087, Risky mean: -0.009369
âŒ Error testing {'layer': 3, 'feature_id': 3518, 'cohen_d': -0.74267578125, 'p_value': 5.235758522267525e-26, 'bankrupt_mean': -0.009368896484375, 'safe_mean': -0.008087158203125, 'bankrupt_std': 0.001220703125, 'safe_std': 0.001743316650390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1788
   Cohen's d: -0.742
   Safe mean: 0.010681, Risky mean: 0.009956
âŒ Error testing {'layer': 3, 'feature_id': 1788, 'cohen_d': -0.7421875, 'p_value': 4.1487004852577224e-26, 'bankrupt_mean': 0.00995635986328125, 'safe_mean': 0.01068115234375, 'bankrupt_std': 0.0009455680847167969, 'safe_std': 0.0009765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3694
   Cohen's d: 0.742
   Safe mean: -0.016479, Risky mean: -0.014732
âŒ Error testing {'layer': 3, 'feature_id': 3694, 'cohen_d': 0.7421875, 'p_value': 5.807319578505433e-26, 'bankrupt_mean': -0.01473236083984375, 'safe_mean': -0.0164794921875, 'bankrupt_std': 0.0020999908447265625, 'safe_std': 0.0023670196533203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3295
   Cohen's d: 0.741
   Safe mean: 0.003723, Risky mean: 0.005760
âŒ Error testing {'layer': 3, 'feature_id': 3295, 'cohen_d': 0.74072265625, 'p_value': 5.354567490097973e-26, 'bankrupt_mean': 0.00576019287109375, 'safe_mean': 0.00372314453125, 'bankrupt_std': 0.002651214599609375, 'safe_std': 0.002750396728515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3858
   Cohen's d: 0.741
   Safe mean: -0.008965, Risky mean: -0.007221
âŒ Error testing {'layer': 3, 'feature_id': 3858, 'cohen_d': 0.74072265625, 'p_value': 8.209360525341634e-26, 'bankrupt_mean': -0.007221221923828125, 'safe_mean': -0.00896453857421875, 'bankrupt_std': 0.0017261505126953125, 'safe_std': 0.00238037109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-441
   Cohen's d: -0.739
   Safe mean: 0.000505, Risky mean: -0.001576
âŒ Error testing {'layer': 3, 'feature_id': 441, 'cohen_d': -0.7392578125, 'p_value': 8.664631987327557e-26, 'bankrupt_mean': -0.0015764236450195312, 'safe_mean': 0.0005049705505371094, 'bankrupt_std': 0.0026187896728515625, 'safe_std': 0.002826690673828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1234
   Cohen's d: 0.737
   Safe mean: -0.020081, Risky mean: -0.018433
âŒ Error testing {'layer': 3, 'feature_id': 1234, 'cohen_d': 0.73681640625, 'p_value': 7.837255018327706e-26, 'bankrupt_mean': -0.0184326171875, 'safe_mean': -0.02008056640625, 'bankrupt_std': 0.0024166107177734375, 'safe_std': 0.002223968505859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-577
   Cohen's d: -0.736
   Safe mean: 0.009750, Risky mean: 0.007339
âŒ Error testing {'layer': 3, 'feature_id': 577, 'cohen_d': -0.736328125, 'p_value': 9.807727692472317e-26, 'bankrupt_mean': 0.0073394775390625, 'safe_mean': 0.0097503662109375, 'bankrupt_std': 0.003383636474609375, 'safe_std': 0.0032672882080078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-244
   Cohen's d: 0.735
   Safe mean: -0.000145, Risky mean: 0.001461
âŒ Error testing {'layer': 3, 'feature_id': 244, 'cohen_d': 0.7353515625, 'p_value': 1.0388700417354468e-25, 'bankrupt_mean': 0.001461029052734375, 'safe_mean': -0.00014495849609375, 'bankrupt_std': 0.0020580291748046875, 'safe_std': 0.0021839141845703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2073
   Cohen's d: -0.735
   Safe mean: 0.014717, Risky mean: 0.012733
âŒ Error testing {'layer': 3, 'feature_id': 2073, 'cohen_d': -0.7353515625, 'p_value': 1.348557996402378e-25, 'bankrupt_mean': 0.01273345947265625, 'safe_mean': 0.01471710205078125, 'bankrupt_std': 0.0024166107177734375, 'safe_std': 0.00270843505859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1733
   Cohen's d: 0.734
   Safe mean: 0.032532, Risky mean: 0.033966
âŒ Error testing {'layer': 3, 'feature_id': 1733, 'cohen_d': 0.734375, 'p_value': 1.8375541113846777e-25, 'bankrupt_mean': 0.033966064453125, 'safe_mean': 0.03253173828125, 'bankrupt_std': 0.0015821456909179688, 'safe_std': 0.0019683837890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3151
   Cohen's d: -0.733
   Safe mean: 0.004631, Risky mean: 0.002567
âŒ Error testing {'layer': 3, 'feature_id': 3151, 'cohen_d': -0.73291015625, 'p_value': 1.579574117153702e-25, 'bankrupt_mean': 0.002567291259765625, 'safe_mean': 0.00463104248046875, 'bankrupt_std': 0.0030002593994140625, 'safe_std': 0.0028057098388671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-624
   Cohen's d: 0.732
   Safe mean: -0.010307, Risky mean: -0.008934
âŒ Error testing {'layer': 3, 'feature_id': 624, 'cohen_d': 0.732421875, 'p_value': 1.855338952606364e-25, 'bankrupt_mean': -0.00893402099609375, 'safe_mean': -0.01030731201171875, 'bankrupt_std': 0.001827239990234375, 'safe_std': 0.0018749237060546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-645
   Cohen's d: -0.732
   Safe mean: 0.014389, Risky mean: 0.012566
âŒ Error testing {'layer': 3, 'feature_id': 645, 'cohen_d': -0.732421875, 'p_value': 2.518084038953151e-25, 'bankrupt_mean': 0.01256561279296875, 'safe_mean': 0.0143890380859375, 'bankrupt_std': 0.0026416778564453125, 'safe_std': 0.0024890899658203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1699
   Cohen's d: -0.732
   Safe mean: -0.000669, Risky mean: -0.002544
âŒ Error testing {'layer': 3, 'feature_id': 1699, 'cohen_d': -0.732421875, 'p_value': 1.5927044412259839e-25, 'bankrupt_mean': -0.002544403076171875, 'safe_mean': -0.0006694793701171875, 'bankrupt_std': 0.0019683837890625, 'safe_std': 0.0025730133056640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-576
   Cohen's d: -0.731
   Safe mean: -0.005386, Risky mean: -0.006313
âŒ Error testing {'layer': 3, 'feature_id': 576, 'cohen_d': -0.73095703125, 'p_value': 5.278649886879802e-25, 'bankrupt_mean': -0.006313323974609375, 'safe_mean': -0.0053863525390625, 'bankrupt_std': 0.0015048980712890625, 'safe_std': 0.0012683868408203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1546
   Cohen's d: 0.730
   Safe mean: 0.006088, Risky mean: 0.007957
âŒ Error testing {'layer': 3, 'feature_id': 1546, 'cohen_d': 0.73046875, 'p_value': 2.6277380949305213e-25, 'bankrupt_mean': 0.00795745849609375, 'safe_mean': 0.0060882568359375, 'bankrupt_std': 0.002826690673828125, 'safe_std': 0.0025482177734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1459
   Cohen's d: 0.730
   Safe mean: -0.001681, Risky mean: 0.000288
âŒ Error testing {'layer': 3, 'feature_id': 1459, 'cohen_d': 0.72998046875, 'p_value': 3.3058686649912833e-25, 'bankrupt_mean': 0.0002880096435546875, 'safe_mean': -0.0016813278198242188, 'bankrupt_std': 0.0024662017822265625, 'safe_std': 0.00270843505859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3400
   Cohen's d: 0.730
   Safe mean: -0.016266, Risky mean: -0.013771
âŒ Error testing {'layer': 3, 'feature_id': 3400, 'cohen_d': 0.72998046875, 'p_value': 3.2044976524545088e-25, 'bankrupt_mean': -0.01377105712890625, 'safe_mean': -0.016265869140625, 'bankrupt_std': 0.00266265869140625, 'safe_std': 0.003444671630859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-963
   Cohen's d: -0.728
   Safe mean: 0.004822, Risky mean: 0.002512
âŒ Error testing {'layer': 3, 'feature_id': 963, 'cohen_d': -0.7275390625, 'p_value': 4.1377321627271715e-25, 'bankrupt_mean': 0.0025119781494140625, 'safe_mean': 0.00482177734375, 'bankrupt_std': 0.0026073455810546875, 'safe_std': 0.003192901611328125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-59
   Cohen's d: -0.727
   Safe mean: -0.062744, Risky mean: -0.064880
âŒ Error testing {'layer': 3, 'feature_id': 59, 'cohen_d': -0.7265625, 'p_value': 4.907891623819725e-25, 'bankrupt_mean': -0.06488037109375, 'safe_mean': -0.062744140625, 'bankrupt_std': 0.002315521240234375, 'safe_std': 0.002960205078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  31%|â–ˆâ–ˆâ–ˆ       | 184/600 [00:00<00:01, 334.59it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-3228
   Cohen's d: 0.726
   Safe mean: 0.002651, Risky mean: 0.005157
âŒ Error testing {'layer': 3, 'feature_id': 3228, 'cohen_d': 0.72607421875, 'p_value': 5.341757254338641e-25, 'bankrupt_mean': 0.005157470703125, 'safe_mean': 0.002651214599609375, 'bankrupt_std': 0.0034694671630859375, 'safe_std': 0.003452301025390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1355
   Cohen's d: 0.723
   Safe mean: -0.003159, Risky mean: -0.000932
âŒ Error testing {'layer': 3, 'feature_id': 1355, 'cohen_d': 0.72314453125, 'p_value': 8.930757332779526e-25, 'bankrupt_mean': -0.0009322166442871094, 'safe_mean': -0.0031585693359375, 'bankrupt_std': 0.0028896331787109375, 'safe_std': 0.0030879974365234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3515
   Cohen's d: -0.723
   Safe mean: 0.009712, Risky mean: 0.005486
âŒ Error testing {'layer': 3, 'feature_id': 3515, 'cohen_d': -0.72314453125, 'p_value': 8.33952784581235e-25, 'bankrupt_mean': 0.00548553466796875, 'safe_mean': 0.00971221923828125, 'bankrupt_std': 0.004833221435546875, 'safe_std': 0.005878448486328125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-553
   Cohen's d: -0.723
   Safe mean: -0.009277, Risky mean: -0.010742
âŒ Error testing {'layer': 3, 'feature_id': 553, 'cohen_d': -0.72265625, 'p_value': 6.537484404566615e-25, 'bankrupt_mean': -0.0107421875, 'safe_mean': -0.00927734375, 'bankrupt_std': 0.0018434524536132812, 'safe_std': 0.0020275115966796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1009
   Cohen's d: 0.721
   Safe mean: -0.007458, Risky mean: -0.004032
âŒ Error testing {'layer': 3, 'feature_id': 1009, 'cohen_d': 0.720703125, 'p_value': 1.0751184985561295e-24, 'bankrupt_mean': -0.004032135009765625, 'safe_mean': -0.007457733154296875, 'bankrupt_std': 0.00431060791015625, 'safe_std': 0.004764556884765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1283
   Cohen's d: -0.719
   Safe mean: -0.016785, Risky mean: -0.017731
âŒ Error testing {'layer': 3, 'feature_id': 1283, 'cohen_d': -0.71923828125, 'p_value': 6.815240580856948e-25, 'bankrupt_mean': -0.017730712890625, 'safe_mean': -0.01678466796875, 'bankrupt_std': 0.0010356903076171875, 'safe_std': 0.0013151168823242188}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1391
   Cohen's d: 0.719
   Safe mean: -0.029678, Risky mean: -0.027542
âŒ Error testing {'layer': 3, 'feature_id': 1391, 'cohen_d': 0.71923828125, 'p_value': 1.542187357369261e-24, 'bankrupt_mean': -0.0275421142578125, 'safe_mean': -0.0296783447265625, 'bankrupt_std': 0.00305938720703125, 'safe_std': 0.0029697418212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-58
   Cohen's d: 0.719
   Safe mean: 0.000801, Risky mean: 0.002493
âŒ Error testing {'layer': 3, 'feature_id': 58, 'cohen_d': 0.71875, 'p_value': 1.319361491544106e-24, 'bankrupt_mean': 0.0024929046630859375, 'safe_mean': 0.0008006095886230469, 'bankrupt_std': 0.00225067138671875, 'safe_std': 0.002353668212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2442
   Cohen's d: -0.719
   Safe mean: 0.003551, Risky mean: 0.000149
âŒ Error testing {'layer': 3, 'feature_id': 2442, 'cohen_d': -0.71875, 'p_value': 1.4188634069215154e-24, 'bankrupt_mean': 0.00014901161193847656, 'safe_mean': 0.003551483154296875, 'bankrupt_std': 0.004276275634765625, 'safe_std': 0.0047454833984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3390
   Cohen's d: -0.719
   Safe mean: -0.008232, Risky mean: -0.010521
âŒ Error testing {'layer': 3, 'feature_id': 3390, 'cohen_d': -0.71875, 'p_value': 1.538494393537516e-24, 'bankrupt_mean': -0.01052093505859375, 'safe_mean': -0.00823211669921875, 'bankrupt_std': 0.0032482147216796875, 'safe_std': 0.0031833648681640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1407
   Cohen's d: -0.718
   Safe mean: -0.004627, Risky mean: -0.005802
âŒ Error testing {'layer': 3, 'feature_id': 1407, 'cohen_d': -0.7177734375, 'p_value': 1.2840683591922618e-24, 'bankrupt_mean': -0.005802154541015625, 'safe_mean': -0.004627227783203125, 'bankrupt_std': 0.00146484375, 'safe_std': 0.0016374588012695312}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2569
   Cohen's d: 0.718
   Safe mean: 0.008904, Risky mean: 0.010620
âŒ Error testing {'layer': 3, 'feature_id': 2569, 'cohen_d': 0.7177734375, 'p_value': 1.5229605479274383e-24, 'bankrupt_mean': 0.0106201171875, 'safe_mean': 0.00890350341796875, 'bankrupt_std': 0.0022907257080078125, 'safe_std': 0.002391815185546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-4006
   Cohen's d: -0.718
   Safe mean: 0.012749, Risky mean: 0.009758
âŒ Error testing {'layer': 3, 'feature_id': 4006, 'cohen_d': -0.7177734375, 'p_value': 1.7251607781106462e-24, 'bankrupt_mean': 0.00975799560546875, 'safe_mean': 0.01274871826171875, 'bankrupt_std': 0.0037899017333984375, 'safe_std': 0.004180908203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-817
   Cohen's d: 0.717
   Safe mean: -0.014786, Risky mean: -0.012932
âŒ Error testing {'layer': 3, 'feature_id': 817, 'cohen_d': 0.71728515625, 'p_value': 1.4339546870289773e-24, 'bankrupt_mean': -0.01293182373046875, 'safe_mean': -0.0147857666015625, 'bankrupt_std': 0.0024166107177734375, 'safe_std': 0.0025844573974609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-918
   Cohen's d: -0.717
   Safe mean: -0.013840, Risky mean: -0.014679
âŒ Error testing {'layer': 3, 'feature_id': 918, 'cohen_d': -0.716796875, 'p_value': 8.64751985641035e-25, 'bankrupt_mean': -0.014678955078125, 'safe_mean': -0.0138397216796875, 'bankrupt_std': 0.0008459091186523438, 'safe_std': 0.001171112060546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1043
   Cohen's d: 0.716
   Safe mean: -0.006413, Risky mean: -0.005363
âŒ Error testing {'layer': 3, 'feature_id': 1043, 'cohen_d': 0.71630859375, 'p_value': 1.0397808129898047e-24, 'bankrupt_mean': -0.00536346435546875, 'safe_mean': -0.006412506103515625, 'bankrupt_std': 0.0017261505126953125, 'safe_std': 0.0014448165893554688}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1316
   Cohen's d: 0.716
   Safe mean: 0.015656, Risky mean: 0.017761
âŒ Error testing {'layer': 3, 'feature_id': 1316, 'cohen_d': 0.71630859375, 'p_value': 2.2991379830760387e-24, 'bankrupt_mean': 0.01776123046875, 'safe_mean': 0.015655517578125, 'bankrupt_std': 0.0030002593994140625, 'safe_std': 0.0029392242431640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2735
   Cohen's d: -0.715
   Safe mean: -0.001563, Risky mean: -0.002695
âŒ Error testing {'layer': 3, 'feature_id': 2735, 'cohen_d': -0.71533203125, 'p_value': 1.4101428768918764e-24, 'bankrupt_mean': -0.0026950836181640625, 'safe_mean': -0.0015630722045898438, 'bankrupt_std': 0.0013151168823242188, 'safe_std': 0.0015821456909179688}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2456
   Cohen's d: 0.715
   Safe mean: 0.022018, Risky mean: 0.025650
âŒ Error testing {'layer': 3, 'feature_id': 2456, 'cohen_d': 0.71484375, 'p_value': 2.2586259374847134e-24, 'bankrupt_mean': 0.0256500244140625, 'safe_mean': 0.0220184326171875, 'bankrupt_std': 0.004062652587890625, 'safe_std': 0.00510406494140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2590
   Cohen's d: 0.714
   Safe mean: 0.017395, Risky mean: 0.018768
âŒ Error testing {'layer': 3, 'feature_id': 2590, 'cohen_d': 0.71435546875, 'p_value': 4.282422025866569e-24, 'bankrupt_mean': 0.018768310546875, 'safe_mean': 0.01739501953125, 'bankrupt_std': 0.0016918182373046875, 'safe_std': 0.0019378662109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3825
   Cohen's d: -0.714
   Safe mean: -0.007030, Risky mean: -0.007771
âŒ Error testing {'layer': 3, 'feature_id': 3825, 'cohen_d': -0.71435546875, 'p_value': 3.3566106687113964e-24, 'bankrupt_mean': -0.007770538330078125, 'safe_mean': -0.007030487060546875, 'bankrupt_std': 0.0010919570922851562, 'safe_std': 0.0010356903076171875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2055
   Cohen's d: 0.713
   Safe mean: -0.001067, Risky mean: 0.000691
âŒ Error testing {'layer': 3, 'feature_id': 2055, 'cohen_d': 0.712890625, 'p_value': 4.205212964761719e-24, 'bankrupt_mean': 0.0006914138793945312, 'safe_mean': -0.0010671615600585938, 'bankrupt_std': 0.0026302337646484375, 'safe_std': 0.0024662017822265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2126
   Cohen's d: -0.713
   Safe mean: 0.035461, Risky mean: 0.033295
âŒ Error testing {'layer': 3, 'feature_id': 2126, 'cohen_d': -0.712890625, 'p_value': 3.397014237664627e-24, 'bankrupt_mean': 0.033294677734375, 'safe_mean': 0.03546142578125, 'bankrupt_std': 0.003009796142578125, 'safe_std': 0.003040313720703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2539
   Cohen's d: -0.713
   Safe mean: 0.016022, Risky mean: 0.014427
âŒ Error testing {'layer': 3, 'feature_id': 2539, 'cohen_d': -0.712890625, 'p_value': 4.945317346967718e-24, 'bankrupt_mean': 0.01442718505859375, 'safe_mean': 0.016021728515625, 'bankrupt_std': 0.0020427703857421875, 'safe_std': 0.00225067138671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1448
   Cohen's d: -0.712
   Safe mean: 0.001047, Risky mean: -0.001243
âŒ Error testing {'layer': 3, 'feature_id': 1448, 'cohen_d': -0.71240234375, 'p_value': 4.254744923710982e-24, 'bankrupt_mean': -0.0012426376342773438, 'safe_mean': 0.0010471343994140625, 'bankrupt_std': 0.0031070709228515625, 'safe_std': 0.0032196044921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1763
   Cohen's d: 0.712
   Safe mean: 0.005970, Risky mean: 0.007866
âŒ Error testing {'layer': 3, 'feature_id': 1763, 'cohen_d': 0.7119140625, 'p_value': 4.3448000752330404e-24, 'bankrupt_mean': 0.00786590576171875, 'safe_mean': 0.005970001220703125, 'bankrupt_std': 0.0027179718017578125, 'safe_std': 0.00266265869140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2605
   Cohen's d: -0.710
   Safe mean: -0.022507, Risky mean: -0.024506
âŒ Error testing {'layer': 3, 'feature_id': 2605, 'cohen_d': -0.7099609375, 'p_value': 5.886959656814348e-24, 'bankrupt_mean': -0.024505615234375, 'safe_mean': -0.0225067138671875, 'bankrupt_std': 0.0022106170654296875, 'safe_std': 0.0028362274169921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2240
   Cohen's d: -0.707
   Safe mean: -0.022171, Risky mean: -0.023834
âŒ Error testing {'layer': 3, 'feature_id': 2240, 'cohen_d': -0.70654296875, 'p_value': 7.05452760190464e-24, 'bankrupt_mean': -0.023834228515625, 'safe_mean': -0.0221710205078125, 'bankrupt_std': 0.0028781890869140625, 'safe_std': 0.0023288726806640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-3279
   Cohen's d: -0.706
   Safe mean: -0.004131, Risky mean: -0.006191
âŒ Error testing {'layer': 3, 'feature_id': 3279, 'cohen_d': -0.70556640625, 'p_value': 9.925405406879047e-24, 'bankrupt_mean': -0.006191253662109375, 'safe_mean': -0.004131317138671875, 'bankrupt_std': 0.0025959014892578125, 'safe_std': 0.0029296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2736
   Cohen's d: -0.705
   Safe mean: 0.018341, Risky mean: 0.017212
âŒ Error testing {'layer': 3, 'feature_id': 2736, 'cohen_d': -0.705078125, 'p_value': 7.922321976067753e-24, 'bankrupt_mean': 0.0172119140625, 'safe_mean': 0.018341064453125, 'bankrupt_std': 0.00146484375, 'safe_std': 0.0016012191772460938}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-4016
   Cohen's d: 0.703
   Safe mean: -0.023682, Risky mean: -0.021545
âŒ Error testing {'layer': 3, 'feature_id': 4016, 'cohen_d': 0.70263671875, 'p_value': 1.5271663828188527e-23, 'bankrupt_mean': -0.02154541015625, 'safe_mean': -0.023681640625, 'bankrupt_std': 0.002429962158203125, 'safe_std': 0.00305938720703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3494
   Cohen's d: -0.702
   Safe mean: 0.013512, Risky mean: 0.011574
âŒ Error testing {'layer': 3, 'feature_id': 3494, 'cohen_d': -0.70166015625, 'p_value': 1.7548055097003005e-23, 'bankrupt_mean': 0.01157379150390625, 'safe_mean': 0.01351165771484375, 'bankrupt_std': 0.0024166107177734375, 'safe_std': 0.002773284912109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-814
   Cohen's d: 0.700
   Safe mean: 0.022232, Risky mean: 0.024536
âŒ Error testing {'layer': 3, 'feature_id': 814, 'cohen_d': 0.69970703125, 'p_value': 2.5682778794011757e-23, 'bankrupt_mean': 0.0245361328125, 'safe_mean': 0.0222320556640625, 'bankrupt_std': 0.0031070709228515625, 'safe_std': 0.00330352783203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2568
   Cohen's d: 0.700
   Safe mean: -0.023895, Risky mean: -0.022476
âŒ Error testing {'layer': 3, 'feature_id': 2568, 'cohen_d': 0.69970703125, 'p_value': 2.4688263678492747e-23, 'bankrupt_mean': -0.0224761962890625, 'safe_mean': -0.023895263671875, 'bankrupt_std': 0.002071380615234375, 'safe_std': 0.0020275115966796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3821
   Cohen's d: -0.700
   Safe mean: 0.052185, Risky mean: 0.050629
âŒ Error testing {'layer': 3, 'feature_id': 3821, 'cohen_d': -0.69970703125, 'p_value': 2.552353521138847e-23, 'bankrupt_mean': 0.050628662109375, 'safe_mean': 0.05218505859375, 'bankrupt_std': 0.0018749237060546875, 'safe_std': 0.0022373199462890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1712
   Cohen's d: 0.699
   Safe mean: 0.019043, Risky mean: 0.020767
âŒ Error testing {'layer': 3, 'feature_id': 1712, 'cohen_d': 0.69921875, 'p_value': 2.5858471554609127e-23, 'bankrupt_mean': 0.0207672119140625, 'safe_mean': 0.01904296875, 'bankrupt_std': 0.00212860107421875, 'safe_std': 0.0024776458740234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2953
   Cohen's d: 0.699
   Safe mean: 0.015480, Risky mean: 0.017090
âŒ Error testing {'layer': 3, 'feature_id': 2953, 'cohen_d': 0.69873046875, 'p_value': 2.4399098852049566e-23, 'bankrupt_mean': 0.01708984375, 'safe_mean': 0.01548004150390625, 'bankrupt_std': 0.0022640228271484375, 'safe_std': 0.0023040771484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3427
   Cohen's d: 0.699
   Safe mean: -0.020538, Risky mean: -0.016846
âŒ Error testing {'layer': 3, 'feature_id': 3427, 'cohen_d': 0.69873046875, 'p_value': 2.6620914953653835e-23, 'bankrupt_mean': -0.016845703125, 'safe_mean': -0.020538330078125, 'bankrupt_std': 0.004871368408203125, 'safe_std': 0.005298614501953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-599
   Cohen's d: -0.698
   Safe mean: -0.010048, Risky mean: -0.011795
âŒ Error testing {'layer': 3, 'feature_id': 599, 'cohen_d': -0.6982421875, 'p_value': 2.3752233637062e-23, 'bankrupt_mean': -0.0117950439453125, 'safe_mean': -0.01004791259765625, 'bankrupt_std': 0.0027179718017578125, 'safe_std': 0.0024890899658203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2343
   Cohen's d: -0.698
   Safe mean: -0.002436, Risky mean: -0.004833
âŒ Error testing {'layer': 3, 'feature_id': 2343, 'cohen_d': -0.69775390625, 'p_value': 3.0949739722721824e-23, 'bankrupt_mean': -0.004833221435546875, 'safe_mean': -0.0024356842041015625, 'bankrupt_std': 0.00321197509765625, 'safe_std': 0.003444671630859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3002
   Cohen's d: 0.698
   Safe mean: 0.008499, Risky mean: 0.010178
âŒ Error testing {'layer': 3, 'feature_id': 3002, 'cohen_d': 0.69775390625, 'p_value': 3.5342177514245547e-23, 'bankrupt_mean': 0.0101776123046875, 'safe_mean': 0.0084991455078125, 'bankrupt_std': 0.002170562744140625, 'safe_std': 0.0024166107177734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1102
   Cohen's d: 0.697
   Safe mean: 0.028305, Risky mean: 0.029556
âŒ Error testing {'layer': 3, 'feature_id': 1102, 'cohen_d': 0.697265625, 'p_value': 8.265990942597183e-24, 'bankrupt_mean': 0.0295562744140625, 'safe_mean': 0.0283050537109375, 'bankrupt_std': 0.0020275115966796875, 'safe_std': 0.00177764892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 228/600 [00:00<00:01, 364.12it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-2008
   Cohen's d: 0.696
   Safe mean: 0.017807, Risky mean: 0.019638
âŒ Error testing {'layer': 3, 'feature_id': 2008, 'cohen_d': 0.6962890625, 'p_value': 4.4530284945362234e-23, 'bankrupt_mean': 0.0196380615234375, 'safe_mean': 0.0178070068359375, 'bankrupt_std': 0.002773284912109375, 'safe_std': 0.0026302337646484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2309
   Cohen's d: -0.696
   Safe mean: 0.015167, Risky mean: 0.012825
âŒ Error testing {'layer': 3, 'feature_id': 2309, 'cohen_d': -0.6962890625, 'p_value': 4.2285808920627506e-23, 'bankrupt_mean': 0.01282501220703125, 'safe_mean': 0.015167236328125, 'bankrupt_std': 0.0031833648681640625, 'safe_std': 0.0033740997314453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-324
   Cohen's d: -0.696
   Safe mean: -0.013878, Risky mean: -0.015602
âŒ Error testing {'layer': 3, 'feature_id': 324, 'cohen_d': -0.69580078125, 'p_value': 4.293772771979544e-23, 'bankrupt_mean': -0.01560211181640625, 'safe_mean': -0.01387786865234375, 'bankrupt_std': 0.002536773681640625, 'safe_std': 0.0024776458740234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1233
   Cohen's d: 0.695
   Safe mean: 0.049316, Risky mean: 0.051086
âŒ Error testing {'layer': 3, 'feature_id': 1233, 'cohen_d': 0.69482421875, 'p_value': 6.209374783730806e-23, 'bankrupt_mean': 0.05108642578125, 'safe_mean': 0.04931640625, 'bankrupt_std': 0.002391815185546875, 'safe_std': 0.002559661865234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-480
   Cohen's d: -0.694
   Safe mean: 0.004776, Risky mean: 0.003542
âŒ Error testing {'layer': 3, 'feature_id': 480, 'cohen_d': -0.6943359375, 'p_value': 4.387200524052414e-23, 'bankrupt_mean': 0.0035419464111328125, 'safe_mean': 0.0047760009765625, 'bankrupt_std': 0.001708984375, 'safe_std': 0.00177764892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1944
   Cohen's d: -0.694
   Safe mean: -0.006413, Risky mean: -0.010048
âŒ Error testing {'layer': 3, 'feature_id': 1944, 'cohen_d': -0.6943359375, 'p_value': 5.0641101404280473e-23, 'bankrupt_mean': -0.01004791259765625, 'safe_mean': -0.006412506103515625, 'bankrupt_std': 0.00492095947265625, 'safe_std': 0.0052490234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2118
   Cohen's d: 0.694
   Safe mean: -0.031052, Risky mean: -0.029358
âŒ Error testing {'layer': 3, 'feature_id': 2118, 'cohen_d': 0.69384765625, 'p_value': 4.716869655388844e-23, 'bankrupt_mean': -0.02935791015625, 'safe_mean': -0.0310516357421875, 'bankrupt_std': 0.00234222412109375, 'safe_std': 0.00244140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3370
   Cohen's d: 0.693
   Safe mean: 0.005367, Risky mean: 0.008499
âŒ Error testing {'layer': 3, 'feature_id': 3370, 'cohen_d': 0.693359375, 'p_value': 5.87457771795622e-23, 'bankrupt_mean': 0.0084991455078125, 'safe_mean': 0.005367279052734375, 'bankrupt_std': 0.004230499267578125, 'safe_std': 0.004520416259765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2974
   Cohen's d: 0.693
   Safe mean: -0.011948, Risky mean: -0.010307
âŒ Error testing {'layer': 3, 'feature_id': 2974, 'cohen_d': 0.69287109375, 'p_value': 6.184965383589807e-23, 'bankrupt_mean': -0.01030731201171875, 'safe_mean': -0.0119476318359375, 'bankrupt_std': 0.002391815185546875, 'safe_std': 0.0023670196533203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3273
   Cohen's d: -0.690
   Safe mean: 0.013916, Risky mean: 0.013008
âŒ Error testing {'layer': 3, 'feature_id': 3273, 'cohen_d': -0.6904296875, 'p_value': 6.031461299880847e-23, 'bankrupt_mean': 0.01300811767578125, 'safe_mean': 0.013916015625, 'bankrupt_std': 0.001171112060546875, 'safe_std': 0.0013151168823242188}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3921
   Cohen's d: -0.690
   Safe mean: 0.016800, Risky mean: 0.014969
âŒ Error testing {'layer': 3, 'feature_id': 3921, 'cohen_d': -0.6904296875, 'p_value': 9.838325325970871e-23, 'bankrupt_mean': 0.0149688720703125, 'safe_mean': 0.0167999267578125, 'bankrupt_std': 0.002429962158203125, 'safe_std': 0.00266265869140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-972
   Cohen's d: -0.689
   Safe mean: -0.015236, Risky mean: -0.018112
âŒ Error testing {'layer': 3, 'feature_id': 972, 'cohen_d': -0.689453125, 'p_value': 1.0642346900856355e-22, 'bankrupt_mean': -0.0181121826171875, 'safe_mean': -0.01523590087890625, 'bankrupt_std': 0.00384521484375, 'safe_std': 0.004184722900390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3584
   Cohen's d: -0.688
   Safe mean: 0.004417, Risky mean: 0.002195
âŒ Error testing {'layer': 3, 'feature_id': 3584, 'cohen_d': -0.68798828125, 'p_value': 1.0997481445831902e-22, 'bankrupt_mean': 0.0021953582763671875, 'safe_mean': 0.00441741943359375, 'bankrupt_std': 0.0028476715087890625, 'safe_std': 0.003238677978515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3654
   Cohen's d: -0.688
   Safe mean: 0.001135, Risky mean: -0.000207
âŒ Error testing {'layer': 3, 'feature_id': 3654, 'cohen_d': -0.6875, 'p_value': 1.583724237964099e-22, 'bankrupt_mean': -0.00020742416381835938, 'safe_mean': 0.0011348724365234375, 'bankrupt_std': 0.0016012191772460938, 'safe_std': 0.0019683837890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-4039
   Cohen's d: 0.686
   Safe mean: -0.016296, Risky mean: -0.014664
âŒ Error testing {'layer': 3, 'feature_id': 4039, 'cohen_d': 0.68603515625, 'p_value': 1.7649290853497045e-22, 'bankrupt_mean': -0.0146636962890625, 'safe_mean': -0.01629638671875, 'bankrupt_std': 0.002086639404296875, 'safe_std': 0.002391815185546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-609
   Cohen's d: -0.685
   Safe mean: 0.026199, Risky mean: 0.025238
âŒ Error testing {'layer': 3, 'feature_id': 609, 'cohen_d': -0.68505859375, 'p_value': 1.721482744616833e-22, 'bankrupt_mean': 0.025238037109375, 'safe_mean': 0.0261993408203125, 'bankrupt_std': 0.0014028549194335938, 'safe_std': 0.0014028549194335938}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1505
   Cohen's d: 0.685
   Safe mean: 0.018326, Risky mean: 0.019272
âŒ Error testing {'layer': 3, 'feature_id': 1505, 'cohen_d': 0.68505859375, 'p_value': 1.0569434907702798e-22, 'bankrupt_mean': 0.0192718505859375, 'safe_mean': 0.0183258056640625, 'bankrupt_std': 0.0011186599731445312, 'safe_std': 0.00138092041015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2913
   Cohen's d: -0.684
   Safe mean: 0.005875, Risky mean: 0.003956
âŒ Error testing {'layer': 3, 'feature_id': 2913, 'cohen_d': -0.68408203125, 'p_value': 1.8466495004397803e-22, 'bankrupt_mean': 0.003955841064453125, 'safe_mean': 0.0058746337890625, 'bankrupt_std': 0.002696990966796875, 'safe_std': 0.0028057098388671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-344
   Cohen's d: -0.684
   Safe mean: 0.031982, Risky mean: 0.028824
âŒ Error testing {'layer': 3, 'feature_id': 344, 'cohen_d': -0.68359375, 'p_value': 2.2336347967432237e-22, 'bankrupt_mean': 0.0288238525390625, 'safe_mean': 0.031982421875, 'bankrupt_std': 0.0042724609375, 'safe_std': 0.00463104248046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-446
   Cohen's d: 0.683
   Safe mean: -0.011086, Risky mean: -0.008369
âŒ Error testing {'layer': 3, 'feature_id': 446, 'cohen_d': 0.68310546875, 'p_value': 2.2957929582533107e-22, 'bankrupt_mean': -0.00836944580078125, 'safe_mean': -0.01108551025390625, 'bankrupt_std': 0.0039825439453125, 'safe_std': 0.00397491455078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3249
   Cohen's d: 0.683
   Safe mean: -0.008369, Risky mean: -0.006535
âŒ Error testing {'layer': 3, 'feature_id': 3249, 'cohen_d': 0.68310546875, 'p_value': 2.611068355386786e-22, 'bankrupt_mean': -0.006534576416015625, 'safe_mean': -0.00836944580078125, 'bankrupt_std': 0.0020580291748046875, 'safe_std': 0.00270843505859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1515
   Cohen's d: 0.683
   Safe mean: 0.001974, Risky mean: 0.004360
âŒ Error testing {'layer': 3, 'feature_id': 1515, 'cohen_d': 0.6826171875, 'p_value': 2.4726863366741426e-22, 'bankrupt_mean': 0.004360198974609375, 'safe_mean': 0.0019741058349609375, 'bankrupt_std': 0.0034618377685546875, 'safe_std': 0.0034961700439453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-4009
   Cohen's d: -0.683
   Safe mean: 0.005150, Risky mean: 0.003925
âŒ Error testing {'layer': 3, 'feature_id': 4009, 'cohen_d': -0.6826171875, 'p_value': 1.9615676593454278e-22, 'bankrupt_mean': 0.003925323486328125, 'safe_mean': 0.00514984130859375, 'bankrupt_std': 0.0020999908447265625, 'safe_std': 0.00177764892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-388
   Cohen's d: -0.682
   Safe mean: -0.007351, Risky mean: -0.009560
âŒ Error testing {'layer': 3, 'feature_id': 388, 'cohen_d': -0.68212890625, 'p_value': 3.2417837152609704e-22, 'bankrupt_mean': -0.00955963134765625, 'safe_mean': -0.007350921630859375, 'bankrupt_std': 0.002826690673828125, 'safe_std': 0.00325775146484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3102
   Cohen's d: 0.681
   Safe mean: 0.029404, Risky mean: 0.031372
âŒ Error testing {'layer': 3, 'feature_id': 3102, 'cohen_d': 0.68115234375, 'p_value': 3.159255243850047e-22, 'bankrupt_mean': 0.0313720703125, 'safe_mean': 0.0294036865234375, 'bankrupt_std': 0.0026187896728515625, 'safe_std': 0.002899169921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2957
   Cohen's d: -0.681
   Safe mean: -0.014832, Risky mean: -0.016006
âŒ Error testing {'layer': 3, 'feature_id': 2957, 'cohen_d': -0.6806640625, 'p_value': 2.2436759244598624e-22, 'bankrupt_mean': -0.0160064697265625, 'safe_mean': -0.01483154296875, 'bankrupt_std': 0.0014848709106445312, 'safe_std': 0.0017261505126953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3031
   Cohen's d: 0.680
   Safe mean: 0.014122, Risky mean: 0.015419
âŒ Error testing {'layer': 3, 'feature_id': 3031, 'cohen_d': 0.68017578125, 'p_value': 3.8735917766777484e-22, 'bankrupt_mean': 0.01541900634765625, 'safe_mean': 0.01412200927734375, 'bankrupt_std': 0.0014448165893554688, 'safe_std': 0.001922607421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3112
   Cohen's d: 0.680
   Safe mean: -0.004951, Risky mean: -0.003185
âŒ Error testing {'layer': 3, 'feature_id': 3112, 'cohen_d': 0.68017578125, 'p_value': 3.4825156495519153e-22, 'bankrupt_mean': -0.003185272216796875, 'safe_mean': -0.00495147705078125, 'bankrupt_std': 0.0026187896728515625, 'safe_std': 0.0025959014892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-292
   Cohen's d: 0.679
   Safe mean: -0.017532, Risky mean: -0.015900
âŒ Error testing {'layer': 3, 'feature_id': 292, 'cohen_d': 0.6787109375, 'p_value': 4.467128036572316e-22, 'bankrupt_mean': -0.015899658203125, 'safe_mean': -0.0175323486328125, 'bankrupt_std': 0.002452850341796875, 'safe_std': 0.0024051666259765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1281
   Cohen's d: 0.679
   Safe mean: -0.014610, Risky mean: -0.012650
âŒ Error testing {'layer': 3, 'feature_id': 1281, 'cohen_d': 0.6787109375, 'p_value': 3.6743205776369317e-22, 'bankrupt_mean': -0.0126495361328125, 'safe_mean': -0.01461029052734375, 'bankrupt_std': 0.0027294158935546875, 'safe_std': 0.0028896331787109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-278
   Cohen's d: -0.678
   Safe mean: -0.002552, Risky mean: -0.004288
âŒ Error testing {'layer': 3, 'feature_id': 278, 'cohen_d': -0.67822265625, 'p_value': 5.3744138466104e-22, 'bankrupt_mean': -0.0042877197265625, 'safe_mean': -0.002552032470703125, 'bankrupt_std': 0.002277374267578125, 'safe_std': 0.0025730133056640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3114
   Cohen's d: 0.678
   Safe mean: 0.006695, Risky mean: 0.007988
âŒ Error testing {'layer': 3, 'feature_id': 3114, 'cohen_d': 0.67822265625, 'p_value': 4.1337978292630624e-22, 'bankrupt_mean': 0.00798797607421875, 'safe_mean': 0.006694793701171875, 'bankrupt_std': 0.001827239990234375, 'safe_std': 0.0019063949584960938}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3635
   Cohen's d: -0.677
   Safe mean: 0.041931, Risky mean: 0.039886
âŒ Error testing {'layer': 3, 'feature_id': 3635, 'cohen_d': -0.67724609375, 'p_value': 6.233495613013674e-22, 'bankrupt_mean': 0.039886474609375, 'safe_mean': 0.04193115234375, 'bankrupt_std': 0.0031452178955078125, 'safe_std': 0.0030193328857421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3360
   Cohen's d: 0.677
   Safe mean: 0.015656, Risky mean: 0.017822
âŒ Error testing {'layer': 3, 'feature_id': 3360, 'cohen_d': 0.6767578125, 'p_value': 5.807019232202868e-22, 'bankrupt_mean': 0.017822265625, 'safe_mean': 0.015655517578125, 'bankrupt_std': 0.00321197509765625, 'safe_std': 0.0032024383544921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2016
   Cohen's d: -0.676
   Safe mean: 0.047211, Risky mean: 0.046021
âŒ Error testing {'layer': 3, 'feature_id': 2016, 'cohen_d': -0.67626953125, 'p_value': 7.751030294333083e-22, 'bankrupt_mean': 0.0460205078125, 'safe_mean': 0.047210693359375, 'bankrupt_std': 0.0018749237060546875, 'safe_std': 0.0017604827880859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1072
   Cohen's d: 0.676
   Safe mean: -0.040253, Risky mean: -0.037750
âŒ Error testing {'layer': 3, 'feature_id': 1072, 'cohen_d': 0.67578125, 'p_value': 6.268963581918451e-22, 'bankrupt_mean': -0.037750244140625, 'safe_mean': -0.040252685546875, 'bankrupt_std': 0.004116058349609375, 'safe_std': 0.0036869049072265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1465
   Cohen's d: -0.676
   Safe mean: -0.019547, Risky mean: -0.020966
âŒ Error testing {'layer': 3, 'feature_id': 1465, 'cohen_d': -0.67578125, 'p_value': 5.7292925237951e-22, 'bankrupt_mean': -0.020965576171875, 'safe_mean': -0.0195465087890625, 'bankrupt_std': 0.0019989013671875, 'safe_std': 0.0020999908447265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3275
   Cohen's d: 0.674
   Safe mean: 0.026794, Risky mean: 0.028122
âŒ Error testing {'layer': 3, 'feature_id': 3275, 'cohen_d': 0.67431640625, 'p_value': 5.786356981496001e-22, 'bankrupt_mean': 0.0281219482421875, 'safe_mean': 0.02679443359375, 'bankrupt_std': 0.0017604827880859375, 'safe_std': 0.0019683837890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1101
   Cohen's d: -0.674
   Safe mean: -0.056305, Risky mean: -0.058868
âŒ Error testing {'layer': 3, 'feature_id': 1101, 'cohen_d': -0.673828125, 'p_value': 8.491521930532164e-22, 'bankrupt_mean': -0.058868408203125, 'safe_mean': -0.056304931640625, 'bankrupt_std': 0.003513336181640625, 'safe_std': 0.0038127899169921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3777
   Cohen's d: -0.674
   Safe mean: -0.022430, Risky mean: -0.024399
âŒ Error testing {'layer': 3, 'feature_id': 3777, 'cohen_d': -0.673828125, 'p_value': 9.142384560163322e-22, 'bankrupt_mean': -0.0243988037109375, 'safe_mean': -0.022430419921875, 'bankrupt_std': 0.0027294158935546875, 'safe_std': 0.0029296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-4063
   Cohen's d: -0.674
   Safe mean: 0.020111, Risky mean: 0.017303
âŒ Error testing {'layer': 3, 'feature_id': 4063, 'cohen_d': -0.673828125, 'p_value': 8.453539206907511e-22, 'bankrupt_mean': 0.017303466796875, 'safe_mean': 0.020111083984375, 'bankrupt_std': 0.004207611083984375, 'safe_std': 0.0041656494140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-665
   Cohen's d: 0.673
   Safe mean: -0.008423, Risky mean: -0.006168
âŒ Error testing {'layer': 3, 'feature_id': 665, 'cohen_d': 0.67333984375, 'p_value': 9.847992460594294e-22, 'bankrupt_mean': -0.006168365478515625, 'safe_mean': -0.0084228515625, 'bankrupt_std': 0.0036945343017578125, 'safe_std': 0.003337860107421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 275/600 [00:00<00:00, 392.77it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-2852
   Cohen's d: -0.673
   Safe mean: -0.007183, Risky mean: -0.008286
âŒ Error testing {'layer': 3, 'feature_id': 2852, 'cohen_d': -0.67333984375, 'p_value': 1.4496791206403179e-21, 'bankrupt_mean': -0.0082855224609375, 'safe_mean': -0.007183074951171875, 'bankrupt_std': 0.0018596649169921875, 'safe_std': 0.0016374588012695312}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-824
   Cohen's d: -0.672
   Safe mean: 0.033417, Risky mean: 0.031021
âŒ Error testing {'layer': 3, 'feature_id': 824, 'cohen_d': -0.67236328125, 'p_value': 1.0810645152215742e-21, 'bankrupt_mean': 0.0310211181640625, 'safe_mean': 0.033416748046875, 'bankrupt_std': 0.0033473968505859375, 'safe_std': 0.003570556640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2364
   Cohen's d: 0.671
   Safe mean: -0.004620, Risky mean: -0.002081
âŒ Error testing {'layer': 3, 'feature_id': 2364, 'cohen_d': 0.67138671875, 'p_value': 1.3802356330194051e-21, 'bankrupt_mean': -0.0020809173583984375, 'safe_mean': -0.004619598388671875, 'bankrupt_std': 0.0037021636962890625, 'safe_std': 0.0037899017333984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1770
   Cohen's d: 0.671
   Safe mean: 0.002718, Risky mean: 0.003630
âŒ Error testing {'layer': 3, 'feature_id': 1770, 'cohen_d': 0.6708984375, 'p_value': 1.2470595034609493e-21, 'bankrupt_mean': 0.0036296844482421875, 'safe_mean': 0.0027179718017578125, 'bankrupt_std': 0.0013370513916015625, 'safe_std': 0.0013589859008789062}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2117
   Cohen's d: -0.671
   Safe mean: -0.001075, Risky mean: -0.003403
âŒ Error testing {'layer': 3, 'feature_id': 2117, 'cohen_d': -0.6708984375, 'p_value': 1.2311836896630537e-21, 'bankrupt_mean': -0.0034027099609375, 'safe_mean': -0.0010747909545898438, 'bankrupt_std': 0.003383636474609375, 'safe_std': 0.0034694671630859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3708
   Cohen's d: -0.670
   Safe mean: 0.012848, Risky mean: 0.011559
âŒ Error testing {'layer': 3, 'feature_id': 3708, 'cohen_d': -0.67041015625, 'p_value': 9.514440754022836e-22, 'bankrupt_mean': 0.01155853271484375, 'safe_mean': 0.012847900390625, 'bankrupt_std': 0.001708984375, 'safe_std': 0.001922607421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-134
   Cohen's d: -0.670
   Safe mean: -0.023224, Risky mean: -0.025253
âŒ Error testing {'layer': 3, 'feature_id': 134, 'cohen_d': -0.669921875, 'p_value': 1.7235110352197633e-21, 'bankrupt_mean': -0.0252532958984375, 'safe_mean': -0.023223876953125, 'bankrupt_std': 0.0031833648681640625, 'safe_std': 0.00302886962890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-625
   Cohen's d: 0.670
   Safe mean: 0.004898, Risky mean: 0.006100
âŒ Error testing {'layer': 3, 'feature_id': 625, 'cohen_d': 0.669921875, 'p_value': 1.5285314834804763e-21, 'bankrupt_mean': 0.006099700927734375, 'safe_mean': 0.0048980712890625, 'bankrupt_std': 0.0018110275268554688, 'safe_std': 0.0017938613891601562}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1272
   Cohen's d: -0.670
   Safe mean: 0.018982, Risky mean: 0.016953
âŒ Error testing {'layer': 3, 'feature_id': 1272, 'cohen_d': -0.669921875, 'p_value': 1.324239506484291e-21, 'bankrupt_mean': 0.0169525146484375, 'safe_mean': 0.01898193359375, 'bankrupt_std': 0.0029201507568359375, 'safe_std': 0.00302886962890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3175
   Cohen's d: -0.670
   Safe mean: 0.021332, Risky mean: 0.019608
âŒ Error testing {'layer': 3, 'feature_id': 3175, 'cohen_d': -0.669921875, 'p_value': 1.4938757179425981e-21, 'bankrupt_mean': 0.0196075439453125, 'safe_mean': 0.021331787109375, 'bankrupt_std': 0.0026416778564453125, 'safe_std': 0.0025730133056640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3867
   Cohen's d: -0.670
   Safe mean: -0.009399, Risky mean: -0.011162
âŒ Error testing {'layer': 3, 'feature_id': 3867, 'cohen_d': -0.669921875, 'p_value': 1.470223166252365e-21, 'bankrupt_mean': -0.01116180419921875, 'safe_mean': -0.0093994140625, 'bankrupt_std': 0.002674102783203125, 'safe_std': 0.0026302337646484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-395
   Cohen's d: 0.669
   Safe mean: -0.003876, Risky mean: -0.002804
âŒ Error testing {'layer': 3, 'feature_id': 395, 'cohen_d': 0.66943359375, 'p_value': 2.3475703287290664e-21, 'bankrupt_mean': -0.002803802490234375, 'safe_mean': -0.003875732421875, 'bankrupt_std': 0.0012445449829101562, 'safe_std': 0.0016193389892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2444
   Cohen's d: 0.669
   Safe mean: -0.009872, Risky mean: -0.008263
âŒ Error testing {'layer': 3, 'feature_id': 2444, 'cohen_d': 0.66943359375, 'p_value': 1.282815211162385e-21, 'bankrupt_mean': -0.00826263427734375, 'safe_mean': -0.0098724365234375, 'bankrupt_std': 0.00225067138671875, 'safe_std': 0.0024051666259765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1343
   Cohen's d: -0.668
   Safe mean: -0.002323, Risky mean: -0.004444
âŒ Error testing {'layer': 3, 'feature_id': 1343, 'cohen_d': -0.66845703125, 'p_value': 1.6912432885005806e-21, 'bankrupt_mean': -0.004444122314453125, 'safe_mean': -0.002323150634765625, 'bankrupt_std': 0.0027942657470703125, 'safe_std': 0.0031833648681640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-730
   Cohen's d: 0.667
   Safe mean: -0.008667, Risky mean: -0.006233
âŒ Error testing {'layer': 3, 'feature_id': 730, 'cohen_d': 0.66748046875, 'p_value': 1.8689448300728718e-21, 'bankrupt_mean': -0.00623321533203125, 'safe_mean': -0.0086669921875, 'bankrupt_std': 0.0035552978515625, 'safe_std': 0.0036449432373046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1036
   Cohen's d: 0.667
   Safe mean: -0.014366, Risky mean: -0.012657
âŒ Error testing {'layer': 3, 'feature_id': 1036, 'cohen_d': 0.66748046875, 'p_value': 2.1340102059692295e-21, 'bankrupt_mean': -0.01265716552734375, 'safe_mean': -0.01436614990234375, 'bankrupt_std': 0.0025959014892578125, 'safe_std': 0.002559661865234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1645
   Cohen's d: -0.667
   Safe mean: -0.018265, Risky mean: -0.020172
âŒ Error testing {'layer': 3, 'feature_id': 1645, 'cohen_d': -0.66748046875, 'p_value': 2.1276628067925075e-21, 'bankrupt_mean': -0.020172119140625, 'safe_mean': -0.0182647705078125, 'bankrupt_std': 0.002899169921875, 'safe_std': 0.002857208251953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3018
   Cohen's d: 0.667
   Safe mean: 0.017288, Risky mean: 0.018997
âŒ Error testing {'layer': 3, 'feature_id': 3018, 'cohen_d': 0.66748046875, 'p_value': 2.0395327725870898e-21, 'bankrupt_mean': 0.0189971923828125, 'safe_mean': 0.0172882080078125, 'bankrupt_std': 0.001743316650390625, 'safe_std': 0.0025844573974609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-4094
   Cohen's d: -0.667
   Safe mean: -0.006115, Risky mean: -0.008110
âŒ Error testing {'layer': 3, 'feature_id': 4094, 'cohen_d': -0.6669921875, 'p_value': 1.929083504818431e-21, 'bankrupt_mean': -0.00811004638671875, 'safe_mean': -0.006114959716796875, 'bankrupt_std': 0.0025844573974609375, 'safe_std': 0.0030002593994140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3267
   Cohen's d: -0.666
   Safe mean: 0.015327, Risky mean: 0.013901
âŒ Error testing {'layer': 3, 'feature_id': 3267, 'cohen_d': -0.666015625, 'p_value': 2.8063618648276747e-21, 'bankrupt_mean': 0.0139007568359375, 'safe_mean': 0.01532745361328125, 'bankrupt_std': 0.002223968505859375, 'safe_std': 0.0021419525146484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3750
   Cohen's d: -0.666
   Safe mean: -0.017349, Risky mean: -0.018890
âŒ Error testing {'layer': 3, 'feature_id': 3750, 'cohen_d': -0.66552734375, 'p_value': 2.247966983946294e-21, 'bankrupt_mean': -0.018890380859375, 'safe_mean': -0.0173492431640625, 'bankrupt_std': 0.002170562744140625, 'safe_std': 0.002315521240234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3799
   Cohen's d: 0.666
   Safe mean: 0.008049, Risky mean: 0.009583
âŒ Error testing {'layer': 3, 'feature_id': 3799, 'cohen_d': 0.66552734375, 'p_value': 3.028332120337331e-21, 'bankrupt_mean': 0.00958251953125, 'safe_mean': 0.00804901123046875, 'bankrupt_std': 0.0020427703857421875, 'safe_std': 0.002315521240234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3051
   Cohen's d: -0.664
   Safe mean: -0.006104, Risky mean: -0.008926
âŒ Error testing {'layer': 3, 'feature_id': 3051, 'cohen_d': -0.6640625, 'p_value': 3.3404329922299083e-21, 'bankrupt_mean': -0.0089263916015625, 'safe_mean': -0.006103515625, 'bankrupt_std': 0.00433349609375, 'safe_std': 0.00424957275390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-804
   Cohen's d: 0.664
   Safe mean: -0.005993, Risky mean: -0.004219
âŒ Error testing {'layer': 3, 'feature_id': 804, 'cohen_d': 0.66357421875, 'p_value': 4.434817298352561e-21, 'bankrupt_mean': -0.00421905517578125, 'safe_mean': -0.005992889404296875, 'bankrupt_std': 0.002857208251953125, 'safe_std': 0.002674102783203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1595
   Cohen's d: 0.664
   Safe mean: 0.009972, Risky mean: 0.011421
âŒ Error testing {'layer': 3, 'feature_id': 1595, 'cohen_d': 0.66357421875, 'p_value': 3.231241849559254e-21, 'bankrupt_mean': 0.01142120361328125, 'safe_mean': 0.00997161865234375, 'bankrupt_std': 0.001708984375, 'safe_std': 0.002197265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1881
   Cohen's d: -0.663
   Safe mean: -0.021393, Risky mean: -0.022537
âŒ Error testing {'layer': 3, 'feature_id': 1881, 'cohen_d': -0.6630859375, 'p_value': 3.773267278333844e-21, 'bankrupt_mean': -0.0225372314453125, 'safe_mean': -0.021392822265625, 'bankrupt_std': 0.0017261505126953125, 'safe_std': 0.0017261505126953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1351
   Cohen's d: 0.663
   Safe mean: -0.024826, Risky mean: -0.023209
âŒ Error testing {'layer': 3, 'feature_id': 1351, 'cohen_d': 0.66259765625, 'p_value': 3.39065525934555e-21, 'bankrupt_mean': -0.0232086181640625, 'safe_mean': -0.0248260498046875, 'bankrupt_std': 0.0022907257080078125, 'safe_std': 0.00244140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-2397
   Cohen's d: -0.663
   Safe mean: 0.001587, Risky mean: -0.000607
âŒ Error testing {'layer': 3, 'feature_id': 2397, 'cohen_d': -0.66259765625, 'p_value': 3.783968104606934e-21, 'bankrupt_mean': -0.0006070137023925781, 'safe_mean': 0.0015869140625, 'bankrupt_std': 0.0026302337646484375, 'safe_std': 0.003330230712890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L3-383
   Cohen's d: -0.662
   Safe mean: -0.002703, Risky mean: -0.004890
âŒ Error testing {'layer': 3, 'feature_id': 383, 'cohen_d': -0.662109375, 'p_value': 4.2138441110533516e-21, 'bankrupt_mean': -0.00489044189453125, 'safe_mean': -0.0027027130126953125, 'bankrupt_std': 0.003078460693359375, 'safe_std': 0.00330352783203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-1197
   Cohen's d: -0.662
   Safe mean: 0.021240, Risky mean: 0.019241
âŒ Error testing {'layer': 3, 'feature_id': 1197, 'cohen_d': -0.662109375, 'p_value': 4.627857994798335e-21, 'bankrupt_mean': 0.0192413330078125, 'safe_mean': 0.021240234375, 'bankrupt_std': 0.0027942657470703125, 'safe_std': 0.00302886962890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3280
   Cohen's d: 0.661
   Safe mean: -0.006371, Risky mean: -0.005001
âŒ Error testing {'layer': 3, 'feature_id': 3280, 'cohen_d': 0.6611328125, 'p_value': 3.555413800453332e-21, 'bankrupt_mean': -0.005001068115234375, 'safe_mean': -0.00637054443359375, 'bankrupt_std': 0.0018434524536132812, 'safe_std': 0.002071380615234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3585
   Cohen's d: 0.661
   Safe mean: 0.087524, Risky mean: 0.089966
âŒ Error testing {'layer': 3, 'feature_id': 3585, 'cohen_d': 0.66064453125, 'p_value': 4.9923160681665e-21, 'bankrupt_mean': 0.0899658203125, 'safe_mean': 0.0875244140625, 'bankrupt_std': 0.0031833648681640625, 'safe_std': 0.0037097930908203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3117
   Cohen's d: 0.659
   Safe mean: -0.004757, Risky mean: -0.002922
âŒ Error testing {'layer': 3, 'feature_id': 3117, 'cohen_d': 0.6591796875, 'p_value': 6.73319819087033e-21, 'bankrupt_mean': -0.00292205810546875, 'safe_mean': -0.004756927490234375, 'bankrupt_std': 0.0031452178955078125, 'safe_std': 0.002773284912109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L3-3542
   Cohen's d: -0.659
   Safe mean: 0.027924, Risky mean: 0.025711
âŒ Error testing {'layer': 3, 'feature_id': 3542, 'cohen_d': -0.6591796875, 'p_value': 6.186655220920929e-21, 'bankrupt_mean': 0.0257110595703125, 'safe_mean': 0.027923583984375, 'bankrupt_std': 0.003078460693359375, 'safe_std': 0.00336456298828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1915
   Cohen's d: -1.109
   Safe mean: 0.032959, Risky mean: 0.026947
âŒ Error testing {'layer': 4, 'feature_id': 1915, 'cohen_d': -1.109375, 'p_value': 1.2088547028603829e-55, 'bankrupt_mean': 0.026947021484375, 'safe_mean': 0.032958984375, 'bankrupt_std': 0.003612518310546875, 'safe_std': 0.005466461181640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3855
   Cohen's d: 1.096
   Safe mean: -0.044525, Risky mean: -0.039703
âŒ Error testing {'layer': 4, 'feature_id': 3855, 'cohen_d': 1.095703125, 'p_value': 3.773919786837316e-54, 'bankrupt_mean': -0.039703369140625, 'safe_mean': -0.044525146484375, 'bankrupt_std': 0.003875732421875, 'safe_std': 0.004421234130859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2234
   Cohen's d: 1.093
   Safe mean: 0.009171, Risky mean: 0.013138
âŒ Error testing {'layer': 4, 'feature_id': 2234, 'cohen_d': 1.0927734375, 'p_value': 5.216575199083567e-54, 'bankrupt_mean': 0.0131378173828125, 'safe_mean': 0.0091705322265625, 'bankrupt_std': 0.00385284423828125, 'safe_std': 0.0036220550537109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2256
   Cohen's d: 1.093
   Safe mean: -0.011665, Risky mean: -0.008301
âŒ Error testing {'layer': 4, 'feature_id': 2256, 'cohen_d': 1.0927734375, 'p_value': 6.207192094481421e-54, 'bankrupt_mean': -0.00830078125, 'safe_mean': -0.01166534423828125, 'bankrupt_std': 0.00250244140625, 'safe_std': 0.0030975341796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3989
   Cohen's d: -1.089
   Safe mean: 0.001172, Risky mean: -0.005238
âŒ Error testing {'layer': 4, 'feature_id': 3989, 'cohen_d': -1.0888671875, 'p_value': 1.3358099134007895e-53, 'bankrupt_mean': -0.005237579345703125, 'safe_mean': 0.0011720657348632812, 'bankrupt_std': 0.005290985107421875, 'safe_std': 0.0059051513671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3777
   Cohen's d: -1.087
   Safe mean: -0.013138, Risky mean: -0.016815
âŒ Error testing {'layer': 4, 'feature_id': 3777, 'cohen_d': -1.0869140625, 'p_value': 2.778274610797272e-53, 'bankrupt_mean': -0.016815185546875, 'safe_mean': -0.0131378173828125, 'bankrupt_std': 0.0032749176025390625, 'safe_std': 0.003391265869140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-459
   Cohen's d: -1.086
   Safe mean: 0.013519, Risky mean: 0.009163
âŒ Error testing {'layer': 4, 'feature_id': 459, 'cohen_d': -1.0859375, 'p_value': 2.539077709226159e-53, 'bankrupt_mean': 0.00916290283203125, 'safe_mean': 0.013519287109375, 'bankrupt_std': 0.00302886962890625, 'safe_std': 0.004039764404296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-7
   Cohen's d: -1.079
   Safe mean: 0.000780, Risky mean: -0.003469
âŒ Error testing {'layer': 4, 'feature_id': 7, 'cohen_d': -1.0791015625, 'p_value': 9.992907964871942e-53, 'bankrupt_mean': -0.0034694671630859375, 'safe_mean': 0.0007796287536621094, 'bankrupt_std': 0.0034694671630859375, 'safe_std': 0.0039520263671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-3188
   Cohen's d: 1.067
   Safe mean: 0.019424, Risky mean: 0.023666
âŒ Error testing {'layer': 4, 'feature_id': 3188, 'cohen_d': 1.0673828125, 'p_value': 1.1721844376035696e-51, 'bankrupt_mean': 0.0236663818359375, 'safe_mean': 0.0194244384765625, 'bankrupt_std': 0.0028896331787109375, 'safe_std': 0.00400543212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1044
   Cohen's d: 1.048
   Safe mean: -0.014847, Risky mean: -0.008743
âŒ Error testing {'layer': 4, 'feature_id': 1044, 'cohen_d': 1.0478515625, 'p_value': 7.608046363648419e-50, 'bankrupt_mean': -0.0087432861328125, 'safe_mean': -0.0148468017578125, 'bankrupt_std': 0.0046844482421875, 'safe_std': 0.005859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-19
   Cohen's d: -1.044
   Safe mean: 0.020752, Risky mean: 0.017410
âŒ Error testing {'layer': 4, 'feature_id': 19, 'cohen_d': -1.0439453125, 'p_value': 1.320151467527471e-49, 'bankrupt_mean': 0.0174102783203125, 'safe_mean': 0.020751953125, 'bankrupt_std': 0.0038127899169921875, 'safe_std': 0.003173828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1275
   Cohen's d: 1.043
   Safe mean: -0.013870, Risky mean: -0.008141
âŒ Error testing {'layer': 4, 'feature_id': 1275, 'cohen_d': 1.04296875, 'p_value': 2.1362296148981613e-49, 'bankrupt_mean': -0.00814056396484375, 'safe_mean': -0.0138702392578125, 'bankrupt_std': 0.00505828857421875, 'safe_std': 0.0055084228515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-104
   Cohen's d: -1.037
   Safe mean: 0.017654, Risky mean: 0.012825
âŒ Error testing {'layer': 4, 'feature_id': 104, 'cohen_d': -1.037109375, 'p_value': 8.886707533918667e-49, 'bankrupt_mean': 0.01282501220703125, 'safe_mean': 0.0176544189453125, 'bankrupt_std': 0.004180908203125, 'safe_std': 0.00467681884765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1185
   Cohen's d: 1.036
   Safe mean: 0.014503, Risky mean: 0.018188
âŒ Error testing {'layer': 4, 'feature_id': 1185, 'cohen_d': 1.0361328125, 'p_value': 1.0301467071840726e-48, 'bankrupt_mean': 0.0181884765625, 'safe_mean': 0.01450347900390625, 'bankrupt_std': 0.0022106170654296875, 'safe_std': 0.003597259521484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2456
   Cohen's d: 1.035
   Safe mean: 0.002308, Risky mean: 0.008278
âŒ Error testing {'layer': 4, 'feature_id': 2456, 'cohen_d': 1.03515625, 'p_value': 1.0645291226829377e-48, 'bankrupt_mean': 0.00827789306640625, 'safe_mean': 0.002307891845703125, 'bankrupt_std': 0.0045928955078125, 'safe_std': 0.005802154541015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1467
   Cohen's d: -1.032
   Safe mean: -0.000800, Risky mean: -0.005173
âŒ Error testing {'layer': 4, 'feature_id': 1467, 'cohen_d': -1.0322265625, 'p_value': 2.4269377096121345e-48, 'bankrupt_mean': -0.0051727294921875, 'safe_mean': -0.0008001327514648438, 'bankrupt_std': 0.0034618377685546875, 'safe_std': 0.00426483154296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2613
   Cohen's d: -1.025
   Safe mean: 0.039551, Risky mean: 0.035156
âŒ Error testing {'layer': 4, 'feature_id': 2613, 'cohen_d': -1.025390625, 'p_value': 7.199733848464059e-48, 'bankrupt_mean': 0.03515625, 'safe_mean': 0.03955078125, 'bankrupt_std': 0.0033473968505859375, 'safe_std': 0.00431060791015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3011
   Cohen's d: 1.019
   Safe mean: -0.073364, Risky mean: -0.068176
âŒ Error testing {'layer': 4, 'feature_id': 3011, 'cohen_d': 1.0185546875, 'p_value': 3.1612568632714706e-47, 'bankrupt_mean': -0.06817626953125, 'safe_mean': -0.0733642578125, 'bankrupt_std': 0.0037746429443359375, 'safe_std': 0.00513458251953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3400
   Cohen's d: 1.018
   Safe mean: -0.011414, Risky mean: -0.005348
âŒ Error testing {'layer': 4, 'feature_id': 3400, 'cohen_d': 1.017578125, 'p_value': 3.188713877876918e-47, 'bankrupt_mean': -0.00534820556640625, 'safe_mean': -0.01141357421875, 'bankrupt_std': 0.005344390869140625, 'safe_std': 0.0059814453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1960
   Cohen's d: -1.017
   Safe mean: 0.002525, Risky mean: -0.002743
âŒ Error testing {'layer': 4, 'feature_id': 1960, 'cohen_d': -1.0166015625, 'p_value': 5.533013352055728e-47, 'bankrupt_mean': -0.002742767333984375, 'safe_mean': 0.00252532958984375, 'bankrupt_std': 0.00389862060546875, 'safe_std': 0.00522613525390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3811
   Cohen's d: -0.999
   Safe mean: 0.010582, Risky mean: 0.006851
âŒ Error testing {'layer': 4, 'feature_id': 3811, 'cohen_d': -0.9990234375, 'p_value': 1.8396054824199837e-45, 'bankrupt_mean': 0.0068511962890625, 'safe_mean': 0.01058197021484375, 'bankrupt_std': 0.004039764404296875, 'safe_std': 0.003726959228515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2692
   Cohen's d: 0.999
   Safe mean: -0.178833, Risky mean: -0.171875
âŒ Error testing {'layer': 4, 'feature_id': 2692, 'cohen_d': 0.99853515625, 'p_value': 1.919547376486814e-45, 'bankrupt_mean': -0.171875, 'safe_mean': -0.1788330078125, 'bankrupt_std': 0.005657196044921875, 'safe_std': 0.00701141357421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 323/600 [00:01<00:00, 417.77it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-243
   Cohen's d: -0.997
   Safe mean: 0.058014, Risky mean: 0.053833
âŒ Error testing {'layer': 4, 'feature_id': 243, 'cohen_d': -0.9970703125, 'p_value': 2.0203549233533992e-45, 'bankrupt_mean': 0.0538330078125, 'safe_mean': 0.058013916015625, 'bankrupt_std': 0.0028476715087890625, 'safe_std': 0.004230499267578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-579
   Cohen's d: -0.997
   Safe mean: 0.036377, Risky mean: 0.033051
âŒ Error testing {'layer': 4, 'feature_id': 579, 'cohen_d': -0.99658203125, 'p_value': 3.3134216317900406e-45, 'bankrupt_mean': 0.033050537109375, 'safe_mean': 0.036376953125, 'bankrupt_std': 0.0036945343017578125, 'safe_std': 0.003330230712890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1859
   Cohen's d: -0.992
   Safe mean: 0.001166, Risky mean: -0.004112
âŒ Error testing {'layer': 4, 'feature_id': 1859, 'cohen_d': -0.9921875, 'p_value': 5.744169646890208e-45, 'bankrupt_mean': -0.00411224365234375, 'safe_mean': 0.0011663436889648438, 'bankrupt_std': 0.00417327880859375, 'safe_std': 0.0053558349609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3611
   Cohen's d: -0.989
   Safe mean: 0.001131, Risky mean: -0.003075
âŒ Error testing {'layer': 4, 'feature_id': 3611, 'cohen_d': -0.9892578125, 'p_value': 1.1464836020644305e-44, 'bankrupt_mean': -0.00307464599609375, 'safe_mean': 0.0011310577392578125, 'bankrupt_std': 0.004669189453125, 'safe_std': 0.00423431396484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1771
   Cohen's d: 0.978
   Safe mean: 0.019852, Risky mean: 0.024811
âŒ Error testing {'layer': 4, 'feature_id': 1771, 'cohen_d': 0.97802734375, 'p_value': 1.001996352384499e-43, 'bankrupt_mean': 0.024810791015625, 'safe_mean': 0.0198516845703125, 'bankrupt_std': 0.004421234130859375, 'safe_std': 0.005092620849609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1395
   Cohen's d: -0.976
   Safe mean: -0.001735, Risky mean: -0.005196
âŒ Error testing {'layer': 4, 'feature_id': 1395, 'cohen_d': -0.9755859375, 'p_value': 1.6309017777337237e-43, 'bankrupt_mean': -0.00519561767578125, 'safe_mean': -0.0017347335815429688, 'bankrupt_std': 0.0033206939697265625, 'safe_std': 0.0035552978515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-819
   Cohen's d: -0.975
   Safe mean: -0.012215, Risky mean: -0.015915
âŒ Error testing {'layer': 4, 'feature_id': 819, 'cohen_d': -0.974609375, 'p_value': 2.180127262198202e-43, 'bankrupt_mean': -0.0159149169921875, 'safe_mean': -0.01221466064453125, 'bankrupt_std': 0.0030879974365234375, 'safe_std': 0.00382232666015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1095
   Cohen's d: 0.968
   Safe mean: -0.004013, Risky mean: -0.000057
âŒ Error testing {'layer': 4, 'feature_id': 1095, 'cohen_d': 0.96826171875, 'p_value': 7.083152436958907e-43, 'bankrupt_mean': -5.6803226470947266e-05, 'safe_mean': -0.0040130615234375, 'bankrupt_std': 0.0032024383544921875, 'safe_std': 0.004116058349609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1515
   Cohen's d: 0.967
   Safe mean: -0.029968, Risky mean: -0.025803
âŒ Error testing {'layer': 4, 'feature_id': 1515, 'cohen_d': 0.96728515625, 'p_value': 6.886851824473574e-43, 'bankrupt_mean': -0.0258026123046875, 'safe_mean': -0.02996826171875, 'bankrupt_std': 0.0035800933837890625, 'safe_std': 0.00432586669921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2976
   Cohen's d: 0.963
   Safe mean: 0.012756, Risky mean: 0.018082
âŒ Error testing {'layer': 4, 'feature_id': 2976, 'cohen_d': 0.962890625, 'p_value': 1.68621851608026e-42, 'bankrupt_mean': 0.0180816650390625, 'safe_mean': 0.01275634765625, 'bankrupt_std': 0.0035552978515625, 'safe_std': 0.005584716796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1224
   Cohen's d: -0.956
   Safe mean: 0.005032, Risky mean: 0.001955
âŒ Error testing {'layer': 4, 'feature_id': 1224, 'cohen_d': -0.95556640625, 'p_value': 6.732800234453622e-42, 'bankrupt_mean': 0.0019550323486328125, 'safe_mean': 0.005031585693359375, 'bankrupt_std': 0.002155303955078125, 'safe_std': 0.0032482147216796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1441
   Cohen's d: -0.951
   Safe mean: -0.006374, Risky mean: -0.009254
âŒ Error testing {'layer': 4, 'feature_id': 1441, 'cohen_d': -0.95068359375, 'p_value': 2.108032668126389e-41, 'bankrupt_mean': -0.00925445556640625, 'safe_mean': -0.006374359130859375, 'bankrupt_std': 0.002452850341796875, 'safe_std': 0.0030498504638671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1254
   Cohen's d: -0.945
   Safe mean: 0.001072, Risky mean: -0.002159
âŒ Error testing {'layer': 4, 'feature_id': 1254, 'cohen_d': -0.9453125, 'p_value': 5.670174394665463e-41, 'bankrupt_mean': -0.00215911865234375, 'safe_mean': 0.001071929931640625, 'bankrupt_std': 0.00225067138671875, 'safe_std': 0.003452301025390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1316
   Cohen's d: 0.938
   Safe mean: 0.010338, Risky mean: 0.015572
âŒ Error testing {'layer': 4, 'feature_id': 1316, 'cohen_d': 0.9384765625, 'p_value': 1.9987360295723356e-40, 'bankrupt_mean': 0.01557159423828125, 'safe_mean': 0.01033782958984375, 'bankrupt_std': 0.004947662353515625, 'safe_std': 0.0055999755859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-1736
   Cohen's d: 0.938
   Safe mean: -0.022385, Risky mean: -0.017624
âŒ Error testing {'layer': 4, 'feature_id': 1736, 'cohen_d': 0.9384765625, 'p_value': 2.2229309719138535e-40, 'bankrupt_mean': -0.0176239013671875, 'safe_mean': -0.0223846435546875, 'bankrupt_std': 0.00445556640625, 'safe_std': 0.005096435546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3299
   Cohen's d: 0.936
   Safe mean: 0.021423, Risky mean: 0.024323
âŒ Error testing {'layer': 4, 'feature_id': 3299, 'cohen_d': 0.93603515625, 'p_value': 3.4762342032294846e-40, 'bankrupt_mean': 0.024322509765625, 'safe_mean': 0.02142333984375, 'bankrupt_std': 0.002559661865234375, 'safe_std': 0.003116607666015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3352
   Cohen's d: -0.934
   Safe mean: -0.000617, Risky mean: -0.003899
âŒ Error testing {'layer': 4, 'feature_id': 3352, 'cohen_d': -0.93408203125, 'p_value': 4.706862830583969e-40, 'bankrupt_mean': -0.00389862060546875, 'safe_mean': -0.0006165504455566406, 'bankrupt_std': 0.0024776458740234375, 'safe_std': 0.0035457611083984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2663
   Cohen's d: -0.932
   Safe mean: 0.021759, Risky mean: 0.017715
âŒ Error testing {'layer': 4, 'feature_id': 2663, 'cohen_d': -0.931640625, 'p_value': 5.969297447960634e-40, 'bankrupt_mean': 0.0177154541015625, 'safe_mean': 0.021759033203125, 'bankrupt_std': 0.00426483154296875, 'safe_std': 0.00434112548828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1461
   Cohen's d: -0.930
   Safe mean: 0.023712, Risky mean: 0.019913
âŒ Error testing {'layer': 4, 'feature_id': 1461, 'cohen_d': -0.93017578125, 'p_value': 9.06726366758919e-40, 'bankrupt_mean': 0.0199127197265625, 'safe_mean': 0.023712158203125, 'bankrupt_std': 0.002826690673828125, 'safe_std': 0.004119873046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-205
   Cohen's d: -0.929
   Safe mean: -0.010803, Risky mean: -0.014626
âŒ Error testing {'layer': 4, 'feature_id': 205, 'cohen_d': -0.9287109375, 'p_value': 1.0827428546492463e-39, 'bankrupt_mean': -0.01462554931640625, 'safe_mean': -0.01080322265625, 'bankrupt_std': 0.002857208251953125, 'safe_std': 0.004150390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3908
   Cohen's d: -0.929
   Safe mean: 0.022598, Risky mean: 0.017868
âŒ Error testing {'layer': 4, 'feature_id': 3908, 'cohen_d': -0.9287109375, 'p_value': 1.1292077473648097e-39, 'bankrupt_mean': 0.0178680419921875, 'safe_mean': 0.0225982666015625, 'bankrupt_std': 0.004581451416015625, 'safe_std': 0.005107879638671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3472
   Cohen's d: -0.926
   Safe mean: 0.009117, Risky mean: 0.005119
âŒ Error testing {'layer': 4, 'feature_id': 3472, 'cohen_d': -0.92578125, 'p_value': 2.061858167064137e-39, 'bankrupt_mean': 0.00511932373046875, 'safe_mean': 0.00911712646484375, 'bankrupt_std': 0.003662109375, 'safe_std': 0.00434112548828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3696
   Cohen's d: 0.925
   Safe mean: -0.033905, Risky mean: -0.031006
âŒ Error testing {'layer': 4, 'feature_id': 3696, 'cohen_d': 0.9248046875, 'p_value': 2.130493263529859e-39, 'bankrupt_mean': -0.031005859375, 'safe_mean': -0.033905029296875, 'bankrupt_std': 0.0019989013671875, 'safe_std': 0.0031642913818359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2945
   Cohen's d: 0.924
   Safe mean: -0.034637, Risky mean: -0.028580
âŒ Error testing {'layer': 4, 'feature_id': 2945, 'cohen_d': 0.92431640625, 'p_value': 2.787211952965079e-39, 'bankrupt_mean': -0.0285797119140625, 'safe_mean': -0.034637451171875, 'bankrupt_std': 0.00658416748046875, 'safe_std': 0.00655364990234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3772
   Cohen's d: -0.922
   Safe mean: -0.014915, Risky mean: -0.019714
âŒ Error testing {'layer': 4, 'feature_id': 3772, 'cohen_d': -0.92236328125, 'p_value': 3.985449855302939e-39, 'bankrupt_mean': -0.01971435546875, 'safe_mean': -0.01491546630859375, 'bankrupt_std': 0.00396728515625, 'safe_std': 0.00524139404296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-76
   Cohen's d: 0.921
   Safe mean: 0.035004, Risky mean: 0.037384
âŒ Error testing {'layer': 4, 'feature_id': 76, 'cohen_d': 0.9208984375, 'p_value': 6.125992651595029e-39, 'bankrupt_mean': 0.037384033203125, 'safe_mean': 0.035003662109375, 'bankrupt_std': 0.0027179718017578125, 'safe_std': 0.0025844573974609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-458
   Cohen's d: -0.920
   Safe mean: 0.024002, Risky mean: 0.019394
âŒ Error testing {'layer': 4, 'feature_id': 458, 'cohen_d': -0.919921875, 'p_value': 5.4551861589549925e-39, 'bankrupt_mean': 0.0193939208984375, 'safe_mean': 0.0240020751953125, 'bankrupt_std': 0.0034961700439453125, 'safe_std': 0.00505828857421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-126
   Cohen's d: -0.917
   Safe mean: -0.010635, Risky mean: -0.013405
âŒ Error testing {'layer': 4, 'feature_id': 126, 'cohen_d': -0.91748046875, 'p_value': 6.085934126951277e-39, 'bankrupt_mean': -0.01340484619140625, 'safe_mean': -0.0106353759765625, 'bankrupt_std': 0.00201416015625, 'safe_std': 0.0030498504638671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-2307
   Cohen's d: -0.912
   Safe mean: 0.005596, Risky mean: -0.002125
âŒ Error testing {'layer': 4, 'feature_id': 2307, 'cohen_d': -0.91162109375, 'p_value': 2.6442541333429224e-38, 'bankrupt_mean': -0.002124786376953125, 'safe_mean': 0.005596160888671875, 'bankrupt_std': 0.007747650146484375, 'safe_std': 0.00849151611328125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3422
   Cohen's d: 0.911
   Safe mean: 0.005741, Risky mean: 0.011055
âŒ Error testing {'layer': 4, 'feature_id': 3422, 'cohen_d': 0.9111328125, 'p_value': 2.8283388642976034e-38, 'bankrupt_mean': 0.01105499267578125, 'safe_mean': 0.005741119384765625, 'bankrupt_std': 0.00527191162109375, 'safe_std': 0.005847930908203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2207
   Cohen's d: 0.909
   Safe mean: -0.017914, Risky mean: -0.013702
âŒ Error testing {'layer': 4, 'feature_id': 2207, 'cohen_d': 0.9091796875, 'p_value': 4.104068765858725e-38, 'bankrupt_mean': -0.013702392578125, 'safe_mean': -0.017913818359375, 'bankrupt_std': 0.003009796142578125, 'safe_std': 0.00467681884765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3962
   Cohen's d: -0.908
   Safe mean: 0.033783, Risky mean: 0.028732
âŒ Error testing {'layer': 4, 'feature_id': 3962, 'cohen_d': -0.90771484375, 'p_value': 6.188561273048575e-38, 'bankrupt_mean': 0.0287322998046875, 'safe_mean': 0.033782958984375, 'bankrupt_std': 0.00395965576171875, 'safe_std': 0.005615234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-560
   Cohen's d: 0.907
   Safe mean: -0.000563, Risky mean: 0.003735
âŒ Error testing {'layer': 4, 'feature_id': 560, 'cohen_d': 0.9072265625, 'p_value': 6.303467867734138e-38, 'bankrupt_mean': 0.003734588623046875, 'safe_mean': -0.0005626678466796875, 'bankrupt_std': 0.0037822723388671875, 'safe_std': 0.004764556884765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1460
   Cohen's d: -0.906
   Safe mean: 0.004158, Risky mean: -0.000237
âŒ Error testing {'layer': 4, 'feature_id': 1460, 'cohen_d': -0.90576171875, 'p_value': 7.08725540035131e-38, 'bankrupt_mean': -0.00023651123046875, 'safe_mean': 0.00415802001953125, 'bankrupt_std': 0.003726959228515625, 'safe_std': 0.0048828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2473
   Cohen's d: -0.905
   Safe mean: -0.020920, Risky mean: -0.024643
âŒ Error testing {'layer': 4, 'feature_id': 2473, 'cohen_d': -0.90478515625, 'p_value': 1.0816162460271128e-37, 'bankrupt_mean': -0.0246429443359375, 'safe_mean': -0.0209197998046875, 'bankrupt_std': 0.0035800933837890625, 'safe_std': 0.0041351318359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3018
   Cohen's d: 0.905
   Safe mean: 0.007076, Risky mean: 0.011314
âŒ Error testing {'layer': 4, 'feature_id': 3018, 'cohen_d': 0.90478515625, 'p_value': 8.392792171932958e-38, 'bankrupt_mean': 0.01131439208984375, 'safe_mean': 0.007076263427734375, 'bankrupt_std': 0.0032939910888671875, 'safe_std': 0.00472259521484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1516
   Cohen's d: -0.904
   Safe mean: 0.039825, Risky mean: 0.035675
âŒ Error testing {'layer': 4, 'feature_id': 1516, 'cohen_d': -0.90380859375, 'p_value': 1.38436827979775e-37, 'bankrupt_mean': 0.035675048828125, 'safe_mean': 0.039825439453125, 'bankrupt_std': 0.003936767578125, 'safe_std': 0.004611968994140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-303
   Cohen's d: 0.900
   Safe mean: -0.025192, Risky mean: -0.021500
âŒ Error testing {'layer': 4, 'feature_id': 303, 'cohen_d': 0.900390625, 'p_value': 1.906672089831439e-37, 'bankrupt_mean': -0.0214996337890625, 'safe_mean': -0.0251922607421875, 'bankrupt_std': 0.0024890899658203125, 'safe_std': 0.00414276123046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-748
   Cohen's d: 0.899
   Safe mean: -0.006268, Risky mean: -0.002686
âŒ Error testing {'layer': 4, 'feature_id': 748, 'cohen_d': 0.8994140625, 'p_value': 2.7399549418258505e-37, 'bankrupt_mean': -0.002685546875, 'safe_mean': -0.006267547607421875, 'bankrupt_std': 0.004299163818359375, 'safe_std': 0.00397491455078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-815
   Cohen's d: -0.896
   Safe mean: -0.015640, Risky mean: -0.021439
âŒ Error testing {'layer': 4, 'feature_id': 815, 'cohen_d': -0.89599609375, 'p_value': 4.2777630109743155e-37, 'bankrupt_mean': -0.0214385986328125, 'safe_mean': -0.0156402587890625, 'bankrupt_std': 0.005466461181640625, 'safe_std': 0.006500244140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-160
   Cohen's d: -0.896
   Safe mean: 0.020126, Risky mean: 0.015518
âŒ Error testing {'layer': 4, 'feature_id': 160, 'cohen_d': -0.8955078125, 'p_value': 5.080869908563685e-37, 'bankrupt_mean': 0.0155181884765625, 'safe_mean': 0.0201263427734375, 'bankrupt_std': 0.004688262939453125, 'safe_std': 0.005161285400390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1401
   Cohen's d: 0.896
   Safe mean: -0.055634, Risky mean: -0.051636
âŒ Error testing {'layer': 4, 'feature_id': 1401, 'cohen_d': 0.8955078125, 'p_value': 5.187595565747156e-37, 'bankrupt_mean': -0.0516357421875, 'safe_mean': -0.055633544921875, 'bankrupt_std': 0.004180908203125, 'safe_std': 0.004474639892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 368/600 [00:01<00:00, 406.29it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-520
   Cohen's d: -0.891
   Safe mean: 0.043274, Risky mean: 0.040405
âŒ Error testing {'layer': 4, 'feature_id': 520, 'cohen_d': -0.89111328125, 'p_value': 1.168341164351377e-36, 'bankrupt_mean': 0.0404052734375, 'safe_mean': 0.04327392578125, 'bankrupt_std': 0.0032291412353515625, 'safe_std': 0.0032196044921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3116
   Cohen's d: -0.889
   Safe mean: -0.003708, Risky mean: -0.008629
âŒ Error testing {'layer': 4, 'feature_id': 3116, 'cohen_d': -0.888671875, 'p_value': 1.925018927349496e-36, 'bankrupt_mean': -0.00862884521484375, 'safe_mean': -0.0037078857421875, 'bankrupt_std': 0.004566192626953125, 'safe_std': 0.005573272705078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1104
   Cohen's d: -0.888
   Safe mean: 0.185181, Risky mean: 0.180420
âŒ Error testing {'layer': 4, 'feature_id': 1104, 'cohen_d': -0.88818359375, 'p_value': 1.778734367934199e-36, 'bankrupt_mean': 0.180419921875, 'safe_mean': 0.1851806640625, 'bankrupt_std': 0.00482177734375, 'safe_std': 0.005374908447265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-956
   Cohen's d: 0.886
   Safe mean: 0.017410, Risky mean: 0.023911
âŒ Error testing {'layer': 4, 'feature_id': 956, 'cohen_d': 0.8857421875, 'p_value': 2.883371481997217e-36, 'bankrupt_mean': 0.0239105224609375, 'safe_mean': 0.0174102783203125, 'bankrupt_std': 0.00629425048828125, 'safe_std': 0.007373809814453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-746
   Cohen's d: 0.884
   Safe mean: 0.025818, Risky mean: 0.028641
âŒ Error testing {'layer': 4, 'feature_id': 746, 'cohen_d': 0.88427734375, 'p_value': 3.306616413945224e-36, 'bankrupt_mean': 0.0286407470703125, 'safe_mean': 0.02581787109375, 'bankrupt_std': 0.00250244140625, 'safe_std': 0.00321197509765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1131
   Cohen's d: 0.881
   Safe mean: -0.051208, Risky mean: -0.046906
âŒ Error testing {'layer': 4, 'feature_id': 1131, 'cohen_d': 0.88134765625, 'p_value': 5.673635493289412e-36, 'bankrupt_mean': -0.046905517578125, 'safe_mean': -0.05120849609375, 'bankrupt_std': 0.005146026611328125, 'safe_std': 0.004871368408203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2815
   Cohen's d: -0.881
   Safe mean: 0.005966, Risky mean: 0.001660
âŒ Error testing {'layer': 4, 'feature_id': 2815, 'cohen_d': -0.880859375, 'p_value': 6.068542889648551e-36, 'bankrupt_mean': 0.0016603469848632812, 'safe_mean': 0.0059661865234375, 'bankrupt_std': 0.0035552978515625, 'safe_std': 0.004924774169921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3897
   Cohen's d: 0.880
   Safe mean: 0.016785, Risky mean: 0.020264
âŒ Error testing {'layer': 4, 'feature_id': 3897, 'cohen_d': 0.88037109375, 'p_value': 8.031849104420494e-36, 'bankrupt_mean': 0.020263671875, 'safe_mean': 0.01678466796875, 'bankrupt_std': 0.0040283203125, 'safe_std': 0.0039520263671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1182
   Cohen's d: 0.879
   Safe mean: 0.036499, Risky mean: 0.039307
âŒ Error testing {'layer': 4, 'feature_id': 1182, 'cohen_d': 0.87939453125, 'p_value': 9.083764968530964e-36, 'bankrupt_mean': 0.039306640625, 'safe_mean': 0.0364990234375, 'bankrupt_std': 0.0026302337646484375, 'safe_std': 0.00321197509765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2513
   Cohen's d: 0.878
   Safe mean: -0.004608, Risky mean: -0.000844
âŒ Error testing {'layer': 4, 'feature_id': 2513, 'cohen_d': 0.87841796875, 'p_value': 1.1334934062487321e-35, 'bankrupt_mean': -0.0008444786071777344, 'safe_mean': -0.004608154296875, 'bankrupt_std': 0.003452301025390625, 'safe_std': 0.00431060791015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3817
   Cohen's d: 0.877
   Safe mean: 0.028503, Risky mean: 0.033630
âŒ Error testing {'layer': 4, 'feature_id': 3817, 'cohen_d': 0.876953125, 'p_value': 1.481161190276134e-35, 'bankrupt_mean': 0.03363037109375, 'safe_mean': 0.02850341796875, 'bankrupt_std': 0.0057373046875, 'safe_std': 0.005855560302734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2530
   Cohen's d: -0.875
   Safe mean: 0.001987, Risky mean: -0.002041
âŒ Error testing {'layer': 4, 'feature_id': 2530, 'cohen_d': -0.87548828125, 'p_value': 1.7536918970755262e-35, 'bankrupt_mean': -0.002040863037109375, 'safe_mean': 0.001987457275390625, 'bankrupt_std': 0.00426483154296875, 'safe_std': 0.004611968994140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2489
   Cohen's d: -0.874
   Safe mean: -0.001355, Risky mean: -0.004200
âŒ Error testing {'layer': 4, 'feature_id': 2489, 'cohen_d': -0.87353515625, 'p_value': 2.7111829767997245e-35, 'bankrupt_mean': -0.004199981689453125, 'safe_mean': -0.0013551712036132812, 'bankrupt_std': 0.002773284912109375, 'safe_std': 0.0032749176025390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1531
   Cohen's d: 0.873
   Safe mean: -0.035950, Risky mean: -0.028793
âŒ Error testing {'layer': 4, 'feature_id': 1531, 'cohen_d': 0.87255859375, 'p_value': 3.0499047030517906e-35, 'bankrupt_mean': -0.0287933349609375, 'safe_mean': -0.03594970703125, 'bankrupt_std': 0.006191253662109375, 'safe_std': 0.00826263427734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-232
   Cohen's d: 0.867
   Safe mean: -0.033173, Risky mean: -0.029190
âŒ Error testing {'layer': 4, 'feature_id': 232, 'cohen_d': 0.8671875, 'p_value': 7.217698647914429e-35, 'bankrupt_mean': -0.0291900634765625, 'safe_mean': -0.033172607421875, 'bankrupt_std': 0.003192901611328125, 'safe_std': 0.00463104248046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3787
   Cohen's d: 0.866
   Safe mean: -0.028641, Risky mean: -0.022049
âŒ Error testing {'layer': 4, 'feature_id': 3787, 'cohen_d': 0.86572265625, 'p_value': 8.747493639658517e-35, 'bankrupt_mean': -0.0220489501953125, 'safe_mean': -0.0286407470703125, 'bankrupt_std': 0.00617218017578125, 'safe_std': 0.007656097412109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-678
   Cohen's d: -0.864
   Safe mean: 0.018372, Risky mean: 0.013687
âŒ Error testing {'layer': 4, 'feature_id': 678, 'cohen_d': -0.86376953125, 'p_value': 1.5235668263294862e-34, 'bankrupt_mean': 0.0136871337890625, 'safe_mean': 0.01837158203125, 'bankrupt_std': 0.0040130615234375, 'safe_std': 0.00547027587890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1674
   Cohen's d: 0.861
   Safe mean: 0.010658, Risky mean: 0.013977
âŒ Error testing {'layer': 4, 'feature_id': 1674, 'cohen_d': 0.861328125, 'p_value': 1.8166445090845003e-34, 'bankrupt_mean': 0.01397705078125, 'safe_mean': 0.01065826416015625, 'bankrupt_std': 0.004222869873046875, 'safe_std': 0.00383758544921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1793
   Cohen's d: -0.861
   Safe mean: 0.012077, Risky mean: 0.007645
âŒ Error testing {'layer': 4, 'feature_id': 1793, 'cohen_d': -0.861328125, 'p_value': 2.1233457112146913e-34, 'bankrupt_mean': 0.0076446533203125, 'safe_mean': 0.01207733154296875, 'bankrupt_std': 0.0036869049072265625, 'safe_std': 0.005191802978515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2442
   Cohen's d: -0.861
   Safe mean: -0.007580, Risky mean: -0.011871
âŒ Error testing {'layer': 4, 'feature_id': 2442, 'cohen_d': -0.86083984375, 'p_value': 2.3173411990847727e-34, 'bankrupt_mean': -0.011871337890625, 'safe_mean': -0.007579803466796875, 'bankrupt_std': 0.003612518310546875, 'safe_std': 0.00502777099609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3553
   Cohen's d: 0.860
   Safe mean: -0.035156, Risky mean: -0.030945
âŒ Error testing {'layer': 4, 'feature_id': 3553, 'cohen_d': 0.8603515625, 'p_value': 2.469463219685249e-34, 'bankrupt_mean': -0.03094482421875, 'safe_mean': -0.03515625, 'bankrupt_std': 0.00455474853515625, 'safe_std': 0.00490570068359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1790
   Cohen's d: -0.859
   Safe mean: -0.010483, Risky mean: -0.015411
âŒ Error testing {'layer': 4, 'feature_id': 1790, 'cohen_d': -0.85888671875, 'p_value': 3.122866417559803e-34, 'bankrupt_mean': -0.015411376953125, 'safe_mean': -0.0104827880859375, 'bankrupt_std': 0.00534820556640625, 'safe_std': 0.0057525634765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3763
   Cohen's d: -0.858
   Safe mean: 0.004177, Risky mean: -0.000619
âŒ Error testing {'layer': 4, 'feature_id': 3763, 'cohen_d': -0.8583984375, 'p_value': 2.836415853548004e-34, 'bankrupt_mean': -0.0006189346313476562, 'safe_mean': 0.004177093505859375, 'bankrupt_std': 0.004791259765625, 'safe_std': 0.005603790283203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2395
   Cohen's d: -0.855
   Safe mean: 0.020981, Risky mean: 0.016754
âŒ Error testing {'layer': 4, 'feature_id': 2395, 'cohen_d': -0.85498046875, 'p_value': 5.79681128341668e-34, 'bankrupt_mean': 0.016754150390625, 'safe_mean': 0.0209808349609375, 'bankrupt_std': 0.0052490234375, 'safe_std': 0.004932403564453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1906
   Cohen's d: 0.854
   Safe mean: -0.008774, Risky mean: -0.004288
âŒ Error testing {'layer': 4, 'feature_id': 1906, 'cohen_d': 0.85400390625, 'p_value': 7.705654512286994e-34, 'bankrupt_mean': -0.0042877197265625, 'safe_mean': -0.0087738037109375, 'bankrupt_std': 0.00548553466796875, 'safe_std': 0.0052490234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2798
   Cohen's d: -0.854
   Safe mean: 0.011253, Risky mean: 0.006062
âŒ Error testing {'layer': 4, 'feature_id': 2798, 'cohen_d': -0.85400390625, 'p_value': 6.418466326934202e-34, 'bankrupt_mean': 0.006061553955078125, 'safe_mean': 0.01125335693359375, 'bankrupt_std': 0.0049896240234375, 'safe_std': 0.006107330322265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1519
   Cohen's d: -0.854
   Safe mean: 0.031250, Risky mean: 0.026825
âŒ Error testing {'layer': 4, 'feature_id': 1519, 'cohen_d': -0.853515625, 'p_value': 7.378327050287948e-34, 'bankrupt_mean': 0.026824951171875, 'safe_mean': 0.03125, 'bankrupt_std': 0.004180908203125, 'safe_std': 0.005214691162109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3697
   Cohen's d: 0.854
   Safe mean: 0.034210, Risky mean: 0.037659
âŒ Error testing {'layer': 4, 'feature_id': 3697, 'cohen_d': 0.853515625, 'p_value': 9.070802959367451e-34, 'bankrupt_mean': 0.03765869140625, 'safe_mean': 0.034210205078125, 'bankrupt_std': 0.0036945343017578125, 'safe_std': 0.004055023193359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-337
   Cohen's d: 0.850
   Safe mean: -0.048798, Risky mean: -0.045990
âŒ Error testing {'layer': 4, 'feature_id': 337, 'cohen_d': 0.85009765625, 'p_value': 1.33555122261654e-33, 'bankrupt_mean': -0.045989990234375, 'safe_mean': -0.048797607421875, 'bankrupt_std': 0.002685546875, 'safe_std': 0.0033206939697265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3814
   Cohen's d: 0.848
   Safe mean: -0.036224, Risky mean: -0.032806
âŒ Error testing {'layer': 4, 'feature_id': 3814, 'cohen_d': 0.84765625, 'p_value': 2.2828653590842883e-33, 'bankrupt_mean': -0.032806396484375, 'safe_mean': -0.036224365234375, 'bankrupt_std': 0.003337860107421875, 'safe_std': 0.004055023193359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1364
   Cohen's d: -0.847
   Safe mean: 0.021683, Risky mean: 0.017792
âŒ Error testing {'layer': 4, 'feature_id': 1364, 'cohen_d': -0.84716796875, 'p_value': 2.208686790527373e-33, 'bankrupt_mean': 0.017791748046875, 'safe_mean': 0.0216827392578125, 'bankrupt_std': 0.00490570068359375, 'safe_std': 0.004581451416015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3078
   Cohen's d: 0.845
   Safe mean: -0.007019, Risky mean: -0.004551
âŒ Error testing {'layer': 4, 'feature_id': 3078, 'cohen_d': 0.84521484375, 'p_value': 3.184708737813527e-33, 'bankrupt_mean': -0.004550933837890625, 'safe_mean': -0.00701904296875, 'bankrupt_std': 0.0026187896728515625, 'safe_std': 0.0029296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2388
   Cohen's d: 0.844
   Safe mean: 0.004448, Risky mean: 0.007275
âŒ Error testing {'layer': 4, 'feature_id': 2388, 'cohen_d': 0.84423828125, 'p_value': 4.61839093635888e-33, 'bankrupt_mean': 0.007274627685546875, 'safe_mean': 0.00444793701171875, 'bankrupt_std': 0.0023040771484375, 'safe_std': 0.003383636474609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-923
   Cohen's d: -0.844
   Safe mean: 0.000583, Risky mean: -0.002945
âŒ Error testing {'layer': 4, 'feature_id': 923, 'cohen_d': -0.84375, 'p_value': 3.4586981251425486e-33, 'bankrupt_mean': -0.0029449462890625, 'safe_mean': 0.0005826950073242188, 'bankrupt_std': 0.00389862060546875, 'safe_std': 0.004184722900390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1327
   Cohen's d: -0.843
   Safe mean: 0.019440, Risky mean: 0.016251
âŒ Error testing {'layer': 4, 'feature_id': 1327, 'cohen_d': -0.84326171875, 'p_value': 4.85256572237934e-33, 'bankrupt_mean': 0.0162506103515625, 'safe_mean': 0.019439697265625, 'bankrupt_std': 0.003078460693359375, 'safe_std': 0.0038051605224609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2675
   Cohen's d: -0.841
   Safe mean: 0.031952, Risky mean: 0.028961
âŒ Error testing {'layer': 4, 'feature_id': 2675, 'cohen_d': -0.84130859375, 'p_value': 7.554967474199357e-33, 'bankrupt_mean': 0.028961181640625, 'safe_mean': 0.031951904296875, 'bankrupt_std': 0.0029087066650390625, 'safe_std': 0.0035800933837890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-52
   Cohen's d: -0.840
   Safe mean: 0.007580, Risky mean: 0.003298
âŒ Error testing {'layer': 4, 'feature_id': 52, 'cohen_d': -0.83984375, 'p_value': 8.265705245453533e-33, 'bankrupt_mean': 0.0032978057861328125, 'safe_mean': 0.007579803466796875, 'bankrupt_std': 0.005584716796875, 'safe_std': 0.0050811767578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-742
   Cohen's d: -0.839
   Safe mean: 0.012268, Risky mean: 0.008263
âŒ Error testing {'layer': 4, 'feature_id': 742, 'cohen_d': -0.83935546875, 'p_value': 9.635659019076137e-33, 'bankrupt_mean': 0.00826263427734375, 'safe_mean': 0.01226806640625, 'bankrupt_std': 0.005237579345703125, 'safe_std': 0.0047607421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2582
   Cohen's d: -0.839
   Safe mean: 0.046936, Risky mean: 0.043182
âŒ Error testing {'layer': 4, 'feature_id': 2582, 'cohen_d': -0.8388671875, 'p_value': 9.089154189589285e-33, 'bankrupt_mean': 0.043182373046875, 'safe_mean': 0.04693603515625, 'bankrupt_std': 0.0037899017333984375, 'safe_std': 0.00449371337890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3926
   Cohen's d: -0.839
   Safe mean: -0.036987, Risky mean: -0.041351
âŒ Error testing {'layer': 4, 'feature_id': 3926, 'cohen_d': -0.8388671875, 'p_value': 8.852061197818502e-33, 'bankrupt_mean': -0.041351318359375, 'safe_mean': -0.0369873046875, 'bankrupt_std': 0.005146026611328125, 'safe_std': 0.0052032470703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1429
   Cohen's d: -0.836
   Safe mean: -0.029129, Risky mean: -0.033112
âŒ Error testing {'layer': 4, 'feature_id': 1429, 'cohen_d': -0.83642578125, 'p_value': 1.2040350543540775e-32, 'bankrupt_mean': -0.033111572265625, 'safe_mean': -0.0291290283203125, 'bankrupt_std': 0.004657745361328125, 'safe_std': 0.0047607421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3351
   Cohen's d: -0.836
   Safe mean: 0.043182, Risky mean: 0.039490
âŒ Error testing {'layer': 4, 'feature_id': 3351, 'cohen_d': -0.83642578125, 'p_value': 1.3164353440110065e-32, 'bankrupt_mean': 0.03948974609375, 'safe_mean': 0.043182373046875, 'bankrupt_std': 0.003444671630859375, 'safe_std': 0.0044403076171875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 411/600 [00:01<00:00, 341.79it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-3341
   Cohen's d: 0.836
   Safe mean: -0.004597, Risky mean: -0.000998
âŒ Error testing {'layer': 4, 'feature_id': 3341, 'cohen_d': 0.8359375, 'p_value': 1.385876669171976e-32, 'bankrupt_mean': -0.0009975433349609375, 'safe_mean': -0.004596710205078125, 'bankrupt_std': 0.0032749176025390625, 'safe_std': 0.00433349609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2806
   Cohen's d: 0.835
   Safe mean: -0.012848, Risky mean: -0.009148
âŒ Error testing {'layer': 4, 'feature_id': 2806, 'cohen_d': 0.83544921875, 'p_value': 1.7049786722013446e-32, 'bankrupt_mean': -0.00914764404296875, 'safe_mean': -0.012847900390625, 'bankrupt_std': 0.0027828216552734375, 'safe_std': 0.004474639892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2334
   Cohen's d: 0.834
   Safe mean: 0.016357, Risky mean: 0.020142
âŒ Error testing {'layer': 4, 'feature_id': 2334, 'cohen_d': 0.83447265625, 'p_value': 2.0462265727488433e-32, 'bankrupt_mean': 0.0201416015625, 'safe_mean': 0.016357421875, 'bankrupt_std': 0.003734588623046875, 'safe_std': 0.0045623779296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2461
   Cohen's d: 0.833
   Safe mean: 0.229614, Risky mean: 0.233765
âŒ Error testing {'layer': 4, 'feature_id': 2461, 'cohen_d': 0.83349609375, 'p_value': 2.5241419038821215e-32, 'bankrupt_mean': 0.2337646484375, 'safe_mean': 0.2296142578125, 'bankrupt_std': 0.00432586669921875, 'safe_std': 0.0050048828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1495
   Cohen's d: 0.832
   Safe mean: 0.009468, Risky mean: 0.012680
âŒ Error testing {'layer': 4, 'feature_id': 1495, 'cohen_d': 0.83203125, 'p_value': 2.8524443138806087e-32, 'bankrupt_mean': 0.0126800537109375, 'safe_mean': 0.00946807861328125, 'bankrupt_std': 0.00244140625, 'safe_std': 0.00389862060546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3476
   Cohen's d: 0.831
   Safe mean: 0.041840, Risky mean: 0.046448
âŒ Error testing {'layer': 4, 'feature_id': 3476, 'cohen_d': 0.8310546875, 'p_value': 3.4501665599632914e-32, 'bankrupt_mean': 0.04644775390625, 'safe_mean': 0.041839599609375, 'bankrupt_std': 0.00464630126953125, 'safe_std': 0.005573272705078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1150
   Cohen's d: 0.830
   Safe mean: -0.004028, Risky mean: 0.001232
âŒ Error testing {'layer': 4, 'feature_id': 1150, 'cohen_d': 0.82958984375, 'p_value': 4.070589830367372e-32, 'bankrupt_mean': 0.001232147216796875, 'safe_mean': -0.0040283203125, 'bankrupt_std': 0.005237579345703125, 'safe_std': 0.00637054443359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-573
   Cohen's d: 0.829
   Safe mean: -0.014870, Risky mean: -0.011375
âŒ Error testing {'layer': 4, 'feature_id': 573, 'cohen_d': 0.8291015625, 'p_value': 5.164978696106811e-32, 'bankrupt_mean': -0.01137542724609375, 'safe_mean': -0.01486968994140625, 'bankrupt_std': 0.00384521484375, 'safe_std': 0.004230499267578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-591
   Cohen's d: -0.828
   Safe mean: 0.019547, Risky mean: 0.016251
âŒ Error testing {'layer': 4, 'feature_id': 591, 'cohen_d': -0.82763671875, 'p_value': 6.855174932307623e-32, 'bankrupt_mean': 0.0162506103515625, 'safe_mean': 0.0195465087890625, 'bankrupt_std': 0.003116607666015625, 'safe_std': 0.0040130615234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-852
   Cohen's d: -0.826
   Safe mean: 0.019791, Risky mean: 0.016037
âŒ Error testing {'layer': 4, 'feature_id': 852, 'cohen_d': -0.82568359375, 'p_value': 8.950958246925359e-32, 'bankrupt_mean': 0.0160369873046875, 'safe_mean': 0.0197906494140625, 'bankrupt_std': 0.0036945343017578125, 'safe_std': 0.004573822021484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2849
   Cohen's d: 0.826
   Safe mean: 0.025513, Risky mean: 0.030853
âŒ Error testing {'layer': 4, 'feature_id': 2849, 'cohen_d': 0.82568359375, 'p_value': 8.612165913986491e-32, 'bankrupt_mean': 0.030853271484375, 'safe_mean': 0.0255126953125, 'bankrupt_std': 0.004932403564453125, 'safe_std': 0.006511688232421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1167
   Cohen's d: -0.823
   Safe mean: 0.005199, Risky mean: 0.001959
âŒ Error testing {'layer': 4, 'feature_id': 1167, 'cohen_d': -0.8232421875, 'p_value': 1.4338324637078045e-31, 'bankrupt_mean': 0.0019588470458984375, 'safe_mean': 0.005199432373046875, 'bankrupt_std': 0.0033111572265625, 'safe_std': 0.00395965576171875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-322
   Cohen's d: -0.823
   Safe mean: 0.026199, Risky mean: 0.024200
âŒ Error testing {'layer': 4, 'feature_id': 322, 'cohen_d': -0.82275390625, 'p_value': 1.4786079142799537e-31, 'bankrupt_mean': 0.024200439453125, 'safe_mean': 0.0261993408203125, 'bankrupt_std': 0.0028057098388671875, 'safe_std': 0.0024166107177734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-111
   Cohen's d: 0.822
   Safe mean: -0.005146, Risky mean: -0.002787
âŒ Error testing {'layer': 4, 'feature_id': 111, 'cohen_d': 0.822265625, 'p_value': 1.3573547452830446e-31, 'bankrupt_mean': -0.0027866363525390625, 'safe_mean': -0.005146026611328125, 'bankrupt_std': 0.0021419525146484375, 'safe_std': 0.0028896331787109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-1574
   Cohen's d: 0.822
   Safe mean: 0.032257, Risky mean: 0.034698
âŒ Error testing {'layer': 4, 'feature_id': 1574, 'cohen_d': 0.822265625, 'p_value': 1.3522648249665143e-31, 'bankrupt_mean': 0.034698486328125, 'safe_mean': 0.032257080078125, 'bankrupt_std': 0.00286865234375, 'safe_std': 0.0029697418212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-433
   Cohen's d: -0.821
   Safe mean: 0.036652, Risky mean: 0.033875
âŒ Error testing {'layer': 4, 'feature_id': 433, 'cohen_d': -0.82080078125, 'p_value': 2.317067798924227e-31, 'bankrupt_mean': 0.03387451171875, 'safe_mean': 0.036651611328125, 'bankrupt_std': 0.002696990966796875, 'safe_std': 0.0034084320068359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2009
   Cohen's d: 0.820
   Safe mean: -0.029785, Risky mean: -0.027100
âŒ Error testing {'layer': 4, 'feature_id': 2009, 'cohen_d': 0.81982421875, 'p_value': 1.8416146008688564e-31, 'bankrupt_mean': -0.027099609375, 'safe_mean': -0.02978515625, 'bankrupt_std': 0.0034008026123046875, 'safe_std': 0.0032672882080078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2672
   Cohen's d: -0.820
   Safe mean: 0.001272, Risky mean: -0.001866
âŒ Error testing {'layer': 4, 'feature_id': 2672, 'cohen_d': -0.81982421875, 'p_value': 2.3413676373454115e-31, 'bankrupt_mean': -0.0018663406372070312, 'safe_mean': 0.0012722015380859375, 'bankrupt_std': 0.0028362274169921875, 'safe_std': 0.0038604736328125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1481
   Cohen's d: 0.819
   Safe mean: -0.066833, Risky mean: -0.062469
âŒ Error testing {'layer': 4, 'feature_id': 1481, 'cohen_d': 0.8193359375, 'p_value': 2.456973471252656e-31, 'bankrupt_mean': -0.062469482421875, 'safe_mean': -0.06683349609375, 'bankrupt_std': 0.00579833984375, 'safe_std': 0.00531005859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1528
   Cohen's d: -0.819
   Safe mean: -0.011879, Risky mean: -0.015450
âŒ Error testing {'layer': 4, 'feature_id': 1528, 'cohen_d': -0.81884765625, 'p_value': 2.655222408003058e-31, 'bankrupt_mean': -0.01544952392578125, 'safe_mean': -0.01187896728515625, 'bankrupt_std': 0.0047454833984375, 'safe_std': 0.004344940185546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-565
   Cohen's d: 0.818
   Safe mean: 0.030563, Risky mean: 0.034760
âŒ Error testing {'layer': 4, 'feature_id': 565, 'cohen_d': 0.818359375, 'p_value': 2.7407189182198126e-31, 'bankrupt_mean': 0.034759521484375, 'safe_mean': 0.0305633544921875, 'bankrupt_std': 0.00392913818359375, 'safe_std': 0.005161285400390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2220
   Cohen's d: -0.816
   Safe mean: -0.018082, Risky mean: -0.021103
âŒ Error testing {'layer': 4, 'feature_id': 2220, 'cohen_d': -0.81591796875, 'p_value': 3.742101657857789e-31, 'bankrupt_mean': -0.0211029052734375, 'safe_mean': -0.0180816650390625, 'bankrupt_std': 0.003597259521484375, 'safe_std': 0.0037021636962890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-4028
   Cohen's d: -0.816
   Safe mean: -0.069702, Risky mean: -0.074951
âŒ Error testing {'layer': 4, 'feature_id': 4028, 'cohen_d': -0.81591796875, 'p_value': 3.90989997024846e-31, 'bankrupt_mean': -0.074951171875, 'safe_mean': -0.0697021484375, 'bankrupt_std': 0.006748199462890625, 'safe_std': 0.0064239501953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3889
   Cohen's d: 0.815
   Safe mean: 0.008163, Risky mean: 0.014961
âŒ Error testing {'layer': 4, 'feature_id': 3889, 'cohen_d': 0.8154296875, 'p_value': 4.554413012497632e-31, 'bankrupt_mean': 0.01496124267578125, 'safe_mean': 0.0081634521484375, 'bankrupt_std': 0.006786346435546875, 'safe_std': 0.00838470458984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-450
   Cohen's d: 0.814
   Safe mean: -0.004063, Risky mean: 0.000255
âŒ Error testing {'layer': 4, 'feature_id': 450, 'cohen_d': 0.814453125, 'p_value': 6.01014677792599e-31, 'bankrupt_mean': 0.0002548694610595703, 'safe_mean': -0.004062652587890625, 'bankrupt_std': 0.00383758544921875, 'safe_std': 0.00534820556640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2671
   Cohen's d: 0.813
   Safe mean: -0.093079, Risky mean: -0.088074
âŒ Error testing {'layer': 4, 'feature_id': 2671, 'cohen_d': 0.8134765625, 'p_value': 6.407288538842228e-31, 'bankrupt_mean': -0.08807373046875, 'safe_mean': -0.09307861328125, 'bankrupt_std': 0.006439208984375, 'safe_std': 0.00614166259765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1341
   Cohen's d: -0.813
   Safe mean: 0.013512, Risky mean: 0.008575
âŒ Error testing {'layer': 4, 'feature_id': 1341, 'cohen_d': -0.81298828125, 'p_value': 7.497341239078555e-31, 'bankrupt_mean': 0.008575439453125, 'safe_mean': 0.01351165771484375, 'bankrupt_std': 0.0056610107421875, 'safe_std': 0.0060882568359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3007
   Cohen's d: -0.812
   Safe mean: -0.022705, Risky mean: -0.027222
âŒ Error testing {'layer': 4, 'feature_id': 3007, 'cohen_d': -0.8125, 'p_value': 7.680771807414715e-31, 'bankrupt_mean': -0.0272216796875, 'safe_mean': -0.022705078125, 'bankrupt_std': 0.00481414794921875, 'safe_std': 0.005584716796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-278
   Cohen's d: -0.812
   Safe mean: 0.012482, Risky mean: 0.008247
âŒ Error testing {'layer': 4, 'feature_id': 278, 'cohen_d': -0.81201171875, 'p_value': 7.630840252227458e-31, 'bankrupt_mean': 0.00824737548828125, 'safe_mean': 0.012481689453125, 'bankrupt_std': 0.005657196044921875, 'safe_std': 0.00519561767578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3031
   Cohen's d: 0.809
   Safe mean: 0.018860, Risky mean: 0.022568
âŒ Error testing {'layer': 4, 'feature_id': 3031, 'cohen_d': 0.80908203125, 'p_value': 1.2112783567776817e-30, 'bankrupt_mean': 0.0225677490234375, 'safe_mean': 0.01885986328125, 'bankrupt_std': 0.0039520263671875, 'safe_std': 0.00460052490234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-536
   Cohen's d: 0.808
   Safe mean: -0.043304, Risky mean: -0.039398
âŒ Error testing {'layer': 4, 'feature_id': 536, 'cohen_d': 0.80810546875, 'p_value': 1.6304199648368357e-30, 'bankrupt_mean': -0.039398193359375, 'safe_mean': -0.043304443359375, 'bankrupt_std': 0.004901885986328125, 'safe_std': 0.004833221435546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3821
   Cohen's d: -0.808
   Safe mean: 0.076843, Risky mean: 0.074280
âŒ Error testing {'layer': 4, 'feature_id': 3821, 'cohen_d': -0.8076171875, 'p_value': 1.9183622891794648e-30, 'bankrupt_mean': 0.07427978515625, 'safe_mean': 0.07684326171875, 'bankrupt_std': 0.003284454345703125, 'safe_std': 0.003173828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1729
   Cohen's d: -0.807
   Safe mean: 0.021896, Risky mean: 0.019669
âŒ Error testing {'layer': 4, 'feature_id': 1729, 'cohen_d': -0.806640625, 'p_value': 1.85370146147411e-30, 'bankrupt_mean': 0.0196685791015625, 'safe_mean': 0.0218963623046875, 'bankrupt_std': 0.0027179718017578125, 'safe_std': 0.0027618408203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1827
   Cohen's d: -0.807
   Safe mean: -0.022369, Risky mean: -0.025162
âŒ Error testing {'layer': 4, 'feature_id': 1827, 'cohen_d': -0.806640625, 'p_value': 1.6581375424126553e-30, 'bankrupt_mean': -0.0251617431640625, 'safe_mean': -0.022369384765625, 'bankrupt_std': 0.0030689239501953125, 'safe_std': 0.0034694671630859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2158
   Cohen's d: -0.807
   Safe mean: 0.054230, Risky mean: 0.051178
âŒ Error testing {'layer': 4, 'feature_id': 2158, 'cohen_d': -0.806640625, 'p_value': 1.7494903796261332e-30, 'bankrupt_mean': 0.051177978515625, 'safe_mean': 0.054229736328125, 'bankrupt_std': 0.003719329833984375, 'safe_std': 0.0037822723388671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3061
   Cohen's d: -0.806
   Safe mean: -0.021500, Risky mean: -0.025040
âŒ Error testing {'layer': 4, 'feature_id': 3061, 'cohen_d': -0.8056640625, 'p_value': 2.2473301295485742e-30, 'bankrupt_mean': -0.0250396728515625, 'safe_mean': -0.0214996337890625, 'bankrupt_std': 0.003936767578125, 'safe_std': 0.0044097900390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2134
   Cohen's d: 0.803
   Safe mean: -0.027267, Risky mean: -0.022263
âŒ Error testing {'layer': 4, 'feature_id': 2134, 'cohen_d': 0.80322265625, 'p_value': 3.369902904127643e-30, 'bankrupt_mean': -0.0222625732421875, 'safe_mean': -0.0272674560546875, 'bankrupt_std': 0.005367279052734375, 'safe_std': 0.006256103515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2106
   Cohen's d: -0.803
   Safe mean: 0.015854, Risky mean: 0.013527
âŒ Error testing {'layer': 4, 'feature_id': 2106, 'cohen_d': -0.802734375, 'p_value': 4.2770400358520015e-30, 'bankrupt_mean': 0.01352691650390625, 'safe_mean': 0.0158538818359375, 'bankrupt_std': 0.002685546875, 'safe_std': 0.0029087066650390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3084
   Cohen's d: -0.802
   Safe mean: 0.015640, Risky mean: 0.010902
âŒ Error testing {'layer': 4, 'feature_id': 3084, 'cohen_d': -0.8017578125, 'p_value': 4.170314515283679e-30, 'bankrupt_mean': 0.01090240478515625, 'safe_mean': 0.0156402587890625, 'bankrupt_std': 0.0058441162109375, 'safe_std': 0.005908966064453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-495
   Cohen's d: -0.801
   Safe mean: 0.046265, Risky mean: 0.042145
âŒ Error testing {'layer': 4, 'feature_id': 495, 'cohen_d': -0.80078125, 'p_value': 5.082644844676504e-30, 'bankrupt_mean': 0.042144775390625, 'safe_mean': 0.0462646484375, 'bankrupt_std': 0.00463104248046875, 'safe_std': 0.005161285400390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-78
   Cohen's d: -0.800
   Safe mean: 0.028870, Risky mean: 0.025299
âŒ Error testing {'layer': 4, 'feature_id': 78, 'cohen_d': -0.7998046875, 'p_value': 5.49951891115314e-30, 'bankrupt_mean': 0.025299072265625, 'safe_mean': 0.02886962890625, 'bankrupt_std': 0.0030689239501953125, 'safe_std': 0.0045013427734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-784
   Cohen's d: 0.800
   Safe mean: -0.039337, Risky mean: -0.036011
âŒ Error testing {'layer': 4, 'feature_id': 784, 'cohen_d': 0.7998046875, 'p_value': 6.0399644834582646e-30, 'bankrupt_mean': -0.0360107421875, 'safe_mean': -0.039337158203125, 'bankrupt_std': 0.0040130615234375, 'safe_std': 0.0041656494140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 449/600 [00:01<00:00, 340.22it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-2474
   Cohen's d: -0.799
   Safe mean: -0.000257, Risky mean: -0.003504
âŒ Error testing {'layer': 4, 'feature_id': 2474, 'cohen_d': -0.798828125, 'p_value': 6.88287320808859e-30, 'bankrupt_mean': -0.0035037994384765625, 'safe_mean': -0.00025653839111328125, 'bankrupt_std': 0.0036220550537109375, 'safe_std': 0.004077911376953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1937
   Cohen's d: -0.798
   Safe mean: 0.014740, Risky mean: 0.011429
âŒ Error testing {'layer': 4, 'feature_id': 1937, 'cohen_d': -0.7978515625, 'p_value': 8.909303748404543e-30, 'bankrupt_mean': 0.0114288330078125, 'safe_mean': 0.014739990234375, 'bankrupt_std': 0.00356292724609375, 'safe_std': 0.00417327880859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-921
   Cohen's d: -0.796
   Safe mean: 0.078430, Risky mean: 0.075195
âŒ Error testing {'layer': 4, 'feature_id': 921, 'cohen_d': -0.79638671875, 'p_value': 1.0420268982985828e-29, 'bankrupt_mean': 0.0751953125, 'safe_mean': 0.07843017578125, 'bankrupt_std': 0.002750396728515625, 'safe_std': 0.004100799560546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2353
   Cohen's d: -0.796
   Safe mean: 0.004356, Risky mean: 0.000913
âŒ Error testing {'layer': 4, 'feature_id': 2353, 'cohen_d': -0.7958984375, 'p_value': 1.122278189949807e-29, 'bankrupt_mean': 0.0009131431579589844, 'safe_mean': 0.00435638427734375, 'bankrupt_std': 0.003154754638671875, 'safe_std': 0.004360198974609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2984
   Cohen's d: 0.795
   Safe mean: -0.019577, Risky mean: -0.016357
âŒ Error testing {'layer': 4, 'feature_id': 2984, 'cohen_d': 0.79541015625, 'p_value': 1.590298217056767e-29, 'bankrupt_mean': -0.016357421875, 'safe_mean': -0.0195770263671875, 'bankrupt_std': 0.0031070709228515625, 'safe_std': 0.004077911376953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2862
   Cohen's d: -0.795
   Safe mean: -0.022629, Risky mean: -0.025635
âŒ Error testing {'layer': 4, 'feature_id': 2862, 'cohen_d': -0.794921875, 'p_value': 1.3818232611584057e-29, 'bankrupt_mean': -0.025634765625, 'safe_mean': -0.0226287841796875, 'bankrupt_std': 0.003330230712890625, 'safe_std': 0.0037975311279296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1496
   Cohen's d: -0.794
   Safe mean: 0.000854, Risky mean: -0.003275
âŒ Error testing {'layer': 4, 'feature_id': 1496, 'cohen_d': -0.79443359375, 'p_value': 1.359862506458017e-29, 'bankrupt_mean': -0.0032749176025390625, 'safe_mean': 0.0008544921875, 'bankrupt_std': 0.005626678466796875, 'safe_std': 0.00518035888671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-4089
   Cohen's d: 0.794
   Safe mean: -0.058228, Risky mean: -0.054626
âŒ Error testing {'layer': 4, 'feature_id': 4089, 'cohen_d': 0.7939453125, 'p_value': 1.438030679473317e-29, 'bankrupt_mean': -0.05462646484375, 'safe_mean': -0.0582275390625, 'bankrupt_std': 0.00450897216796875, 'safe_std': 0.004535675048828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1004
   Cohen's d: -0.793
   Safe mean: 0.002602, Risky mean: -0.000650
âŒ Error testing {'layer': 4, 'feature_id': 1004, 'cohen_d': -0.79296875, 'p_value': 1.6933776257556005e-29, 'bankrupt_mean': -0.0006499290466308594, 'safe_mean': 0.00260162353515625, 'bankrupt_std': 0.003875732421875, 'safe_std': 0.004108428955078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-65
   Cohen's d: 0.792
   Safe mean: -0.002851, Risky mean: -0.000571
âŒ Error testing {'layer': 4, 'feature_id': 65, 'cohen_d': 0.79248046875, 'p_value': 2.1844283540606035e-29, 'bankrupt_mean': -0.0005712509155273438, 'safe_mean': -0.0028514862060546875, 'bankrupt_std': 0.00266265869140625, 'safe_std': 0.0028896331787109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-925
   Cohen's d: -0.792
   Safe mean: -0.008446, Risky mean: -0.012756
âŒ Error testing {'layer': 4, 'feature_id': 925, 'cohen_d': -0.79150390625, 'p_value': 2.4629098671399975e-29, 'bankrupt_mean': -0.01275634765625, 'safe_mean': -0.00844573974609375, 'bankrupt_std': 0.0042572021484375, 'safe_std': 0.00548553466796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1490
   Cohen's d: 0.792
   Safe mean: -0.022095, Risky mean: -0.017441
âŒ Error testing {'layer': 4, 'feature_id': 1490, 'cohen_d': 0.79150390625, 'p_value': 2.1110084335096576e-29, 'bankrupt_mean': -0.0174407958984375, 'safe_mean': -0.0220947265625, 'bankrupt_std': 0.00533294677734375, 'safe_std': 0.005893707275390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-891
   Cohen's d: -0.790
   Safe mean: 0.096924, Risky mean: 0.090393
âŒ Error testing {'layer': 4, 'feature_id': 891, 'cohen_d': -0.78955078125, 'p_value': 3.0152254712719394e-29, 'bankrupt_mean': 0.09039306640625, 'safe_mean': 0.096923828125, 'bankrupt_std': 0.007686614990234375, 'safe_std': 0.00829315185546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3761
   Cohen's d: 0.790
   Safe mean: -0.007580, Risky mean: -0.004032
âŒ Error testing {'layer': 4, 'feature_id': 3761, 'cohen_d': 0.78955078125, 'p_value': 2.9681230495839643e-29, 'bankrupt_mean': -0.004032135009765625, 'safe_mean': -0.007579803466796875, 'bankrupt_std': 0.0037670135498046875, 'safe_std': 0.0045166015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-1815
   Cohen's d: 0.789
   Safe mean: 0.177734, Risky mean: 0.184448
âŒ Error testing {'layer': 4, 'feature_id': 1815, 'cohen_d': 0.7890625, 'p_value': 3.317160497021401e-29, 'bankrupt_mean': 0.1844482421875, 'safe_mean': 0.177734375, 'bankrupt_std': 0.006496429443359375, 'safe_std': 0.00856781005859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3030
   Cohen's d: -0.786
   Safe mean: -0.013016, Risky mean: -0.015808
âŒ Error testing {'layer': 4, 'feature_id': 3030, 'cohen_d': -0.78564453125, 'p_value': 6.685382332901278e-29, 'bankrupt_mean': -0.01580810546875, 'safe_mean': -0.0130157470703125, 'bankrupt_std': 0.0036792755126953125, 'safe_std': 0.0035552978515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1412
   Cohen's d: 0.785
   Safe mean: 0.031952, Risky mean: 0.035248
âŒ Error testing {'layer': 4, 'feature_id': 1412, 'cohen_d': 0.78466796875, 'p_value': 7.452310067710226e-29, 'bankrupt_mean': 0.035247802734375, 'safe_mean': 0.031951904296875, 'bankrupt_std': 0.003662109375, 'safe_std': 0.004222869873046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1400
   Cohen's d: -0.783
   Safe mean: 0.002163, Risky mean: -0.000895
âŒ Error testing {'layer': 4, 'feature_id': 1400, 'cohen_d': -0.78271484375, 'p_value': 8.911053817771869e-29, 'bankrupt_mean': -0.0008945465087890625, 'safe_mean': 0.002162933349609375, 'bankrupt_std': 0.0028476715087890625, 'safe_std': 0.003936767578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2693
   Cohen's d: 0.782
   Safe mean: 0.036316, Risky mean: 0.039001
âŒ Error testing {'layer': 4, 'feature_id': 2693, 'cohen_d': 0.78173828125, 'p_value': 9.875631269383845e-29, 'bankrupt_mean': 0.03900146484375, 'safe_mean': 0.03631591796875, 'bankrupt_std': 0.0036296844482421875, 'safe_std': 0.0034275054931640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-327
   Cohen's d: -0.781
   Safe mean: 0.009979, Risky mean: 0.007030
âŒ Error testing {'layer': 4, 'feature_id': 327, 'cohen_d': -0.78125, 'p_value': 1.0780687033314126e-28, 'bankrupt_mean': 0.007030487060546875, 'safe_mean': 0.009979248046875, 'bankrupt_std': 0.0029392242431640625, 'safe_std': 0.0037975311279296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1789
   Cohen's d: 0.781
   Safe mean: 0.010635, Risky mean: 0.013458
âŒ Error testing {'layer': 4, 'feature_id': 1789, 'cohen_d': 0.78125, 'p_value': 1.1533501724457042e-28, 'bankrupt_mean': 0.013458251953125, 'safe_mean': 0.0106353759765625, 'bankrupt_std': 0.003116607666015625, 'safe_std': 0.0036296844482421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3174
   Cohen's d: 0.781
   Safe mean: -0.000811, Risky mean: 0.002605
âŒ Error testing {'layer': 4, 'feature_id': 3174, 'cohen_d': 0.78076171875, 'p_value': 1.133354568524373e-28, 'bankrupt_mean': 0.002605438232421875, 'safe_mean': -0.0008111000061035156, 'bankrupt_std': 0.00341796875, 'safe_std': 0.00440216064453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2114
   Cohen's d: -0.780
   Safe mean: 0.010605, Risky mean: 0.006977
âŒ Error testing {'layer': 4, 'feature_id': 2114, 'cohen_d': -0.7802734375, 'p_value': 1.2843054143335826e-28, 'bankrupt_mean': 0.006977081298828125, 'safe_mean': 0.0106048583984375, 'bankrupt_std': 0.00392913818359375, 'safe_std': 0.004669189453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2368
   Cohen's d: 0.780
   Safe mean: -0.013161, Risky mean: -0.008919
âŒ Error testing {'layer': 4, 'feature_id': 2368, 'cohen_d': 0.7802734375, 'p_value': 1.3040819952228808e-28, 'bankrupt_mean': -0.00891876220703125, 'safe_mean': -0.01316070556640625, 'bankrupt_std': 0.00522613525390625, 'safe_std': 0.005443572998046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1156
   Cohen's d: 0.780
   Safe mean: 0.002684, Risky mean: 0.004871
âŒ Error testing {'layer': 4, 'feature_id': 1156, 'cohen_d': 0.77978515625, 'p_value': 1.6192826632619351e-28, 'bankrupt_mean': 0.004871368408203125, 'safe_mean': 0.0026836395263671875, 'bankrupt_std': 0.002223968505859375, 'safe_std': 0.002826690673828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3301
   Cohen's d: 0.780
   Safe mean: -0.017365, Risky mean: -0.013573
âŒ Error testing {'layer': 4, 'feature_id': 3301, 'cohen_d': 0.77978515625, 'p_value': 1.514018848677359e-28, 'bankrupt_mean': -0.01357269287109375, 'safe_mean': -0.017364501953125, 'bankrupt_std': 0.0045013427734375, 'safe_std': 0.00487518310546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1200
   Cohen's d: -0.779
   Safe mean: 0.008240, Risky mean: 0.004650
âŒ Error testing {'layer': 4, 'feature_id': 1200, 'cohen_d': -0.77880859375, 'p_value': 1.6684731704765366e-28, 'bankrupt_mean': 0.004650115966796875, 'safe_mean': 0.00823974609375, 'bankrupt_std': 0.00386810302734375, 'safe_std': 0.00463104248046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1238
   Cohen's d: -0.779
   Safe mean: 0.029861, Risky mean: 0.026398
âŒ Error testing {'layer': 4, 'feature_id': 1238, 'cohen_d': -0.77880859375, 'p_value': 1.906440357122797e-28, 'bankrupt_mean': 0.026397705078125, 'safe_mean': 0.0298614501953125, 'bankrupt_std': 0.003719329833984375, 'safe_std': 0.004474639892578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 486/600 [00:01<00:00, 314.18it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-1396
   Cohen's d: 0.779
   Safe mean: -0.033508, Risky mean: -0.029144
âŒ Error testing {'layer': 4, 'feature_id': 1396, 'cohen_d': 0.77880859375, 'p_value': 1.7496908709440136e-28, 'bankrupt_mean': -0.029144287109375, 'safe_mean': -0.03350830078125, 'bankrupt_std': 0.0059356689453125, 'safe_std': 0.005588531494140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1999
   Cohen's d: -0.779
   Safe mean: 0.021011, Risky mean: 0.017685
âŒ Error testing {'layer': 4, 'feature_id': 1999, 'cohen_d': -0.77880859375, 'p_value': 1.6943317246362261e-28, 'bankrupt_mean': 0.0176849365234375, 'safe_mean': 0.0210113525390625, 'bankrupt_std': 0.0036373138427734375, 'safe_std': 0.004291534423828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2468
   Cohen's d: -0.778
   Safe mean: -0.012581, Risky mean: -0.016708
âŒ Error testing {'layer': 4, 'feature_id': 2468, 'cohen_d': -0.7783203125, 'p_value': 1.919078539992918e-28, 'bankrupt_mean': -0.0167083740234375, 'safe_mean': -0.01258087158203125, 'bankrupt_std': 0.003597259521484375, 'safe_std': 0.0053558349609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-801
   Cohen's d: -0.776
   Safe mean: -0.085266, Risky mean: -0.088013
âŒ Error testing {'layer': 4, 'feature_id': 801, 'cohen_d': -0.7763671875, 'p_value': 3.2835668332088574e-28, 'bankrupt_mean': -0.0880126953125, 'safe_mean': -0.08526611328125, 'bankrupt_std': 0.003009796142578125, 'safe_std': 0.0035552978515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3170
   Cohen's d: 0.775
   Safe mean: 0.009827, Risky mean: 0.012184
âŒ Error testing {'layer': 4, 'feature_id': 3170, 'cohen_d': 0.775390625, 'p_value': 2.566296496950488e-28, 'bankrupt_mean': 0.01218414306640625, 'safe_mean': 0.00982666015625, 'bankrupt_std': 0.002674102783203125, 'safe_std': 0.0030498504638671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3370
   Cohen's d: 0.773
   Safe mean: -0.020157, Risky mean: -0.015793
âŒ Error testing {'layer': 4, 'feature_id': 3370, 'cohen_d': 0.7734375, 'p_value': 3.8818444042820167e-28, 'bankrupt_mean': -0.0157928466796875, 'safe_mean': -0.0201568603515625, 'bankrupt_std': 0.0056610107421875, 'safe_std': 0.00563812255859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1372
   Cohen's d: 0.772
   Safe mean: 0.009064, Risky mean: 0.012741
âŒ Error testing {'layer': 4, 'feature_id': 1372, 'cohen_d': 0.7724609375, 'p_value': 4.238223569011748e-28, 'bankrupt_mean': 0.0127410888671875, 'safe_mean': 0.009063720703125, 'bankrupt_std': 0.00433349609375, 'safe_std': 0.004772186279296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-802
   Cohen's d: -0.771
   Safe mean: 0.013977, Risky mean: 0.011070
âŒ Error testing {'layer': 4, 'feature_id': 802, 'cohen_d': -0.771484375, 'p_value': 4.949192900032279e-28, 'bankrupt_mean': 0.01107025146484375, 'safe_mean': 0.01397705078125, 'bankrupt_std': 0.0029697418212890625, 'safe_std': 0.0037899017333984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-531
   Cohen's d: 0.771
   Safe mean: 0.050568, Risky mean: 0.053741
âŒ Error testing {'layer': 4, 'feature_id': 531, 'cohen_d': 0.7705078125, 'p_value': 6.42185094228069e-28, 'bankrupt_mean': 0.053741455078125, 'safe_mean': 0.050567626953125, 'bankrupt_std': 0.0036449432373046875, 'safe_std': 0.0041351318359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1476
   Cohen's d: -0.771
   Safe mean: 0.046783, Risky mean: 0.041412
âŒ Error testing {'layer': 4, 'feature_id': 1476, 'cohen_d': -0.7705078125, 'p_value': 5.943824890708629e-28, 'bankrupt_mean': 0.041412353515625, 'safe_mean': 0.046783447265625, 'bankrupt_std': 0.006427764892578125, 'safe_std': 0.006988525390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2285
   Cohen's d: -0.770
   Safe mean: 0.051086, Risky mean: 0.048462
âŒ Error testing {'layer': 4, 'feature_id': 2285, 'cohen_d': -0.77001953125, 'p_value': 6.409505554593893e-28, 'bankrupt_mean': 0.0484619140625, 'safe_mean': 0.05108642578125, 'bankrupt_std': 0.002452850341796875, 'safe_std': 0.0034351348876953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-266
   Cohen's d: -0.770
   Safe mean: 0.018097, Risky mean: 0.013947
âŒ Error testing {'layer': 4, 'feature_id': 266, 'cohen_d': -0.76953125, 'p_value': 7.093344505839645e-28, 'bankrupt_mean': 0.013946533203125, 'safe_mean': 0.018096923828125, 'bankrupt_std': 0.00450897216796875, 'safe_std': 0.005420684814453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3869
   Cohen's d: -0.768
   Safe mean: -0.113220, Risky mean: -0.116272
âŒ Error testing {'layer': 4, 'feature_id': 3869, 'cohen_d': -0.767578125, 'p_value': 9.181684509404333e-28, 'bankrupt_mean': -0.11627197265625, 'safe_mean': -0.11322021484375, 'bankrupt_std': 0.002960205078125, 'safe_std': 0.00400543212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2102
   Cohen's d: 0.767
   Safe mean: 0.018417, Risky mean: 0.020477
âŒ Error testing {'layer': 4, 'feature_id': 2102, 'cohen_d': 0.76708984375, 'p_value': 1.2059491154377425e-27, 'bankrupt_mean': 0.020477294921875, 'safe_mean': 0.0184173583984375, 'bankrupt_std': 0.0020580291748046875, 'safe_std': 0.00270843505859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-2950
   Cohen's d: -0.766
   Safe mean: 0.026291, Risky mean: 0.023651
âŒ Error testing {'layer': 4, 'feature_id': 2950, 'cohen_d': -0.76611328125, 'p_value': 1.1006214922904499e-27, 'bankrupt_mean': 0.023651123046875, 'safe_mean': 0.0262908935546875, 'bankrupt_std': 0.0034084320068359375, 'safe_std': 0.003444671630859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2373
   Cohen's d: -0.766
   Safe mean: -0.015671, Risky mean: -0.018982
âŒ Error testing {'layer': 4, 'feature_id': 2373, 'cohen_d': -0.765625, 'p_value': 1.2572982393945853e-27, 'bankrupt_mean': -0.01898193359375, 'safe_mean': -0.0156707763671875, 'bankrupt_std': 0.0038051605224609375, 'safe_std': 0.00434112548828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3980
   Cohen's d: 0.765
   Safe mean: -0.015915, Risky mean: -0.013321
âŒ Error testing {'layer': 4, 'feature_id': 3980, 'cohen_d': 0.76513671875, 'p_value': 1.4052582803031431e-27, 'bankrupt_mean': -0.0133209228515625, 'safe_mean': -0.0159149169921875, 'bankrupt_std': 0.002773284912109375, 'safe_std': 0.0034084320068359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3505
   Cohen's d: 0.764
   Safe mean: -0.013641, Risky mean: -0.008987
âŒ Error testing {'layer': 4, 'feature_id': 3505, 'cohen_d': 0.76416015625, 'p_value': 1.7165870571828443e-27, 'bankrupt_mean': -0.0089874267578125, 'safe_mean': -0.013641357421875, 'bankrupt_std': 0.005916595458984375, 'safe_std': 0.006099700927734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3447
   Cohen's d: -0.764
   Safe mean: -0.016678, Risky mean: -0.020035
âŒ Error testing {'layer': 4, 'feature_id': 3447, 'cohen_d': -0.763671875, 'p_value': 1.8210905058571458e-27, 'bankrupt_mean': -0.0200347900390625, 'safe_mean': -0.0166778564453125, 'bankrupt_std': 0.004055023193359375, 'safe_std': 0.0044097900390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-820
   Cohen's d: 0.763
   Safe mean: 0.031052, Risky mean: 0.035400
âŒ Error testing {'layer': 4, 'feature_id': 820, 'cohen_d': 0.76318359375, 'p_value': 1.8921144381839314e-27, 'bankrupt_mean': 0.035400390625, 'safe_mean': 0.0310516357421875, 'bankrupt_std': 0.005950927734375, 'safe_std': 0.005687713623046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1410
   Cohen's d: -0.763
   Safe mean: 0.019180, Risky mean: 0.012856
âŒ Error testing {'layer': 4, 'feature_id': 1410, 'cohen_d': -0.7626953125, 'p_value': 1.8879193840998688e-27, 'bankrupt_mean': 0.01285552978515625, 'safe_mean': 0.0191802978515625, 'bankrupt_std': 0.00775146484375, 'safe_std': 0.00830841064453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1604
   Cohen's d: -0.760
   Safe mean: -0.034912, Risky mean: -0.037109
âŒ Error testing {'layer': 4, 'feature_id': 1604, 'cohen_d': -0.76025390625, 'p_value': 3.218770845334e-27, 'bankrupt_mean': -0.037109375, 'safe_mean': -0.034912109375, 'bankrupt_std': 0.0023288726806640625, 'safe_std': 0.0029087066650390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2028
   Cohen's d: -0.760
   Safe mean: -0.025742, Risky mean: -0.028152
âŒ Error testing {'layer': 4, 'feature_id': 2028, 'cohen_d': -0.759765625, 'p_value': 3.5180358151885755e-27, 'bankrupt_mean': -0.0281524658203125, 'safe_mean': -0.0257415771484375, 'bankrupt_std': 0.00348663330078125, 'safe_std': 0.0031642913818359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3275
   Cohen's d: 0.760
   Safe mean: 0.012390, Risky mean: 0.016068
âŒ Error testing {'layer': 4, 'feature_id': 3275, 'cohen_d': 0.759765625, 'p_value': 3.437609567087338e-27, 'bankrupt_mean': 0.0160675048828125, 'safe_mean': 0.01239013671875, 'bankrupt_std': 0.00415802001953125, 'safe_std': 0.00485992431640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1160
   Cohen's d: 0.759
   Safe mean: -0.010712, Risky mean: -0.007141
âŒ Error testing {'layer': 4, 'feature_id': 1160, 'cohen_d': 0.75927734375, 'p_value': 3.430554548797189e-27, 'bankrupt_mean': -0.00714111328125, 'safe_mean': -0.010711669921875, 'bankrupt_std': 0.004093170166015625, 'safe_std': 0.00472259521484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3604
   Cohen's d: -0.758
   Safe mean: 0.024963, Risky mean: 0.020279
âŒ Error testing {'layer': 4, 'feature_id': 3604, 'cohen_d': -0.7578125, 'p_value': 4.3214478595924364e-27, 'bankrupt_mean': 0.0202789306640625, 'safe_mean': 0.02496337890625, 'bankrupt_std': 0.005096435546875, 'safe_std': 0.006214141845703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2065
   Cohen's d: -0.757
   Safe mean: 0.038544, Risky mean: 0.034851
âŒ Error testing {'layer': 4, 'feature_id': 2065, 'cohen_d': -0.75732421875, 'p_value': 4.6734368792934206e-27, 'bankrupt_mean': 0.03485107421875, 'safe_mean': 0.038543701171875, 'bankrupt_std': 0.004665374755859375, 'safe_std': 0.0048828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3533
   Cohen's d: 0.757
   Safe mean: -0.015404, Risky mean: -0.012405
âŒ Error testing {'layer': 4, 'feature_id': 3533, 'cohen_d': 0.75732421875, 'p_value': 4.9182191992539836e-27, 'bankrupt_mean': -0.0124053955078125, 'safe_mean': -0.01540374755859375, 'bankrupt_std': 0.00400543212890625, 'safe_std': 0.00395965576171875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-3280
   Cohen's d: 0.757
   Safe mean: -0.000407, Risky mean: 0.004501
âŒ Error testing {'layer': 4, 'feature_id': 3280, 'cohen_d': 0.7568359375, 'p_value': 4.95428898911171e-27, 'bankrupt_mean': 0.0045013427734375, 'safe_mean': -0.0004069805145263672, 'bankrupt_std': 0.005886077880859375, 'safe_std': 0.006500244140625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3727
   Cohen's d: -0.757
   Safe mean: 0.003187, Risky mean: 0.000503
âŒ Error testing {'layer': 4, 'feature_id': 3727, 'cohen_d': -0.7568359375, 'p_value': 5.531924506317018e-27, 'bankrupt_mean': 0.0005030632019042969, 'safe_mean': 0.0031871795654296875, 'bankrupt_std': 0.004070281982421875, 'safe_std': 0.003520965576171875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1961
   Cohen's d: -0.756
   Safe mean: -0.045654, Risky mean: -0.050903
âŒ Error testing {'layer': 4, 'feature_id': 1961, 'cohen_d': -0.75634765625, 'p_value': 5.320279343477481e-27, 'bankrupt_mean': -0.0509033203125, 'safe_mean': -0.045654296875, 'bankrupt_std': 0.006237030029296875, 'safe_std': 0.006961822509765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2628
   Cohen's d: 0.755
   Safe mean: 0.005661, Risky mean: 0.008904
âŒ Error testing {'layer': 4, 'feature_id': 2628, 'cohen_d': 0.75537109375, 'p_value': 6.041023718193649e-27, 'bankrupt_mean': 0.00890350341796875, 'safe_mean': 0.0056610107421875, 'bankrupt_std': 0.003604888916015625, 'safe_std': 0.00431060791015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2581
   Cohen's d: -0.755
   Safe mean: 0.041840, Risky mean: 0.037384
âŒ Error testing {'layer': 4, 'feature_id': 2581, 'cohen_d': -0.7548828125, 'p_value': 6.637585772685682e-27, 'bankrupt_mean': 0.037384033203125, 'safe_mean': 0.041839599609375, 'bankrupt_std': 0.005146026611328125, 'safe_std': 0.005924224853515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1237
   Cohen's d: -0.754
   Safe mean: 0.025238, Risky mean: 0.021271
âŒ Error testing {'layer': 4, 'feature_id': 1237, 'cohen_d': -0.75439453125, 'p_value': 7.891288797971105e-27, 'bankrupt_mean': 0.021270751953125, 'safe_mean': 0.025238037109375, 'bankrupt_std': 0.004467010498046875, 'safe_std': 0.00528717041015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-405
   Cohen's d: -0.754
   Safe mean: 0.010124, Risky mean: 0.004726
âŒ Error testing {'layer': 4, 'feature_id': 405, 'cohen_d': -0.75390625, 'p_value': 7.246741413468226e-27, 'bankrupt_mean': 0.004726409912109375, 'safe_mean': 0.01012420654296875, 'bankrupt_std': 0.006999969482421875, 'safe_std': 0.007160186767578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3779
   Cohen's d: 0.754
   Safe mean: -0.032318, Risky mean: -0.028778
âŒ Error testing {'layer': 4, 'feature_id': 3779, 'cohen_d': 0.75390625, 'p_value': 7.831001920102246e-27, 'bankrupt_mean': -0.028778076171875, 'safe_mean': -0.032318115234375, 'bankrupt_std': 0.004276275634765625, 'safe_std': 0.00470733642578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1639
   Cohen's d: 0.753
   Safe mean: 0.008949, Risky mean: 0.011833
âŒ Error testing {'layer': 4, 'feature_id': 1639, 'cohen_d': 0.7529296875, 'p_value': 9.840043881276179e-27, 'bankrupt_mean': 0.01183319091796875, 'safe_mean': 0.00894927978515625, 'bankrupt_std': 0.0037021636962890625, 'safe_std': 0.00383758544921875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2135
   Cohen's d: 0.753
   Safe mean: -0.015854, Risky mean: -0.012741
âŒ Error testing {'layer': 4, 'feature_id': 2135, 'cohen_d': 0.7529296875, 'p_value': 8.955537595845367e-27, 'bankrupt_mean': -0.0127410888671875, 'safe_mean': -0.0158538818359375, 'bankrupt_std': 0.005191802978515625, 'safe_std': 0.004093170166015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3997
   Cohen's d: -0.752
   Safe mean: 0.008240, Risky mean: 0.003952
âŒ Error testing {'layer': 4, 'feature_id': 3997, 'cohen_d': -0.75244140625, 'p_value': 1.036992059462695e-26, 'bankrupt_mean': 0.0039520263671875, 'safe_mean': 0.00823974609375, 'bankrupt_std': 0.0037021636962890625, 'safe_std': 0.005756378173828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-72
   Cohen's d: -0.752
   Safe mean: 0.004105, Risky mean: 0.001143
âŒ Error testing {'layer': 4, 'feature_id': 72, 'cohen_d': -0.751953125, 'p_value': 1.1124238376413657e-26, 'bankrupt_mean': 0.0011434555053710938, 'safe_mean': 0.0041046142578125, 'bankrupt_std': 0.002979278564453125, 'safe_std': 0.00396728515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2637
   Cohen's d: -0.751
   Safe mean: -0.046844, Risky mean: -0.048706
âŒ Error testing {'layer': 4, 'feature_id': 2637, 'cohen_d': -0.75146484375, 'p_value': 1.1724105812975138e-26, 'bankrupt_mean': -0.0487060546875, 'safe_mean': -0.046844482421875, 'bankrupt_std': 0.0024776458740234375, 'safe_std': 0.0024776458740234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3384
   Cohen's d: 0.751
   Safe mean: -0.047974, Risky mean: -0.044617
âŒ Error testing {'layer': 4, 'feature_id': 3384, 'cohen_d': 0.75146484375, 'p_value': 1.1652876953347018e-26, 'bankrupt_mean': -0.04461669921875, 'safe_mean': -0.0479736328125, 'bankrupt_std': 0.00444793701171875, 'safe_std': 0.004467010498046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 520/600 [00:02<00:00, 144.97it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-3593
   Cohen's d: -0.751
   Safe mean: 0.039246, Risky mean: 0.036163
âŒ Error testing {'layer': 4, 'feature_id': 3593, 'cohen_d': -0.75146484375, 'p_value': 1.0948478579724724e-26, 'bankrupt_mean': 0.036163330078125, 'safe_mean': 0.03924560546875, 'bankrupt_std': 0.004108428955078125, 'safe_std': 0.004100799560546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3265
   Cohen's d: -0.750
   Safe mean: 0.033813, Risky mean: 0.030594
âŒ Error testing {'layer': 4, 'feature_id': 3265, 'cohen_d': -0.75, 'p_value': 1.4463275923674433e-26, 'bankrupt_mean': 0.0305938720703125, 'safe_mean': 0.0338134765625, 'bankrupt_std': 0.00433349609375, 'safe_std': 0.004291534423828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3445
   Cohen's d: -0.750
   Safe mean: 0.022171, Risky mean: 0.018738
âŒ Error testing {'layer': 4, 'feature_id': 3445, 'cohen_d': -0.74951171875, 'p_value': 1.599877512371154e-26, 'bankrupt_mean': 0.01873779296875, 'safe_mean': 0.0221710205078125, 'bankrupt_std': 0.0027294158935546875, 'safe_std': 0.00463104248046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2685
   Cohen's d: -0.749
   Safe mean: -0.039978, Risky mean: -0.042816
âŒ Error testing {'layer': 4, 'feature_id': 2685, 'cohen_d': -0.7490234375, 'p_value': 1.6347879009064224e-26, 'bankrupt_mean': -0.042816162109375, 'safe_mean': -0.03997802734375, 'bankrupt_std': 0.002651214599609375, 'safe_std': 0.00382232666015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2962
   Cohen's d: 0.749
   Safe mean: -0.059601, Risky mean: -0.056793
âŒ Error testing {'layer': 4, 'feature_id': 2962, 'cohen_d': 0.74853515625, 'p_value': 1.9702002585203203e-26, 'bankrupt_mean': -0.056793212890625, 'safe_mean': -0.059600830078125, 'bankrupt_std': 0.0028057098388671875, 'safe_std': 0.0037822723388671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1579
   Cohen's d: 0.748
   Safe mean: -0.062256, Risky mean: -0.059052
âŒ Error testing {'layer': 4, 'feature_id': 1579, 'cohen_d': 0.748046875, 'p_value': 2.0795742954943685e-26, 'bankrupt_mean': -0.059051513671875, 'safe_mean': -0.062255859375, 'bankrupt_std': 0.003444671630859375, 'safe_std': 0.00431060791015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1942
   Cohen's d: -0.748
   Safe mean: -0.025208, Risky mean: -0.028824
âŒ Error testing {'layer': 4, 'feature_id': 1942, 'cohen_d': -0.748046875, 'p_value': 1.9757381076900847e-26, 'bankrupt_mean': -0.0288238525390625, 'safe_mean': -0.02520751953125, 'bankrupt_std': 0.0045166015625, 'safe_std': 0.00484466552734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-867
   Cohen's d: -0.746
   Safe mean: 0.010208, Risky mean: 0.005245
âŒ Error testing {'layer': 4, 'feature_id': 867, 'cohen_d': -0.74560546875, 'p_value': 2.74520621204852e-26, 'bankrupt_mean': 0.005245208740234375, 'safe_mean': 0.0102081298828125, 'bankrupt_std': 0.006542205810546875, 'safe_std': 0.00666046142578125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2556
   Cohen's d: -0.745
   Safe mean: -0.038940, Risky mean: -0.041595
âŒ Error testing {'layer': 4, 'feature_id': 2556, 'cohen_d': -0.7451171875, 'p_value': 2.815400247110693e-26, 'bankrupt_mean': -0.041595458984375, 'safe_mean': -0.0389404296875, 'bankrupt_std': 0.0032482147216796875, 'safe_std': 0.003570556640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3292
   Cohen's d: -0.745
   Safe mean: 0.056396, Risky mean: 0.051239
âŒ Error testing {'layer': 4, 'feature_id': 3292, 'cohen_d': -0.74462890625, 'p_value': 3.283278824589225e-26, 'bankrupt_mean': 0.051239013671875, 'safe_mean': 0.056396484375, 'bankrupt_std': 0.0059967041015625, 'safe_std': 0.0069580078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-610
   Cohen's d: -0.744
   Safe mean: 0.016357, Risky mean: 0.012085
âŒ Error testing {'layer': 4, 'feature_id': 610, 'cohen_d': -0.744140625, 'p_value': 3.5058025304173885e-26, 'bankrupt_mean': 0.0120849609375, 'safe_mean': 0.016357421875, 'bankrupt_std': 0.004947662353515625, 'safe_std': 0.005767822265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3240
   Cohen's d: -0.744
   Safe mean: -0.031204, Risky mean: -0.034485
âŒ Error testing {'layer': 4, 'feature_id': 3240, 'cohen_d': -0.744140625, 'p_value': 3.4148347424012565e-26, 'bankrupt_mean': -0.03448486328125, 'safe_mean': -0.0312042236328125, 'bankrupt_std': 0.00399017333984375, 'safe_std': 0.004421234130859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2957
   Cohen's d: -0.743
   Safe mean: -0.028229, Risky mean: -0.030655
âŒ Error testing {'layer': 4, 'feature_id': 2957, 'cohen_d': -0.74267578125, 'p_value': 4.082630291542462e-26, 'bankrupt_mean': -0.0306549072265625, 'safe_mean': -0.028228759765625, 'bankrupt_std': 0.00348663330078125, 'safe_std': 0.00325775146484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2149
   Cohen's d: -0.742
   Safe mean: 0.003187, Risky mean: 0.000873
âŒ Error testing {'layer': 4, 'feature_id': 2149, 'cohen_d': -0.7421875, 'p_value': 4.003982119530945e-26, 'bankrupt_mean': 0.0008730888366699219, 'safe_mean': 0.0031871795654296875, 'bankrupt_std': 0.002353668212890625, 'safe_std': 0.00313568115234375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 545/600 [00:02<00:00, 101.86it/s]

ðŸ§ª Testing L4-3749
   Cohen's d: 0.742
   Safe mean: 0.017776, Risky mean: 0.021057
âŒ Error testing {'layer': 4, 'feature_id': 3749, 'cohen_d': 0.7421875, 'p_value': 4.501943085082105e-26, 'bankrupt_mean': 0.02105712890625, 'safe_mean': 0.0177764892578125, 'bankrupt_std': 0.00433349609375, 'safe_std': 0.004421234130859375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1070
   Cohen's d: -0.742
   Safe mean: 0.010078, Risky mean: 0.006096
âŒ Error testing {'layer': 4, 'feature_id': 1070, 'cohen_d': -0.74169921875, 'p_value': 4.5742431824562706e-26, 'bankrupt_mean': 0.00609588623046875, 'safe_mean': 0.01007843017578125, 'bankrupt_std': 0.005016326904296875, 'safe_std': 0.005374908447265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3667
   Cohen's d: 0.741
   Safe mean: 0.011551, Risky mean: 0.015373
âŒ Error testing {'layer': 4, 'feature_id': 3667, 'cohen_d': 0.7412109375, 'p_value': 5.303978435177887e-26, 'bankrupt_mean': 0.01537322998046875, 'safe_mean': 0.0115509033203125, 'bankrupt_std': 0.00402069091796875, 'safe_std': 0.005191802978515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1152
   Cohen's d: -0.740
   Safe mean: 0.015083, Risky mean: 0.012268
âŒ Error testing {'layer': 4, 'feature_id': 1152, 'cohen_d': -0.73974609375, 'p_value': 7.181484849932233e-26, 'bankrupt_mean': 0.01226806640625, 'safe_mean': 0.01508331298828125, 'bankrupt_std': 0.004093170166015625, 'safe_std': 0.0037975311279296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1322
   Cohen's d: -0.739
   Safe mean: 0.074402, Risky mean: 0.070068
âŒ Error testing {'layer': 4, 'feature_id': 1322, 'cohen_d': -0.7392578125, 'p_value': 7.789210713700742e-26, 'bankrupt_mean': 0.070068359375, 'safe_mean': 0.07440185546875, 'bankrupt_std': 0.00494384765625, 'safe_std': 0.005893707275390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-345
   Cohen's d: -0.739
   Safe mean: 0.035248, Risky mean: 0.031830
âŒ Error testing {'layer': 4, 'feature_id': 345, 'cohen_d': -0.73876953125, 'p_value': 7.25079221332445e-26, 'bankrupt_mean': 0.031829833984375, 'safe_mean': 0.035247802734375, 'bankrupt_std': 0.0045623779296875, 'safe_std': 0.004627227783203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1036
   Cohen's d: 0.738
   Safe mean: -0.015221, Risky mean: -0.010880
âŒ Error testing {'layer': 4, 'feature_id': 1036, 'cohen_d': 0.73828125, 'p_value': 8.921919816815912e-26, 'bankrupt_mean': -0.0108795166015625, 'safe_mean': -0.01522064208984375, 'bankrupt_std': 0.006000518798828125, 'safe_std': 0.005878448486328125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1645
   Cohen's d: -0.738
   Safe mean: 0.001647, Risky mean: -0.001427
âŒ Error testing {'layer': 4, 'feature_id': 1645, 'cohen_d': -0.73828125, 'p_value': 9.13292984086254e-26, 'bankrupt_mean': -0.00142669677734375, 'safe_mean': 0.0016469955444335938, 'bankrupt_std': 0.005016326904296875, 'safe_std': 0.0041351318359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-4091
   Cohen's d: 0.738
   Safe mean: 0.058868, Risky mean: 0.061371
âŒ Error testing {'layer': 4, 'feature_id': 4091, 'cohen_d': 0.73779296875, 'p_value': 9.879538730968762e-26, 'bankrupt_mean': 0.061370849609375, 'safe_mean': 0.058868408203125, 'bankrupt_std': 0.0022640228271484375, 'safe_std': 0.0034275054931640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1967
   Cohen's d: -0.737
   Safe mean: 0.023178, Risky mean: 0.020645
âŒ Error testing {'layer': 4, 'feature_id': 1967, 'cohen_d': -0.7373046875, 'p_value': 9.216911362396314e-26, 'bankrupt_mean': 0.0206451416015625, 'safe_mean': 0.0231781005859375, 'bankrupt_std': 0.003391265869140625, 'safe_std': 0.0034351348876953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2956
   Cohen's d: -0.737
   Safe mean: 0.000865, Risky mean: -0.002872
âŒ Error testing {'layer': 4, 'feature_id': 2956, 'cohen_d': -0.73681640625, 'p_value': 9.48229176353204e-26, 'bankrupt_mean': -0.002872467041015625, 'safe_mean': 0.0008645057678222656, 'bankrupt_std': 0.004055023193359375, 'safe_std': 0.005092620849609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1055
   Cohen's d: -0.736
   Safe mean: 0.010239, Risky mean: 0.006718
âŒ Error testing {'layer': 4, 'feature_id': 1055, 'cohen_d': -0.73583984375, 'p_value': 1.2055099582736651e-25, 'bankrupt_mean': 0.006717681884765625, 'safe_mean': 0.0102386474609375, 'bankrupt_std': 0.00402069091796875, 'safe_std': 0.004802703857421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1669
   Cohen's d: 0.736
   Safe mean: -0.151733, Risky mean: -0.148804
âŒ Error testing {'layer': 4, 'feature_id': 1669, 'cohen_d': 0.73583984375, 'p_value': 1.0981559360739978e-25, 'bankrupt_mean': -0.1488037109375, 'safe_mean': -0.1517333984375, 'bankrupt_std': 0.003116607666015625, 'safe_std': 0.00400543212890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2661
   Cohen's d: 0.736
   Safe mean: 0.005054, Risky mean: 0.007557
âŒ Error testing {'layer': 4, 'feature_id': 2661, 'cohen_d': 0.73583984375, 'p_value': 1.2401493755192223e-25, 'bankrupt_mean': 0.007556915283203125, 'safe_mean': 0.005054473876953125, 'bankrupt_std': 0.003173828125, 'safe_std': 0.0034084320068359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-2721
   Cohen's d: 0.735
   Safe mean: -0.002176, Risky mean: 0.002380
âŒ Error testing {'layer': 4, 'feature_id': 2721, 'cohen_d': 0.7353515625, 'p_value': 1.3056244638950158e-25, 'bankrupt_mean': 0.00238037109375, 'safe_mean': -0.0021762847900390625, 'bankrupt_std': 0.00656890869140625, 'safe_std': 0.0061798095703125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-604
   Cohen's d: 0.735
   Safe mean: 0.037659, Risky mean: 0.041718
âŒ Error testing {'layer': 4, 'feature_id': 604, 'cohen_d': 0.73486328125, 'p_value': 1.4347338091661055e-25, 'bankrupt_mean': 0.041717529296875, 'safe_mean': 0.03765869140625, 'bankrupt_std': 0.00504302978515625, 'safe_std': 0.0055389404296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-987
   Cohen's d: 0.735
   Safe mean: -0.039673, Risky mean: -0.037659
âŒ Error testing {'layer': 4, 'feature_id': 987, 'cohen_d': 0.73486328125, 'p_value': 1.153072547308362e-25, 'bankrupt_mean': -0.03765869140625, 'safe_mean': -0.0396728515625, 'bankrupt_std': 0.0026073455810546875, 'safe_std': 0.0027408599853515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1282
   Cohen's d: 0.735
   Safe mean: -0.005184, Risky mean: -0.002680
âŒ Error testing {'layer': 4, 'feature_id': 1282, 'cohen_d': 0.73486328125, 'p_value': 1.3236171041994995e-25, 'bankrupt_mean': -0.0026798248291015625, 'safe_mean': -0.005184173583984375, 'bankrupt_std': 0.0033206939697265625, 'safe_std': 0.0034084320068359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2843
   Cohen's d: 0.735
   Safe mean: -0.030807, Risky mean: -0.028320
âŒ Error testing {'layer': 4, 'feature_id': 2843, 'cohen_d': 0.73486328125, 'p_value': 1.5425955900248505e-25, 'bankrupt_mean': -0.0283203125, 'safe_mean': -0.0308074951171875, 'bankrupt_std': 0.00299072265625, 'safe_std': 0.0034008026123046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2150
   Cohen's d: 0.734
   Safe mean: 0.003122, Risky mean: 0.006420
âŒ Error testing {'layer': 4, 'feature_id': 2150, 'cohen_d': 0.73388671875, 'p_value': 1.7310425130044482e-25, 'bankrupt_mean': 0.006420135498046875, 'safe_mean': 0.0031223297119140625, 'bankrupt_std': 0.0039215087890625, 'safe_std': 0.0045166015625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1384
   Cohen's d: -0.730
   Safe mean: -0.037506, Risky mean: -0.041901
âŒ Error testing {'layer': 4, 'feature_id': 1384, 'cohen_d': -0.73046875, 'p_value': 2.5772130010480076e-25, 'bankrupt_mean': -0.041900634765625, 'safe_mean': -0.037506103515625, 'bankrupt_std': 0.005840301513671875, 'safe_std': 0.00601959228515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2323
   Cohen's d: -0.730
   Safe mean: -0.013466, Risky mean: -0.015167
âŒ Error testing {'layer': 4, 'feature_id': 2323, 'cohen_d': -0.73046875, 'p_value': 2.8834626878653496e-25, 'bankrupt_mean': -0.015167236328125, 'safe_mean': -0.01346588134765625, 'bankrupt_std': 0.001983642578125, 'safe_std': 0.00234222412109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-170
   Cohen's d: -0.730
   Safe mean: 0.043152, Risky mean: 0.040497
âŒ Error testing {'layer': 4, 'feature_id': 170, 'cohen_d': -0.72998046875, 'p_value': 2.6453207657236785e-25, 'bankrupt_mean': 0.040496826171875, 'safe_mean': 0.04315185546875, 'bankrupt_std': 0.002696990966796875, 'safe_std': 0.003662109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1817
   Cohen's d: -0.730
   Safe mean: 0.018921, Risky mean: 0.017441
âŒ Error testing {'layer': 4, 'feature_id': 1817, 'cohen_d': -0.72998046875, 'p_value': 3.112878936548931e-25, 'bankrupt_mean': 0.0174407958984375, 'safe_mean': 0.0189208984375, 'bankrupt_std': 0.0015821456909179688, 'safe_std': 0.0020427703857421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2871
   Cohen's d: 0.730
   Safe mean: 0.021027, Risky mean: 0.024643
âŒ Error testing {'layer': 4, 'feature_id': 2871, 'cohen_d': 0.72998046875, 'p_value': 3.044022825299143e-25, 'bankrupt_mean': 0.0246429443359375, 'safe_mean': 0.021026611328125, 'bankrupt_std': 0.0049896240234375, 'safe_std': 0.004955291748046875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1276
   Cohen's d: 0.729
   Safe mean: 0.005856, Risky mean: 0.008430
âŒ Error testing {'layer': 4, 'feature_id': 1276, 'cohen_d': 0.7294921875, 'p_value': 3.0282535078574955e-25, 'bankrupt_mean': 0.00843048095703125, 'safe_mean': 0.005855560302734375, 'bankrupt_std': 0.002979278564453125, 'safe_std': 0.0035457611083984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1535
   Cohen's d: 0.729
   Safe mean: 0.032532, Risky mean: 0.035126
âŒ Error testing {'layer': 4, 'feature_id': 1535, 'cohen_d': 0.7294921875, 'p_value': 3.030359918712239e-25, 'bankrupt_mean': 0.035125732421875, 'safe_mean': 0.03253173828125, 'bankrupt_std': 0.0027408599853515625, 'safe_std': 0.0035800933837890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2492
   Cohen's d: 0.729
   Safe mean: -0.023499, Risky mean: -0.019257
âŒ Error testing {'layer': 4, 'feature_id': 2492, 'cohen_d': 0.72900390625, 'p_value': 3.4432885407881635e-25, 'bankrupt_mean': -0.019256591796875, 'safe_mean': -0.02349853515625, 'bankrupt_std': 0.005092620849609375, 'safe_std': 0.0058441162109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 564/600 [00:03<00:00, 76.16it/s] Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-355
   Cohen's d: -0.729
   Safe mean: -0.021347, Risky mean: -0.023392
âŒ Error testing {'layer': 4, 'feature_id': 355, 'cohen_d': -0.728515625, 'p_value': 3.5115947790486706e-25, 'bankrupt_mean': -0.0233917236328125, 'safe_mean': -0.0213470458984375, 'bankrupt_std': 0.0021419525146484375, 'safe_std': 0.002826690673828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1348
   Cohen's d: 0.729
   Safe mean: -0.004650, Risky mean: -0.000739
âŒ Error testing {'layer': 4, 'feature_id': 1348, 'cohen_d': 0.728515625, 'p_value': 3.383288364839292e-25, 'bankrupt_mean': -0.0007386207580566406, 'safe_mean': -0.004650115966796875, 'bankrupt_std': 0.0044403076171875, 'safe_std': 0.0053863525390625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2876
   Cohen's d: 0.729
   Safe mean: 0.051605, Risky mean: 0.054382
âŒ Error testing {'layer': 4, 'feature_id': 2876, 'cohen_d': 0.728515625, 'p_value': 3.8854024627144257e-25, 'bankrupt_mean': 0.05438232421875, 'safe_mean': 0.051605224609375, 'bankrupt_std': 0.0033740997314453125, 'safe_std': 0.0038299560546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3191
   Cohen's d: -0.729
   Safe mean: 0.035278, Risky mean: 0.032501
âŒ Error testing {'layer': 4, 'feature_id': 3191, 'cohen_d': -0.728515625, 'p_value': 3.942246706417163e-25, 'bankrupt_mean': 0.032501220703125, 'safe_mean': 0.0352783203125, 'bankrupt_std': 0.004093170166015625, 'safe_std': 0.0038051605224609375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2820
   Cohen's d: 0.728
   Safe mean: -0.001237, Risky mean: 0.002485
âŒ Error testing {'layer': 4, 'feature_id': 2820, 'cohen_d': 0.72802734375, 'p_value': 3.5825240465400823e-25, 'bankrupt_mean': 0.0024852752685546875, 'safe_mean': -0.0012369155883789062, 'bankrupt_std': 0.004611968994140625, 'safe_std': 0.005126953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-643
   Cohen's d: 0.728
   Safe mean: 0.009804, Risky mean: 0.012550
âŒ Error testing {'layer': 4, 'feature_id': 643, 'cohen_d': 0.7275390625, 'p_value': 4.348475550562687e-25, 'bankrupt_mean': 0.01255035400390625, 'safe_mean': 0.00980377197265625, 'bankrupt_std': 0.0033740997314453125, 'safe_std': 0.0037899017333984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-48
   Cohen's d: -0.727
   Safe mean: 0.012726, Risky mean: 0.009247
âŒ Error testing {'layer': 4, 'feature_id': 48, 'cohen_d': -0.72705078125, 'p_value': 4.365926082998894e-25, 'bankrupt_mean': 0.009246826171875, 'safe_mean': 0.012725830078125, 'bankrupt_std': 0.004974365234375, 'safe_std': 0.004779815673828125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2202
   Cohen's d: -0.727
   Safe mean: 0.011391, Risky mean: 0.006660
âŒ Error testing {'layer': 4, 'feature_id': 2202, 'cohen_d': -0.72705078125, 'p_value': 4.1769172571647885e-25, 'bankrupt_mean': 0.00666046142578125, 'safe_mean': 0.01139068603515625, 'bankrupt_std': 0.00614166259765625, 'safe_std': 0.006511688232421875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-4074
   Cohen's d: 0.727
   Safe mean: 0.007553, Risky mean: 0.010490
âŒ Error testing {'layer': 4, 'feature_id': 4074, 'cohen_d': 0.72705078125, 'p_value': 3.786541200773735e-25, 'bankrupt_mean': 0.01049041748046875, 'safe_mean': 0.0075531005859375, 'bankrupt_std': 0.00305938720703125, 'safe_std': 0.004062652587890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-371
   Cohen's d: 0.727
   Safe mean: 0.018814, Risky mean: 0.023209
âŒ Error testing {'layer': 4, 'feature_id': 371, 'cohen_d': 0.7265625, 'p_value': 4.909513671196709e-25, 'bankrupt_mean': 0.0232086181640625, 'safe_mean': 0.0188140869140625, 'bankrupt_std': 0.0039825439453125, 'safe_std': 0.006107330322265625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3460
   Cohen's d: -0.727
   Safe mean: -0.008530, Risky mean: -0.010994
âŒ Error testing {'layer': 4, 'feature_id': 3460, 'cohen_d': -0.7265625, 'p_value': 4.53997514305269e-25, 'bankrupt_mean': -0.01099395751953125, 'safe_mean': -0.0085296630859375, 'bankrupt_std': 0.00244140625, 'safe_std': 0.00341796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1664
   Cohen's d: -0.726
   Safe mean: 0.001144, Risky mean: -0.001585
âŒ Error testing {'layer': 4, 'feature_id': 1664, 'cohen_d': -0.72607421875, 'p_value': 4.977895965554363e-25, 'bankrupt_mean': -0.0015850067138671875, 'safe_mean': 0.0011444091796875, 'bankrupt_std': 0.003749847412109375, 'safe_std': 0.0037593841552734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1708
   Cohen's d: 0.726
   Safe mean: 0.001413, Risky mean: 0.004044
âŒ Error testing {'layer': 4, 'feature_id': 1708, 'cohen_d': 0.72607421875, 'p_value': 5.260456537470263e-25, 'bankrupt_mean': 0.0040435791015625, 'safe_mean': 0.0014133453369140625, 'bankrupt_std': 0.0031833648681640625, 'safe_std': 0.0036373138427734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3784
   Cohen's d: 0.726
   Safe mean: 0.018921, Risky mean: 0.022400
âŒ Error testing {'layer': 4, 'feature_id': 3784, 'cohen_d': 0.72607421875, 'p_value': 4.986931025941876e-25, 'bankrupt_mean': 0.02239990234375, 'safe_mean': 0.0189208984375, 'bankrupt_std': 0.00460052490234375, 'safe_std': 0.004795074462890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 579/600 [00:03<00:00, 71.70it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.



ðŸ§ª Testing L4-2925
   Cohen's d: -0.726
   Safe mean: 0.012627, Risky mean: 0.009201
âŒ Error testing {'layer': 4, 'feature_id': 2925, 'cohen_d': -0.7255859375, 'p_value': 5.578512369288817e-25, 'bankrupt_mean': 0.0092010498046875, 'safe_mean': 0.01262664794921875, 'bankrupt_std': 0.004734039306640625, 'safe_std': 0.00472259521484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-83
   Cohen's d: 0.725
   Safe mean: -0.006802, Risky mean: -0.004700
âŒ Error testing {'layer': 4, 'feature_id': 83, 'cohen_d': 0.72509765625, 'p_value': 5.161539105590113e-25, 'bankrupt_mean': -0.00469970703125, 'safe_mean': -0.006801605224609375, 'bankrupt_std': 0.0020580291748046875, 'safe_std': 0.0029201507568359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1465
   Cohen's d: -0.725
   Safe mean: -0.017822, Risky mean: -0.020294
âŒ Error testing {'layer': 4, 'feature_id': 1465, 'cohen_d': -0.72509765625, 'p_value': 5.46152949982322e-25, 'bankrupt_mean': -0.020294189453125, 'safe_mean': -0.017822265625, 'bankrupt_std': 0.0024166107177734375, 'safe_std': 0.0034351348876953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-958
   Cohen's d: -0.725
   Safe mean: 0.050842, Risky mean: 0.047333
âŒ Error testing {'layer': 4, 'feature_id': 958, 'cohen_d': -0.724609375, 'p_value': 6.262558228518277e-25, 'bankrupt_mean': 0.047332763671875, 'safe_mean': 0.05084228515625, 'bankrupt_std': 0.00415802001953125, 'safe_std': 0.004863739013671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3297
   Cohen's d: -0.724
   Safe mean: -0.023056, Risky mean: -0.026489
âŒ Error testing {'layer': 4, 'feature_id': 3297, 'cohen_d': -0.7236328125, 'p_value': 7.275931657961252e-25, 'bankrupt_mean': -0.0264892578125, 'safe_mean': -0.0230560302734375, 'bankrupt_std': 0.00385284423828125, 'safe_std': 0.004772186279296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3846
   Cohen's d: -0.724
   Safe mean: 0.053619, Risky mean: 0.050079
âŒ Error testing {'layer': 4, 'feature_id': 3846, 'cohen_d': -0.7236328125, 'p_value': 6.931247962401577e-25, 'bankrupt_mean': 0.050079345703125, 'safe_mean': 0.053619384765625, 'bankrupt_std': 0.004726409912109375, 'safe_std': 0.004894256591796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3993
   Cohen's d: 0.724
   Safe mean: -0.032349, Risky mean: -0.027618
âŒ Error testing {'layer': 4, 'feature_id': 3993, 'cohen_d': 0.7236328125, 'p_value': 6.84334885661074e-25, 'bankrupt_mean': -0.027618408203125, 'safe_mean': -0.0323486328125, 'bankrupt_std': 0.006664276123046875, 'safe_std': 0.006526947021484375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2341
   Cohen's d: -0.723
   Safe mean: 0.002451, Risky mean: -0.000447
âŒ Error testing {'layer': 4, 'feature_id': 2341, 'cohen_d': -0.72314453125, 'p_value': 7.095840667448548e-25, 'bankrupt_mean': -0.0004470348358154297, 'safe_mean': 0.0024509429931640625, 'bankrupt_std': 0.00348663330078125, 'safe_std': 0.00402069091796875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3212
   Cohen's d: -0.723
   Safe mean: 0.000779, Risky mean: -0.002836
âŒ Error testing {'layer': 4, 'feature_id': 3212, 'cohen_d': -0.72314453125, 'p_value': 7.618919546670715e-25, 'bankrupt_mean': -0.0028362274169921875, 'safe_mean': 0.0007786750793457031, 'bankrupt_std': 0.004611968994140625, 'safe_std': 0.005008697509765625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3911
   Cohen's d: 0.720
   Safe mean: -0.040222, Risky mean: -0.036804
âŒ Error testing {'layer': 4, 'feature_id': 3911, 'cohen_d': 0.72021484375, 'p_value': 1.2866222298612064e-24, 'bankrupt_mean': -0.03680419921875, 'safe_mean': -0.04022216796875, 'bankrupt_std': 0.004810333251953125, 'safe_std': 0.0047454833984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-236
   Cohen's d: -0.719
   Safe mean: -0.038574, Risky mean: -0.041351
âŒ Error testing {'layer': 4, 'feature_id': 236, 'cohen_d': -0.71923828125, 'p_value': 1.2781149174297938e-24, 'bankrupt_mean': -0.041351318359375, 'safe_mean': -0.03857421875, 'bankrupt_std': 0.00330352783203125, 'safe_std': 0.00386810302734375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-606
   Cohen's d: -0.719
   Safe mean: 0.007778, Risky mean: 0.004368
âŒ Error testing {'layer': 4, 'feature_id': 606, 'cohen_d': -0.71923828125, 'p_value': 1.4595270702648745e-24, 'bankrupt_mean': 0.004367828369140625, 'safe_mean': 0.007778167724609375, 'bankrupt_std': 0.00383758544921875, 'safe_std': 0.004772186279296875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3919
   Cohen's d: -0.719
   Safe mean: 0.031830, Risky mean: 0.029907
âŒ Error testing {'layer': 4, 'feature_id': 3919, 'cohen_d': -0.71875, 'p_value': 1.3813944198050504e-24, 'bankrupt_mean': 0.0299072265625, 'safe_mean': 0.031829833984375, 'bankrupt_std': 0.0026302337646484375, 'safe_std': 0.002674102783203125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2703
   Cohen's d: -0.717
   Safe mean: 0.034119, Risky mean: 0.031708
âŒ Error testing {'layer': 4, 'feature_id': 2703, 'cohen_d': -0.716796875, 'p_value': 2.43099781384523e-24, 'bankrupt_mean': 0.031707763671875, 'safe_mean': 0.03411865234375, 'bankrupt_std': 0.0032482147216796875, 'safe_std': 0.0033740997314453125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 598/600 [00:03<00:00, 84.50it/s]Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 506, in run
    result = self.test_single_feature(feature)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 334, in test_single_feature
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2396, in generate
    self._prepare_special_tokens(generation_config, kwargs_has_attention_mask, device=device)
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/generation/utils.py", line 2171, in _prepare_special_tokens
    and isin_mps_friendly(elements=eos_token_tensor, test_elements=pad_token_tensor).any()
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/miniforge3/envs/llama_sae_env/lib/python3.11/site-packages/transformers/pytorch_utils.py", line 338, in isin_mps_friendly
    return torch.isin(elements, test_elements)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Testing features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:03<00:00, 166.33it/s]


ðŸ§ª Testing L4-3088
   Cohen's d: -0.717
   Safe mean: 0.033447, Risky mean: 0.029495
âŒ Error testing {'layer': 4, 'feature_id': 3088, 'cohen_d': -0.716796875, 'p_value': 1.948635426156506e-24, 'bankrupt_mean': 0.0294952392578125, 'safe_mean': 0.033447265625, 'bankrupt_std': 0.0060882568359375, 'safe_std': 0.0054931640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2084
   Cohen's d: 0.715
   Safe mean: -0.008377, Risky mean: -0.005455
âŒ Error testing {'layer': 4, 'feature_id': 2084, 'cohen_d': 0.71533203125, 'p_value': 2.4554278693706348e-24, 'bankrupt_mean': -0.00545501708984375, 'safe_mean': -0.0083770751953125, 'bankrupt_std': 0.0036220550537109375, 'safe_std': 0.004100799560546875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2848
   Cohen's d: 0.715
   Safe mean: 0.005749, Risky mean: 0.009132
âŒ Error testing {'layer': 4, 'feature_id': 2848, 'cohen_d': 0.71484375, 'p_value': 2.5264026138634805e-24, 'bankrupt_mean': 0.00913238525390625, 'safe_mean': 0.005748748779296875, 'bankrupt_std': 0.004840850830078125, 'safe_std': 0.004726409912109375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1553
   Cohen's d: -0.714
   Safe mean: 0.050751, Risky mean: 0.047119
âŒ Error testing {'layer': 4, 'feature_id': 1553, 'cohen_d': -0.71435546875, 'p_value': 2.9232493565143686e-24, 'bankrupt_mean': 0.047119140625, 'safe_mean': 0.050750732421875, 'bankrupt_std': 0.00366973876953125, 'safe_std': 0.005126953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-950
   Cohen's d: 0.714
   Safe mean: -0.000029, Risky mean: 0.004173
âŒ Error testing {'layer': 4, 'feature_id': 950, 'cohen_d': 0.7138671875, 'p_value': 3.2406826928185592e-24, 'bankrupt_mean': 0.00417327880859375, 'safe_mean': -2.8789043426513672e-05, 'bankrupt_std': 0.004840850830078125, 'safe_std': 0.005924224853515625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1147
   Cohen's d: -0.714
   Safe mean: -0.011276, Risky mean: -0.014214
âŒ Error testing {'layer': 4, 'feature_id': 1147, 'cohen_d': -0.7138671875, 'p_value': 3.063361023663258e-24, 'bankrupt_mean': -0.01421356201171875, 'safe_mean': -0.0112762451171875, 'bankrupt_std': 0.003444671630859375, 'safe_std': 0.0041351318359375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1907
   Cohen's d: -0.713
   Safe mean: 0.037201, Risky mean: 0.033905
âŒ Error testing {'layer': 4, 'feature_id': 1907, 'cohen_d': -0.71337890625, 'p_value': 3.62030781275396e-24, 'bankrupt_mean': 0.033905029296875, 'safe_mean': 0.037200927734375, 'bankrupt_std': 0.00530242919921875, 'safe_std': 0.0045928955078125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1713
   Cohen's d: -0.712
   Safe mean: 0.020523, Risky mean: 0.017914
âŒ Error testing {'layer': 4, 'feature_id': 1713, 'cohen_d': -0.71240234375, 'p_value': 3.715172682812381e-24, 'bankrupt_mean': 0.017913818359375, 'safe_mean': 0.0205230712890625, 'bankrupt_std': 0.003154754638671875, 'safe_std': 0.0036792755126953125}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-3271
   Cohen's d: -0.712
   Safe mean: 0.025284, Risky mean: 0.022736
âŒ Error testing {'layer': 4, 'feature_id': 3271, 'cohen_d': -0.7119140625, 'p_value': 4.370089649350991e-24, 'bankrupt_mean': 0.022735595703125, 'safe_mean': 0.0252838134765625, 'bankrupt_std': 0.00365447998046875, 'safe_std': 0.0035800933837890625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1281
   Cohen's d: 0.711
   Safe mean: -0.032532, Risky mean: -0.029999
âŒ Error testing {'layer': 4, 'feature_id': 1281, 'cohen_d': 0.7109375, 'p_value': 4.53430669039955e-24, 'bankrupt_mean': -0.029998779296875, 'safe_mean': -0.03253173828125, 'bankrupt_std': 0.0032749176025390625, 'safe_std': 0.003570556640625}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-2680
   Cohen's d: -0.711
   Safe mean: -0.023376, Risky mean: -0.025711
âŒ Error testing {'layer': 4, 'feature_id': 2680, 'cohen_d': -0.7109375, 'p_value': 5.318702799732555e-24, 'bankrupt_mean': -0.0257110595703125, 'safe_mean': -0.02337646484375, 'bankrupt_std': 0.0031261444091796875, 'safe_std': 0.0032939910888671875}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.


ðŸ§ª Testing L4-1983
   Cohen's d: 0.710
   Safe mean: -0.041962, Risky mean: -0.038605
âŒ Error testing {'layer': 4, 'feature_id': 1983, 'cohen_d': 0.71044921875, 'p_value': 5.125894095541043e-24, 'bankrupt_mean': -0.038604736328125, 'safe_mean': -0.041961669921875, 'bankrupt_std': 0.004093170166015625, 'safe_std': 0.0047454833984375}: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

ðŸ’¾ Checkpoint saved: /data/llm_addiction/experiment_2_multilayer_patching/checkpoint_L3_4_gpu4_L3_4_20251013_144331.json

================================================================================
ðŸ“Š FINAL SUMMARY
================================================================================
Total features tested: 0
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 557, in <module>
    exp.run()
  File "/home/ubuntu/llm_addiction/experiment_2_multilayer_patching_L1_31/experiment_2_L1_31_top300.py", line 531, in run
    print(f"Causal features: {len(causal_features)} ({len(causal_features)/len(all_results)*100:.1f}%)")
                                                      ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~
ZeroDivisionError: division by zero
