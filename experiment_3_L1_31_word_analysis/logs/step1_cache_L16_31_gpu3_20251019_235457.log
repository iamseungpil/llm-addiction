/data/miniforge3/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
ðŸŽ¯ Caching hidden states for layers 16-31
================================================================================
EXPERIMENT 3 STEP 1: HIDDEN STATE CACHING
================================================================================
ðŸš€ Loading LLaMA model...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:02<00:06,  2.09s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.73s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:05<00:01,  1.69s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.53s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:06<00:00,  1.62s/it]
âœ… LLaMA loaded
ðŸ“‚ Loading Exp1 data (6,400 games)...
âœ… Loaded 6400 responses

================================================================================
EXTRACTING HIDDEN STATES
================================================================================
Processing batches:   0%|          | 0/200 [00:00<?, ?it/s]Processing batches:   0%|          | 0/200 [00:07<?, ?it/s]
Traceback (most recent call last):
  File "/home/ubuntu/llm_addiction/experiment_3_L1_31_word_analysis/step1_cache_hidden_states.py", line 213, in <module>
    cache.run()
  File "/home/ubuntu/llm_addiction/experiment_3_L1_31_word_analysis/step1_cache_hidden_states.py", line 191, in run
    self.extract_and_cache(responses, batch_size=32)
  File "/home/ubuntu/llm_addiction/experiment_3_L1_31_word_analysis/step1_cache_hidden_states.py", line 141, in extract_and_cache
    layer_hidden = hidden_states[layer][i, -1, :].cpu().numpy()
TypeError: Got unsupported ScalarType BFloat16
