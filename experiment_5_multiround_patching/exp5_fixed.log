/data/miniforge3/lib/python3.10/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(

A module that was compiled using NumPy 1.x cannot be run in
NumPy 2.2.6 as it may crash. To support both 1.x and 2.x
versions of NumPy, modules must be compiled with NumPy 2.0.
Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.

If you are a user of the module, the easiest solution will be to
downgrade to 'numpy<2' or try to upgrade the affected module.
We expect that some modules will need time to support NumPy 2.

Traceback (most recent call last):  File "/home/ubuntu/llm_addiction/experiment_5_multiround_patching/multiround_patching.py", line 341, in <module>
    main()
  File "/home/ubuntu/llm_addiction/experiment_5_multiround_patching/multiround_patching.py", line 337, in main
    experiment = MultiRoundPatchingExperiment()
  File "/home/ubuntu/llm_addiction/experiment_5_multiround_patching/multiround_patching.py", line 36, in __init__
    self.model = AutoModelForCausalLM.from_pretrained(
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 597, in from_pretrained
    model_class = _get_model_class(config, cls._model_mapping)
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 394, in _get_model_class
    supported_models = model_mapping[type(config)]
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 803, in __getitem__
    return self._load_attr_from_module(model_type, model_name)
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 817, in _load_attr_from_module
    return getattribute_from_module(self._modules[module_name], attr)
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 729, in getattribute_from_module
    if hasattr(module, attr):
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 2292, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 2320, in _get_module
    return importlib.import_module("." + module_name, self.__name__)
  File "/data/miniforge3/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 30, in <module>
    from ...modeling_layers import (
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/modeling_layers.py", line 29, in <module>
    from .processing_utils import Unpack
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/processing_utils.py", line 41, in <module>
    from .video_utils import VideoMetadata, load_video
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/video_utils.py", line 28, in <module>
    from .image_transforms import PaddingMode, to_channel_dimension_format
  File "/data/miniforge3/lib/python3.10/site-packages/transformers/image_transforms.py", line 51, in <module>
    import jax.numpy as jnp
  File "/data/miniforge3/lib/python3.10/site-packages/jax/__init__.py", line 37, in <module>
    import jax.core as _core
  File "/data/miniforge3/lib/python3.10/site-packages/jax/core.py", line 18, in <module>
    from jax._src.core import (
  File "/data/miniforge3/lib/python3.10/site-packages/jax/_src/core.py", line 38, in <module>
    from jax._src import dtypes
  File "/data/miniforge3/lib/python3.10/site-packages/jax/_src/dtypes.py", line 33, in <module>
    from jax._src import config
  File "/data/miniforge3/lib/python3.10/site-packages/jax/_src/config.py", line 27, in <module>
    from jax._src import lib
  File "/data/miniforge3/lib/python3.10/site-packages/jax/_src/lib/__init__.py", line 87, in <module>
    import jaxlib.xla_client as xla_client
  File "/data/miniforge3/lib/python3.10/site-packages/jaxlib/xla_client.py", line 32, in <module>
    from . import xla_extension as _xla
AttributeError: _ARRAY_API not found
Loading LLaMA model...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:04,  1.46s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.46s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.50s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.04s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.20s/it]
âœ… LLaMA model loaded
Loading SAE for layer 25...
ðŸ”§ Loading config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L25R-8x/hyperparams.json
âœ… Loading WORKING SAE for Layer 25
   Config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L25R-8x/hyperparams.json
   Dataset norm: 31.625
   Norm factor: 2.023715
   Using ReLU instead of JumpReLU (threshold=0.0)
ðŸ”§ Loading checkpoint: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L25R-8x/checkpoints/final.safetensors
   File size: 512.1 MB
ðŸ”§ Initializing SAE model...
ðŸ”§ Loading checkpoint weights (CPU)...
âœ… Loaded safetensors file
ðŸ”§ Processing checkpoint weights...
   Loading W_E (encoder.weight)... âœ… (torch.Size([4096, 32768]))
   Loading b_E (encoder.bias)... âœ… (torch.Size([32768]))
   Loading W_D (decoder.weight)... âœ… (torch.Size([32768, 4096]))
   Loading b_D (decoder.bias)... âœ… (torch.Size([4096]))
ðŸ”§ Clearing checkpoint from memory...
ðŸ”§ Loading state dict to model...
ðŸ”§ Moving model to cuda:0...
âœ… OPTIMIZED SAE loaded successfully!
   Layer: 25
   Expected reconstruction error: ~47%
   Feature clamping: VERIFIED WORKING
   Memory optimizations: ENABLED
Loading SAE for layer 26...
ðŸ”§ Loading config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L26R-8x/hyperparams.json
âœ… Loading WORKING SAE for Layer 26
   Config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L26R-8x/hyperparams.json
   Dataset norm: 35.25
   Norm factor: 1.815603
   Using ReLU instead of JumpReLU (threshold=0.0)
ðŸ”§ Loading checkpoint: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L26R-8x/checkpoints/final.safetensors
   File size: 512.1 MB
ðŸ”§ Initializing SAE model...
ðŸ”§ Loading checkpoint weights (CPU)...
âœ… Loaded safetensors file
ðŸ”§ Processing checkpoint weights...
   Loading W_E (encoder.weight)... âœ… (torch.Size([4096, 32768]))
   Loading b_E (encoder.bias)... âœ… (torch.Size([32768]))
   Loading W_D (decoder.weight)... âœ… (torch.Size([32768, 4096]))
   Loading b_D (decoder.bias)... âœ… (torch.Size([4096]))
ðŸ”§ Clearing checkpoint from memory...
ðŸ”§ Loading state dict to model...
ðŸ”§ Moving model to cuda:0...
âœ… OPTIMIZED SAE loaded successfully!
   Layer: 26
   Expected reconstruction error: ~47%
   Feature clamping: VERIFIED WORKING
   Memory optimizations: ENABLED
Loading SAE for layer 27...
ðŸ”§ Loading config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L27R-8x/hyperparams.json
âœ… Loading WORKING SAE for Layer 27
   Config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L27R-8x/hyperparams.json
   Dataset norm: 38.25
   Norm factor: 1.673203
   Using ReLU instead of JumpReLU (threshold=0.0)
ðŸ”§ Loading checkpoint: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L27R-8x/checkpoints/final.safetensors
   File size: 512.1 MB
ðŸ”§ Initializing SAE model...
ðŸ”§ Loading checkpoint weights (CPU)...
âœ… Loaded safetensors file
ðŸ”§ Processing checkpoint weights...
   Loading W_E (encoder.weight)... âœ… (torch.Size([4096, 32768]))
   Loading b_E (encoder.bias)... âœ… (torch.Size([32768]))
   Loading W_D (decoder.weight)... âœ… (torch.Size([32768, 4096]))
   Loading b_D (decoder.bias)... âœ… (torch.Size([4096]))
ðŸ”§ Clearing checkpoint from memory...
ðŸ”§ Loading state dict to model...
ðŸ”§ Moving model to cuda:0...
âœ… OPTIMIZED SAE loaded successfully!
   Layer: 27
   Expected reconstruction error: ~47%
   Feature clamping: VERIFIED WORKING
   Memory optimizations: ENABLED
Loading SAE for layer 28...
ðŸ”§ Loading config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L28R-8x/hyperparams.json
âœ… Loading WORKING SAE for Layer 28
   Config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L28R-8x/hyperparams.json
   Dataset norm: 42.5
   Norm factor: 1.505882
   Using ReLU instead of JumpReLU (threshold=0.0)
ðŸ”§ Loading checkpoint: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L28R-8x/checkpoints/final.safetensors
   File size: 512.1 MB
ðŸ”§ Initializing SAE model...
ðŸ”§ Loading checkpoint weights (CPU)...
âœ… Loaded safetensors file
ðŸ”§ Processing checkpoint weights...
   Loading W_E (encoder.weight)... âœ… (torch.Size([4096, 32768]))
   Loading b_E (encoder.bias)... âœ… (torch.Size([32768]))
   Loading W_D (decoder.weight)... âœ… (torch.Size([32768, 4096]))
   Loading b_D (decoder.bias)... âœ… (torch.Size([4096]))
ðŸ”§ Clearing checkpoint from memory...
ðŸ”§ Loading state dict to model...
ðŸ”§ Moving model to cuda:0...
âœ… OPTIMIZED SAE loaded successfully!
   Layer: 28
   Expected reconstruction error: ~47%
   Feature clamping: VERIFIED WORKING
   Memory optimizations: ENABLED
Loading SAE for layer 29...
ðŸ”§ Loading config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L29R-8x/hyperparams.json
âœ… Loading WORKING SAE for Layer 29
   Config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L29R-8x/hyperparams.json
   Dataset norm: 46.5
   Norm factor: 1.376344
   Using ReLU instead of JumpReLU (threshold=0.0)
ðŸ”§ Loading checkpoint: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L29R-8x/checkpoints/final.safetensors
   File size: 512.1 MB
ðŸ”§ Initializing SAE model...
ðŸ”§ Loading checkpoint weights (CPU)...
âœ… Loaded safetensors file
ðŸ”§ Processing checkpoint weights...
   Loading W_E (encoder.weight)... âœ… (torch.Size([4096, 32768]))
   Loading b_E (encoder.bias)... âœ… (torch.Size([32768]))
   Loading W_D (decoder.weight)... âœ… (torch.Size([32768, 4096]))
   Loading b_D (decoder.bias)... âœ… (torch.Size([4096]))
ðŸ”§ Clearing checkpoint from memory...
ðŸ”§ Loading state dict to model...
ðŸ”§ Moving model to cuda:0...
âœ… OPTIMIZED SAE loaded successfully!
   Layer: 29
   Expected reconstruction error: ~47%
   Feature clamping: VERIFIED WORKING
   Memory optimizations: ENABLED
Loading SAE for layer 30...
ðŸ”§ Loading config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L30R-8x/hyperparams.json
âœ… Loading WORKING SAE for Layer 30
   Config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L30R-8x/hyperparams.json
   Dataset norm: 53.25
   Norm factor: 1.201878
   Using ReLU instead of JumpReLU (threshold=0.0)
ðŸ”§ Loading checkpoint: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L30R-8x/checkpoints/final_fixed.pth
   File size: 512.1 MB
ðŸ”§ Initializing SAE model...
ðŸ”§ Loading checkpoint weights (CPU)...
âœ… Loaded PyTorch file
ðŸ”§ Processing checkpoint weights...
   Loading W_E (W_E)... âœ… (torch.Size([4096, 32768]))
   Loading b_E (b_E)... âœ… (torch.Size([32768]))
   Loading W_D (W_D)... âœ… (torch.Size([32768, 4096]))
   Loading b_D (b_D)... âœ… (torch.Size([4096]))
ðŸ”§ Clearing checkpoint from memory...
ðŸ”§ Loading state dict to model...
ðŸ”§ Moving model to cuda:0...
âœ… OPTIMIZED SAE loaded successfully!
   Layer: 30
   Expected reconstruction error: ~47%
   Feature clamping: VERIFIED WORKING
   Memory optimizations: ENABLED
Loading SAE for layer 31...
ðŸ”§ Loading config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L31R-8x/hyperparams.json
âœ… Loading WORKING SAE for Layer 31
   Config: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L31R-8x/hyperparams.json
   Dataset norm: 74.5
   Norm factor: 0.859060
   Using ReLU instead of JumpReLU (threshold=0.0)
ðŸ”§ Loading checkpoint: /data/.cache/huggingface/hub/models--fnlp--Llama3_1-8B-Base-LXR-8x/snapshots/8dbc1d85edfced43081c03c38b05514dbab1368b/Llama3_1-8B-Base-L31R-8x/checkpoints/final.safetensors
   File size: 512.1 MB
ðŸ”§ Initializing SAE model...
ðŸ”§ Loading checkpoint weights (CPU)...
âœ… Loaded safetensors file
ðŸ”§ Processing checkpoint weights...
   Loading W_E (encoder.weight)... âœ… (torch.Size([4096, 32768]))
   Loading b_E (encoder.bias)... âœ… (torch.Size([32768]))
   Loading W_D (decoder.weight)... âœ… (torch.Size([32768, 4096]))
   Loading b_D (decoder.bias)... âœ… (torch.Size([4096]))
ðŸ”§ Clearing checkpoint from memory...
ðŸ”§ Loading state dict to model...
ðŸ”§ Moving model to cuda:0...
âœ… OPTIMIZED SAE loaded successfully!
   Layer: 31
   Expected reconstruction error: ~47%
   Feature clamping: VERIFIED WORKING
   Memory optimizations: ENABLED
ðŸš€ Experiment 5: Multi-Round Persistent Patching
================================================================================
Loading causal features and population means...
Loaded 178 causal features with population means
Testing features:   0%|          | 0/178 [00:00<?, ?it/s]Testing features:   1%|          | 1/178 [09:51<29:04:49, 591.47s/it]Testing features:   1%|          | 2/178 [18:36<27:00:15, 552.36s/it]Testing features:   2%|â–         | 3/178 [28:06<27:15:14, 560.65s/it]Testing features:   2%|â–         | 4/178 [36:56<26:30:30, 548.45s/it]Testing features:   3%|â–Ž         | 5/178 [45:50<26:06:17, 543.22s/it]