# Pathway Analysis ì›ë¦¬ ë° ì‹¤í—˜ ì„¤ê³„

## ðŸ“š Pathway Analysisëž€?

**Pathway Analysis**ëŠ” LLMì˜ ì—¬ëŸ¬ layerì— ê±¸ì³ ì •ë³´ê°€ ì–´ë–»ê²Œ ì „ë‹¬ë˜ê³  ë³€í™˜ë˜ëŠ”ì§€ë¥¼ ì¶”ì í•˜ëŠ” ë¶„ì„ ë°©ë²•ìž…ë‹ˆë‹¤.

---

## ðŸ”¬ ê¸°ë³¸ ì›ë¦¬

### 1. Feature Correlationì„ í†µí•œ ê°„ì ‘ ì¶”ë¡ 

**í•µì‹¬ ì•„ì´ë””ì–´**:
- ë§Œì•½ L8ì˜ feature Aê°€ L31ì˜ feature Bì™€ **ê°•í•œ ìƒê´€ê´€ê³„**ë¥¼ ë³´ì¸ë‹¤ë©´
- L8ì˜ feature A ì •ë³´ê°€ L31ì˜ feature Bë¡œ **ì „ë‹¬ë˜ì—ˆì„ ê°€ëŠ¥ì„±**ì´ ìžˆìŒ

**ë°©ë²•**:
```python
# ë™ì¼í•œ ê²Œìž„ë“¤ì— ëŒ€í•´
l8_features = [game1_l8, game2_l8, ..., gameN_l8]  # (N games,)
l31_features = [game1_l31, game2_l31, ..., gameN_l31]  # (N games,)

# Pearson correlation
r, p_value = stats.pearsonr(l8_features, l31_features)

if r > 0.6 and p_value < 0.01:
    print("Strong pathway: L8 â†’ L31")
```

**í•œê³„**:
- âŒ **Correlation â‰  Causation**: ì¸ê³¼ê´€ê³„ëŠ” ê²€ì¦ ë¶ˆê°€
- âŒ **ê°„ì ‘ ê²½ë¡œ êµ¬ë¶„ ë¶ˆê°€**: L8 â†’ L31ì´ ì§ì ‘ì¸ì§€, L8 â†’ L10 â†’ L31ì¸ì§€ ëª¨ë¦„
- âŒ **ê³µí†µ ì›ì¸ ê°€ëŠ¥ì„±**: ë‘˜ ë‹¤ ìž…ë ¥ì— ë°˜ì‘í•˜ëŠ” ê²ƒì¼ ìˆ˜ ìžˆìŒ

---

### 2. Multi-hop Pathway Tracing

**3-layer pathway ë°œê²¬ ë°©ë²•**:

```python
# ê°€ì„¤: L8 â†’ L10 â†’ L31 ê²½ë¡œê°€ ì¡´ìž¬
for l8_feat in important_l8_features:
    for l10_feat in important_l10_features:
        for l31_feat in important_l31_features:

            r_8_10 = correlation(l8_feat, l10_feat)
            r_10_31 = correlation(l10_feat, l31_feat)
            r_8_31 = correlation(l8_feat, l31_feat)

            # ê²½ë¡œ ì¡´ìž¬ ì¡°ê±´
            if (r_8_10 > 0.6 and r_10_31 > 0.6 and r_8_31 > 0.5):
                print(f"Pathway: {l8_feat} â†’ {l10_feat} â†’ {l31_feat}")
                print(f"  L8â†’L10: r={r_8_10:.2f}")
                print(f"  L10â†’L31: r={r_10_31:.2f}")
                print(f"  L8â†’L31: r={r_8_31:.2f} (direct)")
```

**í•´ì„**:
- `r_8_10`ê³¼ `r_10_31`ì´ ëª¨ë‘ ë†’ìŒ â†’ L10ì´ **ì¤‘ê°„ ë§¤ê°œì²´** ì—­í• 
- `r_8_31`ë„ ë†’ìŒ â†’ **ì •ë³´ ë³´ì¡´** (L10ì„ ê±°ì³ë„ ì •ë³´ ì†ì‹¤ ì ìŒ)

---

### 3. Anthropic 2025 ë°©ë²•ë¡ ê³¼ì˜ ì°¨ì´

#### Anthropic Attribution Graphs (Causal)
```python
# Anthropic ë°©ë²• (2025)
# Token-level causal intervention

def find_token_attribution(model, prompt, output_token):
    """ê° input tokenì´ outputì— ì–¼ë§ˆë‚˜ ê¸°ì—¬í•˜ëŠ”ì§€ ì¸¡ì •"""

    attributions = []
    for token_pos in range(len(prompt)):
        # íŠ¹ì • tokenì˜ featureë¥¼ ablate
        ablated_output = model.forward_with_ablation(
            prompt,
            ablate_position=token_pos
        )

        # Output ë³€í™” ì¸¡ì •
        delta = original_output - ablated_output
        attributions.append(delta)

    return attributions  # Token-level causal attribution
```

**Anthropicì´ í•  ìˆ˜ ìžˆëŠ” ê²ƒ**:
- âœ… Token-level precision: "$100" í† í°ì´ "bet" ê²°ì •ì— ì–¼ë§ˆë‚˜ ê¸°ì—¬
- âœ… Causal validation: Ablationìœ¼ë¡œ ì¸ê³¼ì„± ê²€ì¦
- âœ… Attention flow: ì–´ëŠ í† í°ì´ ì–´ëŠ í† í°ì— attend
- âœ… Cross-Layer Transcoders: MLPë¥¼ interpretable featuresë¡œ ë¶„í•´

#### ìš°ë¦¬ì˜ Correlation ë°©ë²• (í˜„ìž¬)
```python
# ìš°ë¦¬ ë°©ë²• (last token featuresë§Œ)
# Statistical correlation

def find_layer_correlation(l8_activations, l31_activations):
    """Layer ê°„ feature correlation"""

    correlations = []
    for l8_feat in l8_activations:
        for l31_feat in l31_activations:
            r, p = stats.pearsonr(l8_feat, l31_feat)

            if r > 0.6 and p < 0.01:
                correlations.append({
                    'l8': l8_feat.name,
                    'l31': l31_feat.name,
                    'r': r,
                    'p': p
                })

    return correlations  # Layer-level correlation
```

**ìš°ë¦¬ê°€ í•  ìˆ˜ ìžˆëŠ” ê²ƒ**:
- âœ… Layer-level correlation: L8 featureê°€ L31 featureì™€ ì—°ê²°
- âŒ Token-level precision: ì–´ëŠ í† í° ë•Œë¬¸ì¸ì§€ ëª¨ë¦„
- âŒ Causal validation: Correlationë§Œ ìžˆê³  causation ì—†ìŒ
- âŒ Attention flow: Attention pattern ì—†ìŒ

---

## ðŸŽ¯ í˜„ìž¬ ìƒí™© ë¶„ì„

### Experiment 2 (Patching) ë°ì´í„°

**ì €ìž¥ëœ ì •ë³´**:
```json
{
  "feature": "L11-1829",
  "condition": "safe_baseline",
  "trial": 0,
  "response": "1\nCurrent balance: $150\n...",
  "parsed": {
    "action": "bet",
    "bet": 10,
    "valid": true
  }
}
```

**ì—†ëŠ” ì •ë³´**:
- âŒ Prompt (ìž¬êµ¬ì„± ê°€ëŠ¥í•˜ê¸´ í•¨)
- âŒ Hidden states (layerë³„ activation)
- âŒ SAE features (ëª¨ë“  32,768ê°œ features)
- âŒ Attention patterns

**ê²°ë¡ **:
- âŒ **Pathway tracking ë¶ˆê°€ëŠ¥** (hidden states ì—†ìŒ)
- âœ… **BUT**: ìƒˆë¡œìš´ ì‹¤í—˜ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ê°€ëŠ¥

---

## ðŸ’¡ ìƒˆë¡œìš´ Pathway Tracking ì‹¤í—˜ ì„¤ê³„

### ëª©í‘œ
**2,787ê°œ causal featuresì˜ layer ê°„ ì •ë³´ íë¦„ ì¶”ì **

### ì‹¤í—˜ ì„¤ê³„

#### Phase 1: Feature Extraction (ë°ì´í„° ìˆ˜ì§‘)

```python
class PathwayTrackingExperiment:
    """
    ëª©í‘œ: 2,787ê°œ featuresì˜ ëª¨ë“  layer activations ì¶”ì¶œ
    """

    def __init__(self):
        self.target_features = load_2787_features()
        # Safe: 640, Risky: 2147

        # 6 conditions (Experiment 2ì™€ ë™ì¼)
        self.conditions = [
            'safe_baseline',
            'safe_with_safe_patch',
            'safe_with_risky_patch',
            'risky_baseline',
            'risky_with_safe_patch',
            'risky_with_risky_patch',
        ]

        # ìž‘ì€ ìƒ˜í”Œë¡œ ì‹œìž‘ (ê³„ì‚°ëŸ‰ ê³ ë ¤)
        self.n_trials_per_condition = 30

    def extract_all_layer_features(self, prompt, target_features):
        """
        ëª¨ë“  layerì˜ feature activations ì¶”ì¶œ

        Returns:
            {
                'L1': {feat_id: activation},
                'L2': {feat_id: activation},
                ...
                'L31': {feat_id: activation}
            }
        """

        # 1. LLaMA forward pass
        with torch.no_grad():
            outputs = self.model(
                prompt,
                output_hidden_states=True
            )

        # 2. ê° layerì˜ hidden states â†’ SAE features
        all_layer_features = {}

        for layer in range(1, 32):
            hidden = outputs.hidden_states[layer][:, -1, :]  # Last token

            # SAE encode
            sae = self.load_sae(layer)
            features = sae.encode(hidden)  # (32768,)

            # í•´ë‹¹ layerì˜ target featuresë§Œ ì €ìž¥
            layer_target_feats = [
                f for f in target_features
                if f['layer'] == layer
            ]

            all_layer_features[f'L{layer}'] = {
                feat['feature_id']: features[feat['feature_id']].item()
                for feat in layer_target_feats
            }

        return all_layer_features

    def run_experiment(self):
        """
        ì‹¤í—˜ ì‹¤í–‰
        """
        results = []

        for condition in self.conditions:
            for trial in range(self.n_trials_per_condition):
                # Prompt ìƒì„±
                if 'safe' in condition:
                    prompt = self.safe_prompt
                else:
                    prompt = self.risky_prompt

                # Patching ì ìš© (í•„ìš”ì‹œ)
                if 'patch' in condition:
                    prompt = self.apply_patching(prompt, condition)

                # ëª¨ë“  layer features ì¶”ì¶œ
                all_features = self.extract_all_layer_features(
                    prompt,
                    self.target_features
                )

                # Response ìƒì„±
                response = self.generate_response(prompt)

                # ì €ìž¥
                results.append({
                    'condition': condition,
                    'trial': trial,
                    'all_layer_features': all_features,
                    'response': response,
                    'parsed': self.parse_response(response)
                })

        return results
```

**ì €ìž¥ í˜•ì‹**:
```json
{
  "condition": "safe_baseline",
  "trial": 0,
  "all_layer_features": {
    "L1": {
      "1292": 0.0234,
      "1301": 0.0156,
      ...
    },
    "L2": {
      "2035": 0.0412,
      ...
    },
    ...
    "L31": {
      "10692": 0.7612,
      ...
    }
  },
  "response": "1\nCurrent balance: $150\n...",
  "parsed": {
    "action": "bet",
    "bet": 10
  }
}
```

#### Phase 2: Pathway Analysis (ë¶„ì„)

```python
def analyze_pathways(results):
    """
    2,787ê°œ featuresì˜ layer ê°„ correlation ë¶„ì„
    """

    # 1. Conditionë³„ë¡œ grouping
    safe_baseline = [r for r in results if r['condition'] == 'safe_baseline']

    # 2. Feature activation matrix êµ¬ì„±
    # Shape: (n_trials, n_features_per_layer)

    feature_matrices = {}
    for layer in range(1, 32):
        layer_name = f'L{layer}'

        # ëª¨ë“  trialì˜ í•´ë‹¹ layer features ì¶”ì¶œ
        layer_matrix = []
        for trial_data in safe_baseline:
            layer_feats = trial_data['all_layer_features'][layer_name]
            layer_matrix.append(list(layer_feats.values()))

        feature_matrices[layer_name] = np.array(layer_matrix)
        # Shape: (30 trials, n_features_in_this_layer)

    # 3. Cross-layer correlation
    pathways = []

    for source_layer in range(1, 31):  # L1-L30
        for target_layer in range(source_layer + 1, 32):  # L2-L31

            source_name = f'L{source_layer}'
            target_name = f'L{target_layer}'

            source_matrix = feature_matrices[source_name]  # (30, n_src)
            target_matrix = feature_matrices[target_name]  # (30, n_tgt)

            # ê° source feature Ã— target feature correlation
            for src_idx in range(source_matrix.shape[1]):
                for tgt_idx in range(target_matrix.shape[1]):

                    r, p = stats.pearsonr(
                        source_matrix[:, src_idx],
                        target_matrix[:, tgt_idx]
                    )

                    if abs(r) > 0.6 and p < 0.01:
                        pathways.append({
                            'source': f'{source_name}-{src_idx}',
                            'target': f'{target_name}-{tgt_idx}',
                            'correlation': r,
                            'p_value': p
                        })

    return pathways
```

#### Phase 3: Multi-hop Pathway Discovery

```python
def find_multihop_pathways(pathways):
    """
    3-layer pathways ë°œê²¬: L_i â†’ L_j â†’ L_k
    """

    multi_hop = []

    # Pathwayë¥¼ graphë¡œ ë³€í™˜
    graph = defaultdict(list)
    for p in pathways:
        graph[p['source']].append(p['target'])

    # 3-hop paths ì°¾ê¸°
    for l1_feat in graph.keys():
        l1_layer = int(l1_feat.split('-')[0][1:])

        for l2_feat in graph[l1_feat]:
            l2_layer = int(l2_feat.split('-')[0][1:])

            for l3_feat in graph[l2_feat]:
                l3_layer = int(l3_feat.split('-')[0][1:])

                # Layer ìˆœì„œ í™•ì¸
                if l1_layer < l2_layer < l3_layer:

                    # Direct pathë„ í™•ì¸
                    direct_corr = get_correlation(l1_feat, l3_feat, pathways)

                    multi_hop.append({
                        'path': f'{l1_feat} â†’ {l2_feat} â†’ {l3_feat}',
                        'layers': f'L{l1_layer} â†’ L{l2_layer} â†’ L{l3_layer}',
                        'hop1_corr': get_correlation(l1_feat, l2_feat, pathways),
                        'hop2_corr': get_correlation(l2_feat, l3_feat, pathways),
                        'direct_corr': direct_corr
                    })

    return multi_hop
```

---

## ðŸ“Š ì˜ˆìƒ ê²°ê³¼

### 1. Safe Feature Pathways
```
Early layers (L1-L4) â†’ Late layers (L25-L29)

L1-1292 (safe) â†’ L24-1111 (safe) â†’ L29-??? (safe)
  L1â†’L24: r = 0.72
  L24â†’L29: r = 0.68
  Direct L1â†’L29: r = 0.55
```

### 2. Risky Feature Pathways
```
Middle layers (L9-L17) â†’ Late layers (L30)

L9-??? (risky) â†’ L17-??? (risky) â†’ L30-??? (risky)
  L9â†’L17: r = 0.81
  L17â†’L30: r = 0.75
  Direct L9â†’L30: r = 0.63
```

### 3. Cross-type Inhibition
```
Safe features â†’ Risky features (negative correlation)

L1-1292 (safe) â†’ L9-??? (risky): r = -0.78 (ì–µì œ)
L24-1111 (safe) â†’ L30-??? (risky): r = -0.82 (ì–µì œ)
```

---

## ðŸ’» êµ¬í˜„ ê³„íš

### ê³„ì‚°ëŸ‰ ì¶”ì •

**ë°ì´í„° ìˆ˜ì§‘**:
- 6 conditions Ã— 30 trials = 180 trials
- 31 layers Ã— 2,787 features (í‰ê·  ~90 per layer)
- ì €ìž¥ ê³µê°„: ~180 trials Ã— 31 layers Ã— 90 features Ã— 8 bytes â‰ˆ **4MB**

**Correlation ê³„ì‚°**:
- 2,787 features Ã— 2,787 features â‰ˆ 7.7M pairs
- Cross-layerë§Œ: ~1M pairs (manageable)

**ì˜ˆìƒ ì‹œê°„**:
- Feature extraction: ~180 trials Ã— 2ì´ˆ/trial = **6ë¶„**
- Correlation analysis: ~1M pairs Ã— 0.0001ì´ˆ = **2ë¶„**
- **Total: ~10ë¶„** (feasible!)

### ì‹¤í—˜ ì‹¤í–‰

```bash
# 1. ìƒˆ ì‹¤í—˜ ì½”ë“œ ìž‘ì„±
/home/ubuntu/llm_addiction/experiment_3_pathway_tracking/
â”œâ”€â”€ pathway_tracking_experiment.py
â””â”€â”€ pathway_analysis.py

# 2. ì‹¤í—˜ ì‹¤í–‰ (GPU í•„ìš”)
python pathway_tracking_experiment.py --gpu 4

# 3. ë¶„ì„
python pathway_analysis.py
```

---

## ðŸŽ¯ í•µì‹¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€

### Q1: Patching ì‹¤í—˜ ë°ì´í„°ë¡œ pathway tracking ê°€ëŠ¥?
**A**: âŒ **ë¶ˆê°€ëŠ¥** (hidden states ì €ìž¥ ì•ˆ ë¨)

### Q2: ìƒˆë¡œìš´ ì‹¤í—˜ êµ¬ì„± ê°€ëŠ¥?
**A**: âœ… **ê°€ëŠ¥** (10ë¶„ ë‚´ ì™„ë£Œ ê°€ëŠ¥)

### Q3: LlamaScope ì‚¬ìš© ê°€ëŠ¥?
**A**: âœ… **ì‚¬ìš© ê°€ëŠ¥** (ëª¨ë“  layer SAE ë¡œë“œ)

### Q4: Pathway ë¶„ì„ ì›ë¦¬?
**A**: **Feature correlation across layers**
- Layer iì˜ feature Aì™€ Layer jì˜ feature Bì˜ ìƒê´€ê´€ê³„ ì¸¡ì •
- ë†’ì€ ìƒê´€ê´€ê³„ = ì •ë³´ ì „ë‹¬ ê°€ëŠ¥ì„± (ê°„ì ‘ ì¦ê±°)
- í•œê³„: Correlation â‰  Causation

---

## ðŸ“š ì°¸ê³ ë¬¸í—Œ

1. **Anthropic (2025)**: "Attribution Graphs for Computational Pathways"
   - Token-level causal attribution
   - Cross-Layer Transcoders (CLTs)

2. **Experiment 1 Layer Pathway Analysis** (ìš°ë¦¬)
   - `/home/ubuntu/llm_addiction/experiment_1_layer_pathway_L1_31/`
   - L8 â†’ L10 â†’ L31 pathway ë°œê²¬ (correlation-based)

3. **Pearson Correlation**
   - Statistical measure of linear relationship
   - r > 0.6: strong positive correlation
   - p < 0.01: statistically significant

---

**Date**: 2025-10-22
**Author**: Analysis Documentation
**Purpose**: Pathway Analysis ì›ë¦¬ ì„¤ëª… ë° ìƒˆ ì‹¤í—˜ ì„¤ê³„ ì œì•ˆ
