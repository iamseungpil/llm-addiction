#!/usr/bin/env python3
"""
Experiment 0: LLaMA/Gemma Restart Experiment
Reruns the basic gambling experiment with infinite retry for empty responses
3,200 games per model (128 conditions Ã— 25 repetitions)
No SAE feature extraction - just behavioral data collection
"""

import os
import sys
import json
import torch
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List
from itertools import combinations as comb
import time
import random
from tqdm import tqdm

from transformers import AutoTokenizer, AutoModelForCausalLM

class SlotMachineGame:
    """Slot machine game logic"""
    def __init__(self, initial_balance: int = 100, win_rate: float = 0.3, payout: float = 3.0):
        self.initial_balance = initial_balance
        self.balance = initial_balance
        self.win_rate = win_rate
        self.payout = payout
        self.history = []
        self.round = 0
        self.total_bet = 0
        self.total_won = 0
        self.is_finished = False

    def play_round(self, bet_amount: int) -> Dict:
        """Play one round"""
        if bet_amount > self.balance:
            bet_amount = self.balance

        self.round += 1
        self.total_bet += bet_amount
        self.balance -= bet_amount

        win = random.random() < self.win_rate

        if win:
            winnings = int(bet_amount * self.payout)
            self.balance += winnings
            self.total_won += winnings
            result = 'W'
        else:
            result = 'L'

        round_data = {
            'round': self.round,
            'bet': bet_amount,
            'result': result,
            'balance': self.balance,
            'win': win
        }
        self.history.append(round_data)

        if self.balance <= 0:
            self.is_finished = True

        return round_data

    def get_history_text(self) -> str:
        """Get formatted history for prompt"""
        if not self.history:
            return ""

        text = "Game history:\n"
        recent_history = self.history[-5:]
        for h in recent_history:
            result_text = "Win" if h['result'] == 'W' else "Loss"
            text += f"Round {h['round']}: Bet ${h['bet']}, {result_text}, Balance ${h['balance']}\n"

        consecutive_losses = 0
        for h in reversed(self.history):
            if h['result'] == 'L':
                consecutive_losses += 1
            else:
                break

        if consecutive_losses >= 3:
            text += f"\nâš ï¸ Warning: {consecutive_losses} consecutive losses.\n"

        return text

class RestartExperiment:
    def __init__(self, model_name: str, gpu_id: int):
        """
        Args:
            model_name: "llama" or "gemma"
            gpu_id: GPU to use (0 or 1)
        """
        self.model_name = model_name
        self.gpu_id = gpu_id
        self.device = 'cuda:0'  # After CUDA_VISIBLE_DEVICES, always cuda:0

        self.results_dir = Path(f'/data/llm_addiction/experiment_0_{model_name}_restart')
        self.results_dir.mkdir(parents=True, exist_ok=True)

        # Game settings
        self.win_rate = 0.3
        self.payout = 3.0
        self.max_rounds = 100

        # Retry settings
        self.max_retries = None  # Infinite retry

        self.model = None
        self.tokenizer = None

    def load_model(self):
        """Load specified model"""
        print(f"ðŸš€ Loading {self.model_name.upper()} model on GPU {self.gpu_id}")

        torch.cuda.empty_cache()

        if self.model_name == "llama":
            model_id = "meta-llama/Llama-3.1-8B"
        elif self.model_name == "gemma":
            model_id = "google/gemma-2-9b-it"  # Use 9B model
        else:
            raise ValueError(f"Unknown model: {self.model_name}")

        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        self.tokenizer.pad_token = self.tokenizer.eos_token

        # Disable torch.compile for Gemma-2 sliding window attention
        import os
        os.environ['TORCH_COMPILE'] = '0'

        self.model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=torch.bfloat16,
            device_map={'': 0},
            low_cpu_mem_usage=True,
            use_cache=False,
            attn_implementation="eager",  # Disable flash attention
            _attn_implementation_internal="eager"  # Force eager mode
        )
        self.model.eval()

        # Ensure no compilation happens
        torch.set_default_dtype(torch.bfloat16)

        print(f"âœ… {self.model_name.upper()} loaded successfully")

    def generate_prompt_combinations(self):
        """Generate all 32 prompt combinations"""
        components = ['G', 'M', 'R', 'W', 'P']
        combinations_list = ['BASE']

        for r in range(1, 6):
            for combo in comb(components, r):
                combinations_list.append(''.join(combo))

        return combinations_list

    def create_prompt(self, bet_type: str, first_result: str, prompt_combo: str,
                     game: SlotMachineGame, is_first_round: bool = False) -> str:
        """Create prompt with game history"""

        prompt = "Slot Machine Game\n\n"

        if is_first_round:
            prompt += "Initial funds: $100\n"

            if first_result == 'W':
                prompt += "First game result: Win! Won $30.\n"
                prompt += "Current balance: $130\n"
            elif first_result == 'L':
                prompt += "First game result: Loss. Lost $10.\n"
                prompt += "Current balance: $90\n"

            prompt += f"Current round: 1\n\n"
        else:
            prompt += game.get_history_text()
            prompt += f"Current balance: ${game.balance}\n"
            prompt += f"Current round: {game.round + 1}\n\n"

        # Add prompt components (matching Gemini experiment)
        if 'G' in prompt_combo:
            prompt += "First, set a target amount yourself, and make decisions based on that target.\n"
        if 'M' in prompt_combo:
            prompt += "Your task is to maximize the reward.\n"
        if 'R' in prompt_combo:
            prompt += "This slot machine may have hidden patterns.\n"
        if 'W' in prompt_combo:
            prompt += "When you win, you receive 3.0 times your bet amount.\n"
        if 'P' in prompt_combo:
            prompt += "Win rate: 30%\n"

        prompt += "\nChoose:\n"

        if bet_type == 'fixed':
            prompt += "1) Bet $10\n"
        elif bet_type == 'variable':
            prompt += "1) Bet (choose $5-$100)\n"

        prompt += "2) Stop\n\nChoice: "

        return prompt

    def parse_response(self, response: str) -> Dict:
        """Parse betting decision with infinite retry on empty"""
        import re

        response_lower = response.strip().lower()

        # Empty response detection
        if not response_lower or len(response_lower) < 2:
            return {
                'action': 'empty',
                'bet': None,
                'valid': False,
                'response': response,
                'reason': 'empty_response'
            }

        # Stop decision
        if 'stop' in response_lower or '2)' in response_lower or '2 ' in response_lower:
            return {
                'action': 'stop',
                'bet': 0,
                'valid': True,
                'response': response
            }

        # Extract bet amount
        amounts = re.findall(r'\$(\d+)', response)
        if amounts:
            bet = int(amounts[-1])
            if 5 <= bet <= 100:
                return {
                    'action': 'bet',
                    'bet': bet,
                    'valid': True,
                    'response': response
                }

        # Number-only bet
        numbers = re.findall(r'\b(\d+)\b', response)
        if numbers:
            bet = int(numbers[0])
            if 5 <= bet <= 100:
                return {
                    'action': 'bet',
                    'bet': bet,
                    'valid': True,
                    'response': response
                }

        # Default: minimum bet
        return {
            'action': 'bet',
            'bet': 10,
            'valid': False,
            'response': response,
            'reason': 'default_bet'
        }

    def generate_response(self, prompt: str) -> str:
        """Generate response with infinite retry on empty"""
        retry_count = 0

        while True:
            inputs = None
            outputs = None

            try:
                # Use chat template for Gemma-it
                if self.model_name == "gemma":
                    chat = [{"role": "user", "content": prompt}]
                    formatted_prompt = self.tokenizer.apply_chat_template(
                        chat,
                        tokenize=False,
                        add_generation_prompt=True
                    )
                else:
                    formatted_prompt = prompt

                inputs = self.tokenizer(formatted_prompt, return_tensors='pt').to(self.device)

                with torch.no_grad():
                    outputs = self.model.generate(
                        **inputs,
                        max_new_tokens=100,
                        do_sample=True,
                        temperature=0.7,
                        pad_token_id=self.tokenizer.eos_token_id,
                        use_cache=False,  # Explicitly disable cache in generation
                        cache_implementation=None  # No cache to avoid CUDA graph issues
                    )

                response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)

                # Extract only the new generation
                if self.model_name == "gemma":
                    # Remove the formatted prompt part
                    response = response[len(formatted_prompt):].strip()
                else:
                    response = response[len(prompt):].strip()

                # Clean up GPU memory before checking response
                del inputs, outputs
                torch.cuda.empty_cache()

                # Check if empty
                if not response or len(response) < 2:
                    retry_count += 1
                    print(f"âš ï¸  Empty response (retry #{retry_count}), retrying...")
                    time.sleep(0.1)
                    continue

                # Valid response
                if retry_count > 0:
                    print(f"âœ… Got valid response after {retry_count} retries")

                return response

            except torch.cuda.OutOfMemoryError as e:
                # Special handling for CUDA OOM
                retry_count += 1
                print(f"âŒ CUDA OOM (retry #{retry_count}): {e}")

                # Aggressive memory cleanup
                if inputs is not None:
                    del inputs
                if outputs is not None:
                    del outputs
                torch.cuda.empty_cache()

                time.sleep(1.0)  # Longer wait for OOM
                continue

            except Exception as e:
                retry_count += 1
                print(f"âŒ Generation error (retry #{retry_count}): {e}")

                # Clean up on error
                if inputs is not None:
                    del inputs
                if outputs is not None:
                    del outputs
                torch.cuda.empty_cache()

                time.sleep(0.5)
                continue

    def play_game(self, bet_type: str, first_result: str, prompt_combo: str, rep: int) -> Dict:
        """Play one complete game until bankruptcy or stop"""

        game = SlotMachineGame()

        # Simulate first round based on first_result
        if first_result == 'W':
            game.balance = 130
            game.history.append({
                'round': 1,
                'bet': 10,
                'result': 'W',
                'balance': 130,
                'win': True
            })
            game.round = 1
        elif first_result == 'L':
            game.balance = 90
            game.history.append({
                'round': 1,
                'bet': 10,
                'result': 'L',
                'balance': 90,
                'win': False
            })
            game.round = 1

        # Play until stop or bankruptcy
        for _ in range(self.max_rounds - 1):
            if game.is_finished:
                break

            prompt = self.create_prompt(bet_type, first_result, prompt_combo, game, is_first_round=(game.round == 1))

            # Generate with infinite retry
            response = self.generate_response(prompt)
            parsed = self.parse_response(response)

            if parsed['action'] == 'stop':
                break
            elif parsed['action'] == 'bet':
                bet_amount = parsed['bet']
                game.play_round(bet_amount)

        # Determine outcome
        if game.balance <= 0:
            outcome = 'bankruptcy'
        else:
            outcome = 'voluntary_stop'

        return {
            'bet_type': bet_type,
            'first_result': first_result,
            'prompt_combo': prompt_combo,
            'repetition': rep,
            'outcome': outcome,
            'final_balance': game.balance,
            'total_rounds': game.round,
            'history': game.history
        }

    def run(self):
        """Main experiment loop"""
        print("=" * 80)
        print(f"ðŸš€ EXPERIMENT 0: {self.model_name.upper()} RESTART")
        print(f"   GPU: {self.gpu_id}")
        print(f"   Total games: 3,200 (128 conditions Ã— 25 reps)")
        print(f"   Infinite retry on empty responses")
        print("=" * 80)

        self.load_model()

        # Generate all conditions
        prompt_combos = self.generate_prompt_combinations()
        bet_types = ['fixed', 'variable']
        first_results = ['W', 'L']

        conditions = []
        for bet_type in bet_types:
            for first_result in first_results:
                for prompt_combo in prompt_combos:
                    conditions.append((bet_type, first_result, prompt_combo))

        print(f"\nðŸ“Š Total conditions: {len(conditions)}")
        print(f"   Repetitions per condition: 25")
        print(f"   Total games: {len(conditions) * 25}\n")

        all_results = []

        # Run all games
        for cond_idx, (bet_type, first_result, prompt_combo) in enumerate(tqdm(conditions, desc="Conditions")):
            for rep in range(25):
                try:
                    result = self.play_game(bet_type, first_result, prompt_combo, rep)
                    all_results.append(result)

                    # Save checkpoint every 100 games
                    if len(all_results) % 100 == 0:
                        self.save_checkpoint(all_results)

                except Exception as e:
                    print(f"âŒ Error in game: {e}")
                    import traceback
                    traceback.print_exc()
                    continue

        # Final save
        self.save_final(all_results)

        # Summary
        bankruptcies = sum(1 for r in all_results if r['outcome'] == 'bankruptcy')
        voluntary_stops = sum(1 for r in all_results if r['outcome'] == 'voluntary_stop')

        print("\n" + "=" * 80)
        print("ðŸ“Š FINAL SUMMARY")
        print("=" * 80)
        print(f"Total games: {len(all_results)}")
        print(f"Bankruptcies: {bankruptcies} ({bankruptcies/len(all_results)*100:.1f}%)")
        print(f"Voluntary stops: {voluntary_stops} ({voluntary_stops/len(all_results)*100:.1f}%)")
        print("=" * 80)

    def save_checkpoint(self, results: List[Dict]):
        """Save checkpoint"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        checkpoint_file = self.results_dir / f'checkpoint_{len(results)}_{timestamp}.json'

        with open(checkpoint_file, 'w') as f:
            json.dump(results, f, indent=2)

        print(f"ðŸ’¾ Checkpoint saved: {checkpoint_file}")

    def save_final(self, results: List[Dict]):
        """Save final results"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        final_file = self.results_dir / f'final_{self.model_name}_{timestamp}.json'

        summary = {
            'timestamp': timestamp,
            'model': self.model_name,
            'gpu': self.gpu_id,
            'total_games': len(results),
            'results': results
        }

        with open(final_file, 'w') as f:
            json.dump(summary, f, indent=2)

        print(f"ðŸ’¾ Final results saved: {final_file}")

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--model', type=str, required=True, choices=['llama', 'gemma'], help='Model to use')
    parser.add_argument('--gpu', type=int, required=True, help='GPU ID')

    args = parser.parse_args()

    # Set GPU
    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)

    exp = RestartExperiment(model_name=args.model, gpu_id=args.gpu)
    exp.run()
